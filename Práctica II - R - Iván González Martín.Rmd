---
title: "Práctica II - Software R"
description: |
  Aplicando distintos algoritmos con selección de modelos a Airline Passenger Satisfaction
author:
  - name: Iván González Martín
    affiliation: Universidad Complutense de Madrid
    affiliation_url: https://ucm.es
date: "`r Sys.Date()`"
output:
    distill::distill_article:
        highlight: kate
        colorlinks: true
        code_folding: false
        toc: true            
        toc_depth: 3
editor_options: 
  markdown: 
    wrap: sentence
---

```{r setup, include=FALSE}
# Ajuste comunes de los chunks
knitr::opts_chunk$set(message = FALSE, warning = FALSE,
                      cache = TRUE, res = 400)
```

# Contenido del dataset

El dataset que se presenta para su análisis en esta práctica reúne información acerca de distintas **características evaluables** de **más de 120 000 vuelos nacionales** de **8 aerolíneas estadounidenses**.
Los datos provienen de la **US Airline Passenger Satisfaction Survey (2018)**, una encuesta realizada anualmente por el **Departamento de Transporte de los Estados Unidos** para medir la satisfacción de los pasajeros de las aerolíneas que operan en el país.
La encuesta **recopila información** sobre la calidad de los servicios ofrecidos por las aerolíneas, la puntualidad de los vuelos, la limpieza de las aeronaves, el servicio al cliente, la comodidad de los asientos, y la calidad de la comida y la bebida, entre otros.
Los resultados de la encuesta se emplean para **informar** a **los consumidores, a las aerolíneas y al propio gobierno** sobre el rendimiento de las compañías aéreas, así como para identificar áreas en las que **mejorar su servicio al cliente**.

Los **dos archivos CSV** que componen el dataset se han descargado del **UCI Machine Learning Repository** y no han sido modificados: [<https://bit.ly/3mXgcXx>].

# Objetivo

El objetivo de esta práctica es **predecir** la variable **binaria** `satisfaction` a través de distintos algoritmos con **selección de modelos** (BIC, AUC, etc.).
Concretamente, se emplearán **redes neuronales, regresión logística, técnicas de bagging, Random Forest, Gradient Boosting, XGBoost, modelos SVM y modelos ensamblados**.
**Para este primer PDF, la práctica se resolverá utilizando el software R**.

# Paquetes necesarios

Para llevar a cabo nuestro objetivo, necesitaremos los siguientes paquetes:

```{r paquetes}
# Paquetes
library(tidymodels) # Depuración datos
library(tidyverse) # Modelos
library(outliers) # Outliers
library(parallel) # Paralelización
library(doParallel) # Paralelización
library(performance)
library(ggthemes)
library(glue)
library(ggrepel)
library(caret)
library(gam)
library(randomForest)
library(Boruta)
library(MXM)
library(pROC)
library(visualpred)
library(h2o)
library(stats)
```

# Datos

Los datos que usaremos provienen de dos datasets divididos desde el inicio en **train y test**.
Para el análisis exploratorio, **bindearemos** los dos datasets para poder analizar el **total de las observaciones**.

```{r}
# Cargamos ambas particiones
air_train <- read_csv(file = "/Users/leztin/Library/Mobile Documents/com~apple~CloudDocs/Universidad/Máster/Segundo cuatrimestre/Técnicas de Machine Learning/Práctica 2/Dataset Airplane Satisfaction/train.csv")
air_test <- read_csv(file = "/Users/leztin/Library/Mobile Documents/com~apple~CloudDocs/Universidad/Máster/Segundo cuatrimestre/Técnicas de Machine Learning/Práctica 2/Dataset Airplane Satisfaction/test.csv")

# Creamos en test una columna con la variable objetivo `satisfaction`
air_test$satisfaction <- NA

# Bindeamos las particiones en un archivo completo
air_complete <- rbind(air_train, air_test)
```

# Análisis exploratorio preliminar

Antes de tomar cualquier decisión con los datos, lo primero que haremos será **echar un vistazo numérico** a cómo se comportan las variables.

### Variables

Nuestro dataset cuenta con **420 768 registros** y se compone de las siguientes variables:

```{r}
glimpse(air_complete)
```

| Variable                  | Significado                                                  | Variable                          | Significado                                                           |
|-----------|------------------------|-----------|--------------------------|
| ...1                      | Identificador numérico                                       | id                                | Identificador numérico                                                |
| Gender                    | Género del pasajero                                          | Age                               | Edad del pasajero                                                     |
| Customer Type             | Tipo de cliente                                              | Type of Travel                    | Propósito del vuelo del pasajero                                      |
| Class                     | Clase en la que viajaba el pasajero                          | Flight Distance                   | Distancia del vuelo tomado por el pasajero (km)                       |
| Inflight wifi service     | Nivel de satisfacción del servicio de WiFi a bordo           | Departure/Arrival time convenient | Nivel de satisfacción con la hora de salida/llegada convenida         |
| Ease of Onlinebooking     | Nivel de satisfacción con la reserva en línea                | Gate location                     | Nivel de satisfacción con la ubicación de la puerta de embarque       |
| Food and drink            | Nivel de satisfacción con la comida y bebida servida a bordo | Online boarding                   | Nivel de satisfacción con las opciones de embarque en línea           |
| Seat comfort              | Nivel de satisfacción con la comodidad del asiento           | Inflight entertainment            | Nivel de satisfacción con las opciones de entretenimiento a bordo     |
| On-board service          | Nivel de satisfacción con el servicio a bordo                | Leg room service                  | Nivel de satisfacción con el espacio para las piernas en los asientos |
| Baggage handling          | Nivel de satisfacción con el tratamiento del equipaje        | Checkin service                   | Nivel de satisfacción con el servicio de check-in                     |
| Inflight service          | Nivel de satisfacción con el servicio a bordo                | Cleanliness                       | Nivel de satisfacción con la limpieza a bordo                         |
| Departure Delay in Minutes | Minutos de retraso en la salida (min)                        | Arrival Delay in Minutes           | Minutos de retraso en la llegada (min)                                |
| satisfaction              | Nivel de satisfacción general con la aerolínea               |                                   |                                                                       |

### Balance de la variable objetivo

El objetivo será **predecir si un cliente ha quedado satisfecho con el servicio de la aerolínea o no**, por lo que `satisfaction` será nuestra **variable objetivo**.
En primer lugar comprobaremos cómo se **distribuyen los niveles de la objetivo**, que, como ya se ha comentado, es una variable binaria.

```{r}
# Objetivo: predecir si un cliente ha quedado satisfecho con el servicio de la aerolínea o no
air_complete |>
  count(satisfaction) |>
  drop_na() |> 
  mutate(porc = 100 * n / sum(n))
```

Graficaremos estas proporciones a través de un **gráfico de barras**:

```{r fig.width = 9, fig.asp = 0.62}
air_complete |> 
  mutate(satisfaction = as.factor(satisfaction)) |> 
  count(satisfaction) |>
  drop_na() |> 
  mutate(porc = n / sum(n)) |> 
  ggplot(aes(satisfaction, porc, fill = satisfaction)) +
  geom_col(position = "dodge", color = "black") +
  scale_y_continuous(labels = scales::percent_format(), limit = c(0,0.65)) +
  labs(title = "Proporción de pasajeros que están o no satisfechos \n con los servicios de la aerolínea", x = NULL, y = NULL) +
  theme_minimal() +
  theme(text = element_text(face = "bold", size = 15), plot.title = element_text(hjust = 0.5)) +
  scale_fill_discrete(name = "¿Satisfecho?", labels = c("No", "Sí")) +
  geom_text(aes(label = scales::percent(porc)), position = position_dodge(width = 0.9), vjust = -1) +
  scale_x_discrete(labels = c("0" = "Neutral/No","1" = "Sí"))
```

Como se puede observar en el gráfico, nuestra variable objetivo está **bastante balanceada**.
La **clase minoritaria**, que en este caso es `satisfied`, presenta tan solo un **17 % menos de registros que la otra clase**, por lo que no parece que vayan a darse limitaciones de ningún tipo.
Aún con todo, como el dataset presenta **observaciones en exceso**, en fases posteriores realizaremos un **muestreo estratificado** para que el **balance entre clases de la variable objetivo** (`satisfaction`) **se mantenga**.

Por otro lado, comentaremos también la **precisión y la tasa de fallos bases** de nuestro dataset.
Con una variable binaria como `satisfaction`, la **precisión base (baseline accuracy)** hace referencia a la **tasa de aciertos que se obtendría si se predijera siempre la clase mayoritaria**.
En este caso, dado que el **57 %** de los datos pertenecen a la categoría `neutral or dissatisfied`, la **precisión base sería del 57 %**.
Esto significa que si se predijera siempre la categoría `neutral or dissatisfied`, se acertaría el 57 % de las veces.
Si se analiza este concepto de manera inversa, la **tasa de fallos base (baseline error rate)** sería **el complemento de la precisión base**, es decir, el **43 %** restante.
Ello significa que, en la predicción de nuestra clase mayoritaria (`neutral or dissatisfied`), la **tasa de fallos equivaldría al 43 %** (cifra complementaria a la tasa de aciertos o precisión base).

# Fase 1: Exploración de los datos

## Problemas de codificación

### Exploración inicial de valores ausentes

Tras esta pequeña aproximación al dataset, comienza la **primera fase** de la metodología SEMMA para el depurado de nuestros datos.
En este primer apartado observaremos a *grosso modo* si existen problemas de **codificación** en el dataset.
Lo que más llama la atención con respecto a la codificación de los registros de ciertas variables es el **número de datos ausentes que presenta el dataset**.

```{r}
ausentes <- 
  apply(air_complete, 2, function(x) sum(is.na(x)))

ausentes_tb <- 
  tibble(Variable = names(air_complete), Ausentes = ausentes) |> 
  filter(Ausentes > 0)
ausentes_tb

ausentes_tb |> 
  filter(Variable != "satisfaction") |> 
  ggplot(aes(x = Variable, y = Ausentes)) +
  geom_col(position = "dodge", color = "black") +
  labs(title = "Nº de valores ausentes por variable", x = "Variable", 
       y = "Cantidad de valores ausentes") +
  theme_minimal() +
  theme(text = element_text(face = "bold", size = 9), plot.title = element_text(hjust = 0.5),
        axis.title.x = element_text(vjust=-0.5), axis.title.y = element_text(vjust=2))
```

A priori, parece que únicamente una de las variables presenta variables ausentes (casi 400 registros ausentes).
En fases posteriores, cuando se elabore la receta que aplicaremos a los algoritmos, **imputaremos a cada variable el valor que le corresponda** (media o mediana para las variables numéricas, o moda para las categóricas).

### Identificación de las variables

Por cuestiones de identificación, vamos a **cambiar el nombre** a algunas de nuestras variables.
Todas las variables terminadas en «Sat» implicarán una valoración (0-5) del servicio evaluado.

```{r}
air <-
  air_complete |> 
  dplyr::rename(Customer = `Customer Type`, Travel = `Type of Travel`,
         Distance = `Flight Distance`, WiFi_Sat = `Inflight wifi service`,
         Dep_Arr_Sat = `Departure/Arrival time convenient`, Online_Booking_Sat = `Ease of Online booking`,
         Gate_Sat = `Gate location`, Food_Sat = `Food and drink`,
         Online_Board_Sat = `Online boarding`, Seat_Sat = `Seat comfort`,
         Entertainment_Sat  = `Inflight entertainment`, On_board_Sat = `On-board service`,
         Leg_Sat = `Leg room service`, Checkin_Sat = `Checkin service`,
         Inflight_Sat  = `Inflight service`, Cleanliness_Sat = Cleanliness,
         Departure_Delay = `Departure Delay in Minutes`, Arrival_Delay = `Arrival Delay in Minutes`,
         Satisfaction  = satisfaction, Baggage_Sat = `Baggage handling`)
```

### Variables tipo texto, variables numéricas y factores

En este apartado echaremos un vistazo a la **tipología** de nuestras variables.
Comenzaremos con las **variables tipo texto**:

```{r}
air |>  
  dplyr::select(where(is.character)) |>
  glimpse()
```

En este caso, nuestro dataset contiene **5 variables tipo texto**.
Para el caso de nuestra variable objetivo (`Satisfaction`), la transformaremos ya en numérica con **0 = Neutral or Dissatisfied** y **1 = Satisfied**.

```{r}
air <-
  air |> 
  filter(!is.na(Satisfaction)) |> 
  mutate(Satisfaction = if_else(Satisfaction == "neutral or dissatisfied", 0, 1))
```

Para el resto de variables tipo texto, como ninguna de ellas es ordinal, las transformaremos directamente a **factor**.

```{r}
air <-
  air |> 
  mutate_if(~!is.numeric(.), as.factor)
```

Daremos un repaso también a las **numéricas**.

```{r}
air |>  
  dplyr::select(where(is.numeric)) |>
  glimpse()
```

Todas las **variables numéricas** están **codificadas correctamente**.

## Variables cuantitativas

Una vez asignado a cada variable su **tipología** correspondiente, pasaremos a analizar las **variables cuantitativas** del dataset.
Se analizará ante todo cómo **afecta** cada variable a nuestra **variable objetivo** (`Satisfaction`).
Este análisis servirá, ante todo, para **recategorizar las predictoras numéricas** a la hora de crear la receta para los algoritmos seleccionados.

### Colinealidad

Antes de nada, comprobaremos los posibles **problemas de colinealidad** entre las predictoras numéricas con tal de **eliminar** las que repitan información.

```{r}
library(corrr)
cor_matrix <- 
  air |> dplyr::select(-c(...1, id, )) |> dplyr::select(where(is.numeric)) |> cor(use = "pairwise.complete.obs", method = "pearson")
```

```{r layout="l-body-outset", fig.width=13, fig.asp = .9}
library(corrplot)
cor_matrix |>
  corrplot(method = "number", tl.cex = 0.55, number.cex = 0.7, type = "lower")
```

Como se puede observar, existen bastantes variables con **correlaciones superiores a 0.6**.
Vamos a echarles un vistazo:

```{r layout="l-body-outset", fig.width=13, fig.asp = .9}
# Seleccionar solo las entradas de la matriz de correlación con valores mayores a 0.4
cor_matrix[-0.6 <= cor_matrix & cor_matrix <= 0.6] <- NA

# Creamos el gráfico de correlación
corrplot(cor_matrix, method = "number", type = "lower",tl.cex = 0.55, number.cex = 0.7, na.label=" ")
```

Al tener una variable binaria como objetivo, solo podremos analizar las **correlaciones** entre las propias predictoras numéricas con tal de **deshacernos de información redundante**.
Nos desharemos de aquellas variables que mantengan **correlaciones superiores a 0.65** con otras variables.
**De un par de variables muy correlacionadas, eliminaremos la que mayor correlación mantenga con el resto de nuestras predictoras**.

-   La variable `Online_Booking_Sat` mantiene una correlación de **0.71** con `WiFi_Sat`. Ante este par, eliminaremos `Online_Booking_Sat`.
-   La variable `Arrival_Delay` mantiene una correlación de **-0.97** con `Departure_Delay`. Ante este par, eliminaremos `Arrival_Delay`.
-   La variable `Cleanliness_Sat` mantiene correlaciones de más de **0.65** con `Food_Sat`, `Seat_Sat` y `Entertainment_Sat`. Ante esta situación, eliminaremos `Cleanliness_Sat`.

Además, eliminaremos también las variables `...1` e `id` por ser **contadores numéricos sin ningún tipo de relevancia**.

```{r}
air <- 
  air |> 
  dplyr::select(-c(...1, id, Online_Booking_Sat, Arrival_Delay, Cleanliness_Sat))

air |> 
  dplyr::select(where(is.numeric)) |> 
  glimpse()
```

### Variables Age, Distance y Departure_Delay

```{r}
sum1 <- air |> 
  drop_na() |> 
  summarise(Variable = "Age", min_lead = min(Age), max_lead = max(Age))

sum2 <- air |> 
  drop_na() |>  
  summarise(Variable = "Distance", min_lead = min(Distance), max_lead = max(Distance))

sum3 <- air |> 
  drop_na() |> 
  summarise(Variable = "Departure_Delay", min_lead = min(Departure_Delay), max_lead = max(Departure_Delay))

rbind(sum1, sum2, sum3)
```

Las variables `Age`, `Distance` y `Departure_Delay` son las variables **numéricas continuas** de nuestro dataset, y miden la **edad** del pasajero, la **distancia** (en kilómetros) y el **retraso en la salida del vuelo** (en minutos), respectivamente. Veamos cómo evoluciona nuestra objetivo (`Satisfaction`) en función de estas variables.

```{r eval=FALSE}
sa <- air |> 
  ggplot(aes(x = Age, fill = Satisfaction)) + 
  geom_density(alpha = 0.8) +
  labs(title = "Distribución de la satisfacción general del cliente \n en función de su edad", x = "Edad", y = NULL) +
  scale_fill_discrete(name = "¿Satisfecho?", labels = c("No", "Sí")) +
  theme_minimal() +
  theme(text = element_text(face = "bold", size = 10), plot.title = element_text(hjust = 0.5), 
        axis.title.x = element_text(vjust=-0.5))

as <- air |> 
  ggplot(aes(x = Distance, fill = Satisfaction)) + 
  geom_density(alpha = 0.8) +
  labs(title = "Distribución de la satisfacción general \n del cliente en función de la distancia del viaje", x = "Distancia (km)", y = NULL) +
  scale_fill_discrete(name = "¿Satisfecho?", labels = c("No", "Sí")) +
  theme_minimal() +
  theme(text = element_text(face = "bold", size = 10), plot.title = element_text(hjust = 0.5), 
        axis.title.x = element_text(vjust=-0.5))

da <- air |> 
  filter(Departure_Delay > 0 & Departure_Delay < 300) |> 
  ggplot(aes(x = Departure_Delay, fill = Satisfaction)) + 
  geom_density(alpha = 0.8) +
  labs(title = "Distribución de la satisfacción general del cliente \n en función del retraso en la hora de salida convenida", x = "Retraso en la hora de salida convenida (min)", y = NULL) +
  scale_fill_discrete(name = "¿Satisfecho?", labels = c("No", "Sí")) +
  theme_minimal() +
  theme(text = element_text(face = "bold", size = 10), plot.title = element_text(hjust = 0.5), 
        axis.title.x = element_text(vjust=-0.5))

Rmisc::multiplot(sa, as, da, cols = 2)
```

```{r layout="l-body-outset", fig.width=50, fig.asp = .99, echo=FALSE}
knitr::include_graphics("/Users/leztin/Desktop/Captura de pantalla 2023-05-17 a las 22.53.16.png")  
```

Algunos comentarios a la vista de los gráficos:

-   Si observamos el primer gráfico de distribución, aquel que relaciona **edad con satisfacción general**, podremos percatarnos de que el grupo de individuos **que más satisfecho quedó con su viaje** se corresponde en cierta medida con el **rango etario de mayor edad**, individuos de entre **40 y 60 años**.
    Por contra, gran parte de **los pasajeros menos satisfechos** se sitúan entre los **10 y los 20 años**, destacando también la franja de **más de 60 años**.
    Existen varias posibles explicaciones para esta relación observada entre edad y satisfacción general del cliente.
    Una posible explicación es que los **clientes más jóvenes** pueden tener **expectativas más altas en términos de comodidades y servicios a bordo**, como WiFi gratis o entretenimiento de alta calidad, y pueden quedar más **decepcionados si no se cumplen estas expectativas**.
    Por otro lado, los clientes mayores pueden estar menos interesados en estas comodidades y servicios, y quizá estar más enfocados en la **puntualidad del vuelo y la atención del personal de la aerolínea**, lo que podría explicar su mayor satisfacción general.
    Por otro lado, también es posible que los **problemas de salud y movilidad** de las **personas mayores** puedan influir en su satisfacción general.
    Por ejemplo, si tienen **dificultades para moverse por el avión** o para utilizar los servicios de a bordo, pueden sentirse frustrados y **menos satisfechos con su experiencia de viaje**.
    Este último argumento justificaría el gran porcentaje de viajeros insatisfechos de más de 60 años.

-   Si observamos el segundo gráfico de distribución, aquel que relaciona **los minutos de retraso de la salida del vuelo con la satisfacción general**, podremos percatarnos de que **no parecen existir**, a mi sorpresa, **diferencias significativas en el grado de satisfacción general**.
    A medida que aumentan los minutos de retraso, es cierto que también aumenta ligeramente la proporción de individuos insatisfechos, **pero no de una manera demasiado significativa**.
    Esta variable no parece presentar demasiada correlación con nuestra variable objetivo (`Satisfaction`).

-   Por último, si observamos el tercer gráfico de distribución, aquel que relaciona **la distancia del viaje con la satisfacción general**, podremos percatarnos de que, **a mayor distancia, mayor satisfacción general**.
    La mayoría de clientes insatisfechos se dan en vuelos con distancias recorridas de menos de 1000 kilómetros.
    Esta relación puede ser debida a que, en vuelos largos, existan una **mayor variedad de servicios a bordo**, como opciones de entretenimiento y comidas.
    En **vuelos cortos**, es posible que los **servicios a bordo sean limitados** y los pasajeros puedan sentirse decepcionados en comparación.
    Otra posible explicación es que en vuelos largos, los pasajeros pueden tener **más espacio para moverse y descansar**, lo que puede contribuir a una experiencia de viaje **más satisfactoria**.

### Variables relacionadas con el nivel de satisfacción del cliente

```{r}
sum1 <- air |> 
  summarise(Variable = "WiFi_Sat", min_lead = min(WiFi_Sat), max_lead = max(WiFi_Sat))

sum2 <- air |> 
  summarise(Variable = "Dep_Arr_Sat", min_lead = min(Dep_Arr_Sat), max_lead = max(Dep_Arr_Sat))

sum3 <- air |> 
  summarise(Variable = "Gate_Sat", min_lead = min(Gate_Sat), max_lead = max(Gate_Sat))

sum4 <- air |> 
  summarise(Variable = "Food_Sat", min_lead = min(Food_Sat), max_lead = max(Food_Sat))

sum5 <- air |> 
  summarise(Variable = "Online_Board_Sat", min_lead = min(Online_Board_Sat), max_lead = max(Online_Board_Sat))

sum6 <- air |> 
  summarise(Variable = "Seat_Sat", min_lead = min(Seat_Sat), max_lead = max(Seat_Sat))

sum7 <- air |> 
  summarise(Variable = "Entertainment_Sat", min_lead = min(Entertainment_Sat), max_lead = max(Entertainment_Sat))

sum8 <- air |> 
  summarise(Variable = "On_board_Sat", min_lead = min(On_board_Sat), max_lead = max(On_board_Sat))

sum9 <- air |> 
  summarise(Variable = "Leg_Sat", min_lead = min(Leg_Sat), max_lead = max(Leg_Sat))

sum10 <- air |> 
  summarise(Variable = "Baggage_Sat", min_lead = min(Baggage_Sat), max_lead = max(Baggage_Sat))

sum11 <- air |> 
  summarise(Variable = "Checkin_Sat", min_lead = min(Checkin_Sat), max_lead = max(Checkin_Sat))

sum12 <- air |> 
  summarise(Variable = "Inflight_Sat", min_lead = min(Inflight_Sat), max_lead = max(Inflight_Sat))

rbind(sum1, sum2, sum3, sum4, sum5, sum6, sum7, sum8, sum9, sum10, sum11, sum12)
```

```{r echo=FALSE}
air <- air |> 
  mutate_at(vars(-Distance, -Departure_Delay, -Age), as.factor)
```

Las variables `WiFi_Sat`, `Dep_Arr_Sat`, `Gate_Sat`, `Food_Sat`, `Online_Board_Sat`, `Seat_Sat`, `Entertainment_Sat`, `On_board_Sat`, `Leg_Sat` y `Baggage_Sat` miden la **satisfacción del cliente en una escala del 0 al 5** con ciertos servicios relacionados con el **viaje a bordo del avión** (0 = Nada satisfecho y 5 = Muy satisfecho).
En cierta manera, se tratan de **variables semicualitativas**, pues no almacenan una escala de **valores numéricos continuos**, sino de **valores discretos** (del 0 al 5).
La única variable que no presenta valor 0 es `Baggage_Sat`, que mide el **grado de satisfacción con el tratamiento del equipaje durante el vuelo**.
Por otro lado, la variable `WiFi_Sat` presenta valor 0 cuando el avión **no disponía de servicio de WiFi a bordo**.
Veamos cómo se relaciona nuestra objetivo (`Satisfaction`) con estas variables.

```{r layout="l-body-outset", fig.width=15, fig.asp = .99}
b1 <- air |> 
  group_by(WiFi_Sat) |> 
  count(Satisfaction) |>
  mutate(porc = n / sum(n)) |> 
  mutate(conteo = n) |> 
  ggplot(aes(x = WiFi_Sat, y = conteo, fill = Satisfaction)) +
  geom_col(position = "dodge", color = "black") +
  labs(title = "Distribución de la satisfacción general del cliente en función de\n la satisfacción con el servicio WiFi a bordo", 
       x = "Satisfacción servicio WiFi (0-5)", y = "Conteo") +
  theme_minimal() +
  theme(text = element_text(face = "bold", size = 12), plot.title = element_text(hjust = 0.5), 
  axis.title.x = element_text(vjust = -0.5), axis.title.y = element_text(vjust = 2)) +
  scale_fill_discrete(name = "¿Satisfecho?", labels = c("No", "Sí")) +
  geom_text(aes(label = scales::percent(porc)), position = position_dodge(width = 1), vjust = -1)

b2 <- air |> 
  group_by(Dep_Arr_Sat) |> 
  count(Satisfaction) |>
  mutate(porc = n / sum(n)) |> 
  mutate(conteo = n) |> 
  ggplot(aes(x = Dep_Arr_Sat, y = conteo, fill = Satisfaction)) +
  geom_col(position = "dodge", color = "black") +
  labs(title = "Distribución de la satisfacción general del cliente en función de\n la satisfacción con la hora de salida/llegada convenida", 
       x = "Satisfacción hora de salida/llegada convenida (0-5)", y = "Conteo") +
  theme_minimal() +
  theme(text = element_text(face = "bold", size = 12), plot.title = element_text(hjust = 0.5), 
  axis.title.x = element_text(vjust = -0.5), axis.title.y = element_text(vjust = 2)) +
  scale_fill_discrete(name = "¿Satisfecho?", labels = c("No", "Sí")) +
  geom_text(aes(label = scales::percent(porc)), position = position_dodge(width = 1), vjust = -1)

b3 <- air |> 
  group_by(Gate_Sat) |> 
  count(Satisfaction) |>
  mutate(porc = n / sum(n)) |> 
  mutate(conteo = n) |> 
  ggplot(aes(x = Gate_Sat, y = conteo, fill = Satisfaction)) +
  geom_col(position = "dodge", color = "black") +
  labs(title = "Distribución de la satisfacción general del cliente en función de\n la satisfacción con la ubicación de la puerta de embarque", 
       x = "Satisfacción ubicación puerta de embarque (0-5)", y = "Conteo") +
  theme_minimal() +
  theme(text = element_text(face = "bold", size = 12), plot.title = element_text(hjust = 0.5), 
  axis.title.x = element_text(vjust = -0.5), axis.title.y = element_text(vjust = 2)) +
  scale_fill_discrete(name = "¿Satisfecho?", labels = c("No", "Sí")) +
  geom_text(aes(label = scales::percent(porc)), position = position_dodge(width = 1), vjust = -1)

b4 <- air |> 
  group_by(Food_Sat) |> 
  count(Satisfaction) |>
  mutate(porc = n / sum(n)) |> 
  mutate(conteo = n) |> 
  ggplot(aes(x = Food_Sat, y = conteo, fill = Satisfaction)) +
  geom_col(position = "dodge", color = "black") +
  labs(title = "Distribución de la satisfacción general del cliente en función de\n la satisfacción con la comida y bebida servida a bordo", 
       x = "Satisfacción comida y bebida a bordo (0-5)", y = "Conteo") +
  theme_minimal() +
  theme(text = element_text(face = "bold", size = 12), plot.title = element_text(hjust = 0.5), 
  axis.title.x = element_text(vjust = -0.5), axis.title.y = element_text(vjust = 2)) +
  scale_fill_discrete(name = "¿Satisfecho?", labels = c("No", "Sí")) +
  geom_text(aes(label = scales::percent(porc)), position = position_dodge(width = 1), vjust = -1)

b5 <- air |> 
  group_by(Online_Board_Sat) |> 
  count(Satisfaction) |>
  mutate(porc = n / sum(n)) |> 
  mutate(conteo = n) |> 
  ggplot(aes(x = Online_Board_Sat, y = conteo, fill = Satisfaction)) +
  geom_col(position = "dodge", color = "black") +
  labs(title = "Distribución de la satisfacción general del cliente en función de\n la satisfacción con la reserva a través de página web", 
       x = "Satisfacción reserva por página web (0-5)", y = "Conteo") +
  theme_minimal() +
  theme(text = element_text(face = "bold", size = 12), plot.title = element_text(hjust = 0.5), 
  axis.title.x = element_text(vjust = -0.5), axis.title.y = element_text(vjust = 2)) +
  scale_fill_discrete(name = "¿Satisfecho?", labels = c("No", "Sí")) +
  geom_text(aes(label = scales::percent(porc)), position = position_dodge(width = 1), vjust = -1)

b6 <- air |> 
  group_by(Seat_Sat) |> 
  count(Satisfaction) |>
  mutate(porc = n / sum(n)) |> 
  mutate(conteo = n) |> 
  ggplot(aes(x = Seat_Sat, y = conteo, fill = Satisfaction)) +
  geom_col(position = "dodge", color = "black") +
  labs(title = "Distribución de la satisfacción general del cliente en función de\n la satisfacción con la comodidad del asiento", 
       x = "Satisfacción comodidad del asiento (0-5)", y = "Conteo") +
  theme_minimal() +
  theme(text = element_text(face = "bold", size = 12), plot.title = element_text(hjust = 0.5), 
  axis.title.x = element_text(vjust = -0.5), axis.title.y = element_text(vjust = 2)) +
  scale_fill_discrete(name = "¿Satisfecho?", labels = c("No", "Sí")) +
  geom_text(aes(label = scales::percent(porc)), position = position_dodge(width = 1), vjust = -1)

Rmisc::multiplot(b1, b2, b3, b4, b5, b6, cols = 2)
```

Algunos comentarios a la vista de los gráficos:

-   Las **variables predictoras** que tienen una **correlación positiva alta** con nuestra objetivo `Satisfaction` son `WiFi_Sat`, `Online_Board_Sat` y `Seat_Sat`.
    Esto sugiere que si un cliente está satisfecho con el **servicio de WiFi a bordo**, la **reserva online del vuelo** y la **comodidad del asiento**, es más probable que esté satisfecho con su **experiencia de viaje en general**.
    Estas variables podrían ser importantes para considerar al mejorar la satisfacción del cliente en el futuro, por lo que **las conservaremos íntegramente para futuras fases**.
    El único cambio que probablemente se lleve a cabo en la fase de reagrupación de las variables es el de **agrupar la categoría** `0` con **alguna otra**, principalmente por su disminuido número de registros.

-   Las variables `Food_Sat`, y `Gate_Sat` también **correlacionan positivamente** con la **satisfacción general** del cliente (`Satisfaction`), pero no tanto como las variables anteriores.
    Esto sugiere que aunque estas variables son importantes para la satisfacción general del cliente, **no son tan relevantes como las anteriores tres**.
    De nuevo, en este caso también se optará por agrupar la categoría `0` de ambas variables con otra que presente **similar distribución y mayor número de registros**.

-   Por último, la variable `Dep_Arr_Sat` **no parece presentar una correlación significativa con la satisfacción general** (`Satisfaction`).
    Para **todas las categorías de la variables** el nivel de satisfacción es **más o menos el mismo** (en torno al 45 %).
    Esto sugiere que, en general, **la hora de llegada o salida del avión** no es un factor **determinante** para la satisfacción general del cliente.
    **Las anteriores variables parecen mucho más relevantes que esta última**.

```{r layout="l-body-outset", fig.width=15, fig.asp = .99}
b7 <- air |> 
  group_by(Entertainment_Sat) |> 
  count(Satisfaction) |>
  mutate(porc = n / sum(n)) |> 
  mutate(conteo = n) |> 
  ggplot(aes(x = Entertainment_Sat, y = conteo, fill = Satisfaction)) +
  geom_col(position = "dodge", color = "black") +
  labs(title = "Distribución de la satisfacción general del cliente en función de\n la satisfacción con las opciones de entretenimiento a bordo", 
       x = "Satisfacción entretenimiento a bordo (0-5)", y = "Conteo") +
  theme_minimal() +
  theme(text = element_text(face = "bold", size = 12), plot.title = element_text(hjust = 0.5), 
  axis.title.x = element_text(vjust = -0.5), axis.title.y = element_text(vjust = 2)) +
  scale_fill_discrete(name = "¿Satisfecho?", labels = c("No", "Sí")) +
  geom_text(aes(label = scales::percent(porc)), position = position_dodge(width = 1), vjust = -1)

b8 <- air |> 
  group_by(On_board_Sat) |> 
  count(Satisfaction) |>
  mutate(porc = n / sum(n)) |> 
  mutate(conteo = n) |> 
  ggplot(aes(x = On_board_Sat, y = conteo, fill = Satisfaction)) +
  geom_col(position = "dodge", color = "black") +
  labs(title = "Distribución de la satisfacción general del cliente en función de\n la satisfacción con el servicio durante todo el vuelo", 
       x = "Satisfacción servicio durante todo el vuelo", y = "Conteo") +
  theme_minimal() +
  theme(text = element_text(face = "bold", size = 12), plot.title = element_text(hjust = 0.5), 
  axis.title.x = element_text(vjust = -0.5), axis.title.y = element_text(vjust = 2)) +
  scale_fill_discrete(name = "¿Satisfecho?", labels = c("No", "Sí")) +
  geom_text(aes(label = scales::percent(porc)), position = position_dodge(width = 1), vjust = -1)

b9 <- air |> 
  group_by(Leg_Sat) |> 
  count(Satisfaction) |>
  mutate(porc = n / sum(n)) |> 
  mutate(conteo = n) |> 
  ggplot(aes(x = Leg_Sat, y = conteo, fill = Satisfaction)) +
  geom_col(position = "dodge", color = "black") +
  labs(title = "Distribución de la satisfacción general del cliente en función de\n la satisfacción con el espacio para las piernas en el asiento", 
       x = "Satisfacción espacio para las piernas en el asiento (0-5)", y = "Conteo") +
  theme_minimal() +
  theme(text = element_text(face = "bold", size = 12), plot.title = element_text(hjust = 0.5), 
  axis.title.x = element_text(vjust = -0.5), axis.title.y = element_text(vjust = 2)) +
  scale_fill_discrete(name = "¿Satisfecho?", labels = c("No", "Sí")) +
  geom_text(aes(label = scales::percent(porc)), position = position_dodge(width = 1), vjust = -1)

b10 <- air |> 
  group_by(Baggage_Sat) |> 
  count(Satisfaction) |>
  mutate(porc = n / sum(n)) |> 
  mutate(conteo = n) |> 
  ggplot(aes(x = Baggage_Sat, y = conteo, fill = Satisfaction)) +
  geom_col(position = "dodge", color = "black") +
  labs(title = "Distribución de la satisfacción general del cliente en función de\n la satisfacción con el tratamiento del equipaje", 
       x = "Satisfacción tratamiento del equipaje (1-5)", y = "Conteo") +
  theme_minimal() +
  theme(text = element_text(face = "bold", size = 12), plot.title = element_text(hjust = 0.5), 
  axis.title.x = element_text(vjust = -0.5), axis.title.y = element_text(vjust = 2)) +
  scale_fill_discrete(name = "¿Satisfecho?", labels = c("No", "Sí")) +
  geom_text(aes(label = scales::percent(porc)), position = position_dodge(width = 1), vjust = -1)

b11 <- air |> 
  group_by(Checkin_Sat) |> 
  count(Satisfaction) |>
  mutate(porc = n / sum(n)) |> 
  mutate(conteo = n) |> 
  ggplot(aes(x = Checkin_Sat, y = conteo, fill = Satisfaction)) +
  geom_col(position = "dodge", color = "black") +
  labs(title = "Distribución de la satisfacción general del cliente en función de\n la satisfacción con el servicio de check-in", 
       x = "Satisfacción servicio de check-in (0-5)", y = "Conteo") +
  theme_minimal() +
  theme(text = element_text(face = "bold", size = 12), plot.title = element_text(hjust = 0.5), 
  axis.title.x = element_text(vjust = -0.5), axis.title.y = element_text(vjust = 2)) +
  scale_fill_discrete(name = "¿Satisfecho?", labels = c("No", "Sí")) +
  geom_text(aes(label = scales::percent(porc)), position = position_dodge(width = 1), vjust = -1)

b12 <- air |> 
  group_by(Inflight_Sat) |> 
  count(Satisfaction) |>
  mutate(porc = n / sum(n)) |> 
  mutate(conteo = n) |> 
  ggplot(aes(x = Inflight_Sat, y = conteo, fill = Satisfaction)) +
  geom_col(position = "dodge", color = "black") +
  labs(title = "Distribución de la satisfacción general del cliente en función de\n la satisfacción con el servicio a bordo", 
       x = "Satisfacción servicio a bordo (0-5)", y = "Conteo") +
  theme_minimal() +
  theme(text = element_text(face = "bold", size = 12), plot.title = element_text(hjust = 0.5), 
  axis.title.x = element_text(vjust = -0.5), axis.title.y = element_text(vjust = 2)) +
  scale_fill_discrete(name = "¿Satisfecho?", labels = c("No", "Sí")) +
  geom_text(aes(label = scales::percent(porc)), position = position_dodge(width = 1), vjust = -1)

Rmisc::multiplot(b7, b8, b9, b10, b11, b12, cols = 2)
```

Algunos comentarios a la vista de los gráficos:

-   En este caso, parece que este grupo de seis variables mantiene **correlaciones muy similares** respecto de nuestra variable objetivo (`Satisfaction`). Todas son **positivas y, en mayor o menor medida, presentan la misma fortaleza**. Por diferenciar en cierta medida, parece que las variables `Entertainment_Sat`, `Inflight_Sat` y `Leg_Sat` presentan una **correlación un poco más fuerte en los niveles 3-4**, aunque no es un detalle demasiado significativo. Como en el anterior set de variables, la categoría `0` la terminaremos **agrupando con alguna de las otras** debido a su número tan **reducido de registros**.

## Variables cualitativas

### Variable Gender

```{r}
air |>
  count(Gender, sort = TRUE) |>
  mutate(porc = 100*n/sum(n))
```

La variable `Gender` presenta **2 modalidades**, por lo que se trata de una **variable binaria**.
La **proporción** de los registros está muy balanceada, en torno al 50 % para cada clase.
Comprobemos ahora su afectación sobre nuestra variable objetivo.

```{r}
air |>
  group_by(Gender) |> 
  count(Satisfaction) |>
  mutate(porc = 100*n/sum(n)) |> 
  ungroup()
```

```{r layout="l-body-outset", fig.width=13, fig.asp = .6}
hombre <- air |> 
  filter(Gender == "Male") |> 
  group_by(Satisfaction) |>
  summarise(n = n()) |> 
  ggplot(aes(x = "", y = n, fill = Satisfaction)) + 
  geom_bar(stat = "identity", color = "black") + 
  coord_polar("y") + geom_text(aes(label = paste(100 * round(n/51177, 2), "%")), 
                               position = position_stack(vjust = 0.5), check_overlap = T, size = 7) + 
  labs(x = NULL, y = NULL, fill = NULL, title = "Distribución de la satisfacción del cliente \npara individuos de género masculino") + 
  theme_minimal() +
  theme(axis.line = element_blank(), text = element_text(face = "bold", size = 15), axis.text = element_blank(), 
        axis.ticks = element_blank(), plot.title = element_text(hjust = 0.5)) +
  scale_fill_discrete(name = "¿Satisfecho?", labels = c("No", "Sí"))

mujer <- air |> 
  filter(Gender == "Female") |> 
  group_by(Satisfaction) |>
  summarise(n = n()) |> 
  ggplot(aes(x = "", y = n, fill = Satisfaction)) + 
  geom_bar(stat = "identity", width = 2, color = "black") + 
  coord_polar("y") + geom_text(aes(label = paste(100 * round(n/52727, 2), "%")), 
                               position = position_stack(vjust = 0.5), check_overlap = T, size = 7) + 
  labs(x = NULL, y = NULL, fill = NULL, title = "Distribución de la satisfacción del cliente \npara individuos de género femenino") + 
  theme_minimal() +
  theme(axis.line = element_blank(), text = element_text(face = "bold", size = 15), axis.text = element_blank(), 
        axis.ticks = element_blank(), plot.title = element_text(hjust = 0.5)) +
  scale_fill_discrete(name = "¿Satisfecho?", labels = c("No", "Sí"))

Rmisc:::multiplot(hombre, mujer, cols = 2)
```

Algunos comentarios a la vista de los gráficos:

-   Si observamos ambos diagramas sectoriales, podremos percatarnos de que **no existen diferencias apreciables en la satisfacción del cliente según su género**. Para ambos géneros la proporción ronda el **44.5 % de satisfechos frente al 56.5 % de insatisfechos**. Podríamos confirmar, por tanto, que la variable `Gender` está **incorrelada con nuestra objetivo** (`Satisfaction`): el género del cliente no parece influir en su satisfacción general del viaje.

### Variable Customer

```{r}
air |>
  count(Customer, sort = TRUE) |>
  mutate(porc = 100*n/sum(n))
```

La variable `Customer` presenta **2 modalidades**, por lo que se trata de una **variable binaria**.
La **proporción** de los registros favorece a los individuos **más leales**, con un **81.7 %** sobre el total.
Es una variable **desbalanceada**.
Comprobemos ahora su afectación sobre nuestra variable objetivo.

```{r}
air |>
  group_by(Customer) |> 
  count(Satisfaction) |>
  mutate(porc = 100*n/sum(n)) |> 
  ungroup()
```

```{r  layout="l-body-outset", fig.width=13, fig.asp = .6}
a1 <- air |> 
  filter(Customer == "disloyal Customer") |> 
  group_by(Satisfaction) |>
  summarise(n = n()) |> 
  ggplot(aes(x = "", y = n, fill = Satisfaction)) + 
  geom_bar(stat = "identity", color = "black") + 
  coord_polar("y") + geom_text(aes(label = paste(100 * round(n/18981, 2), "%")), 
                               position = position_stack(vjust = 0.5), check_overlap = T, size = 7) + 
  labs(x = NULL, y = NULL, fill = NULL, title = "Distribución de la satisfacción del cliente \npara individuos desleales a la compañía") + 
  theme_minimal() +
  theme(axis.line = element_blank(), text = element_text(face = "bold", size = 15), axis.text = element_blank(), 
        axis.ticks = element_blank(), plot.title = element_text(hjust = 0.5)) +
  scale_fill_discrete(name = "¿Satisfecho?", labels = c("No", "Sí"))

a2 <- air |> 
  filter(Customer == "Loyal Customer") |> 
  group_by(Satisfaction) |>
  summarise(n = n()) |> 
  ggplot(aes(x = "", y = n, fill = Satisfaction)) + 
  geom_bar(stat = "identity", width = 2, color = "black") + 
  coord_polar("y") + geom_text(aes(label = paste(100 * round(n/84923, 2), "%")), 
                               position = position_stack(vjust = 0.5), check_overlap = T, size = 7) + 
  labs(x = NULL, y = NULL, fill = NULL, title = "Distribución de la satisfacción del cliente \npara individuos leales a la compañía") + 
  theme_minimal() +
  theme(axis.line = element_blank(), text = element_text(face = "bold", size = 15), axis.text = element_blank(), 
        axis.ticks = element_blank(), plot.title = element_text(hjust = 0.5)) +
  scale_fill_discrete(name = "¿Satisfecho?", labels = c("No", "Sí"))

Rmisc:::multiplot(a1, a2, cols = 2)
```

Algunos comentarios a la vista de los gráficos:

-   Si observamos ambos diagramas sectoriales, podremos percatarnos de que **sí que existen diferencias significativas en la satisfacción del cliente según su nivel de lealtad a la marca**. Mientras que para **clientes leales el porcentaje de satisfacción es del 52 %**, para **clientes desleales ese mismo nivel desciende hasta el 24 %**. Ello puede deberse a que los individuos desleales pueden llegar a tener una **mayor predisposición a encontrar problemas** o fallas en el servicio que reciben y que, por ello, queden **más insatisfechos**. Además, los clientes desleales podrían llegar a tener una **menor tolerancia a los problemas que puedan surgir durante su viaje** y podrían estar más dispuestos a **quejarse o expresar su insatisfacción** en comparación con los clientes leales, quienes pueden tener una actitud **más comprensiva** ante situaciones desfavorables.

### Variable Travel

```{r}
air |>
  count(Travel, sort = TRUE) |>
  mutate(porc = 100*n/sum(n))
```

La variable `Travel` presenta **2 modalidades**, por lo que se trata de una **variable binaria**.
La **proporción** de los registros favorece a los individuos que **viajan por motivos de negocio**, con un **68.9 %** sobre el total.
Es una variable **desbalanceada**.
Comprobemos ahora su afectación sobre nuestra variable objetivo.

```{r}
air |>
  group_by(Travel) |> 
  count(Satisfaction) |>
  mutate(porc = 100*n/sum(n)) |> 
  ungroup()
```

```{r  layout="l-body-outset", fig.width=13, fig.asp = .6}
a1 <- air |> 
  filter(Travel == "Business travel") |> 
  group_by(Satisfaction) |>
  summarise(n = n()) |> 
  ggplot(aes(x = "", y = n, fill = Satisfaction)) + 
  geom_bar(stat = "identity", color = "black") + 
  coord_polar("y") + geom_text(aes(label = paste(100 * round(n/71655, 2), "%")), 
                               position = position_stack(vjust = 0.5), check_overlap = T, size = 7) + 
  labs(x = NULL, y = NULL, fill = NULL, title = "Distribución de la satisfacción del cliente \npara individuos que viajan por negocio") + 
  theme_minimal() +
  theme(axis.line = element_blank(), text = element_text(face = "bold", size = 15), axis.text = element_blank(), 
        axis.ticks = element_blank(), plot.title = element_text(hjust = 0.5)) +
  scale_fill_discrete(name = "¿Satisfecho?", labels = c("No", "Sí"))

a2 <- air |> 
  filter(Travel == "Personal Travel") |> 
  group_by(Satisfaction) |>
  summarise(n = n()) |> 
  ggplot(aes(x = "", y = n, fill = Satisfaction)) + 
  geom_bar(stat = "identity", width = 2, color = "black") + 
  coord_polar("y") + geom_text(aes(label = paste(100 * round(n/32249, 2), "%")), 
                               position = position_stack(vjust = 0.5), check_overlap = T, size = 7) + 
  labs(x = NULL, y = NULL, fill = NULL, title = "Distribución de la satisfacción del cliente \npara individuos que viajan por ocio") + 
  theme_minimal() +
  theme(axis.line = element_blank(), text = element_text(face = "bold", size = 15), axis.text = element_blank(), 
        axis.ticks = element_blank(), plot.title = element_text(hjust = 0.5)) +
  scale_fill_discrete(name = "¿Satisfecho?", labels = c("No", "Sí"))

Rmisc:::multiplot(a1, a2, cols = 2)
```

Algunos comentarios a la vista de los gráficos:

-   Si observamos ambos diagramas sectoriales, podremos percatarnos de que **sí que existen diferencias significativas en la satisfacción del cliente según su motivo de viaje**. Mientras que para **clientes que viajan por motivos de negocio el porcentaje de satisfacción es del 58 %**, para **turistas ese mismo nivel desciende hasta el 10 %**. En este sentido, el cliente que viaja por motivos de negocios podría esperar un **servicio más eficiente y orientado a sus necesidades**, mientras que un turista podría estar más interesado en la **comodidad y la calidad** del entretenimiento a bordo. Otra posible razón es que los clientes que viajan por **negocios** podrían estar **más dispuestos a pagar por un servicio de mayor calidad**, mientras que los **turistas** podrían presentar **mayor sensibilidad al precio**.

### Variable Class

```{r}
air |>
  count(Class, sort = TRUE) |>
  mutate(porc = 100*n/sum(n))
```

La variable `Class` presenta **3 modalidades**.
La **proporción** de los registros favorece a los individuos que **viajan en clase Business o Eco**, con un **44-47 %** sobre el total.
Encontramos tan solo un 7 % de los registros en los que el cliente viaja en clase `Eco Plus`.
Comprobemos ahora su afectación sobre nuestra variable objetivo.

```{r}
air |>
  group_by(Class) |> 
  count(Satisfaction) |>
  mutate(porc = 100*n/sum(n)) |> 
  ungroup()
```

```{r  layout="l-body-outset", fig.width = 13, fig.asp = 0.6}
air |> 
  group_by(Class) |> 
  count(Satisfaction) |>
  mutate(porc = n / sum(n)) |> 
  mutate(conteo = n) |> 
  ggplot(aes(x = reorder(Class, -conteo), y = conteo, fill = Satisfaction)) +
  geom_col(position = "dodge", color = "black") +
  labs(title = "Distribución de la satisfacción del cliente en función de la clase en la que viajaba el individuo", x = "Clase", y = "Conteo") +
  theme_minimal() +
  theme(text = element_text(face = "bold", size = 15), plot.title = element_text(hjust = 0.5), 
  axis.title.x = element_text(vjust = -0.5), axis.title.y = element_text(vjust = 2)) +
  scale_fill_discrete(name = "¿Satisfecho?", labels = c("No", "Sí")) +
  geom_text(aes(label = scales::percent(porc)), position = position_dodge(width = 1), vjust = -1)
```

Algunos comentarios a la vista del gráfico:

-   Si observamos el gráfico de barras, podremos percatarnos de que **sí que existen diferencias significativas en la satisfacción del cliente según la clase en la que viajaba**. Mientras que para **clientes que viajan en clase business el porcentaje de satisfacción es del 69.4 %**, para **viajeros de clase Eco o Eco Plus ese mismo nivel desciende hasta el 18-20 %**. Esta relación es bastante obvia: los asientos de **clase business ofrecen mayores comodidades** que los del resto de clases, por lo que el **nivel de satisfacción general** debe ser, en media, **superior al resto**.

# Fases 2 y 3: Muestreo y modificación estructural de los datos

Tras la fase de exploración de nuestro dataset (EDA), continuaremos con las fases de **muestreo** y **modificación** de los datos.
En primer lugar, y dado que nuestro dataset contiene **más de 200 000 tuplas**, realizaremos un **muestreo** del **2 %** para que nos quede una muestra de, aproximadamente, **3 000 registros**.
Si no redujésemos las dimensiones de nuestro dataset, los **filtros** y los **wrappers** para la selección de variables **tardarían horas en ejecutarse**.
**Además, hemos fijado distintas semillas para comprobar que el muestreo no influya de alguna manera en los modelos y se han obtenido con todas ellas resultados muy similares**.
El muestreo se realiza teniendo en cuenta las **proporciones originales de las categorías** de nuestra variable objetivo, para no alterar las **dimensiones originales** del dataset.

En segundo lugar, para la fase de **modificación** de los datos, consideraremos **dos apartados** principales.
Uno primero en donde se ejecutarán las **modificaciones estructurales** que afecten a toda las base de datos (transformar variables a factores, problemas de codificación o de rango, variables que no aportan, creación de variables en general, etc.), y uno segundo en donde se llevarán a cabo aquellas **modificaciones** que afecten **a cada algoritmo en concreto** a modo de **receta** (normalización para la métrica, recategorización, tratamiento de outliers/ausentes, dummyficación, etc.).

## Muestreo

Realizamos el muestreo.
Lo retenemos en la nueva variable `air_sample`.

```{r}
# Fijamos semilla
set.seed(12346)

# Muestreo
air_sample <-
  air_train |> 
  group_by(satisfaction) |>  
  slice_sample(prop = 0.02) |> 
  ungroup()
```

## Modificaciones estructurales

Tras ello, procedemos a las **modificaciones estructurales**.
Se tratan los problemas de **codificación** y de **tipología** de las variables comentados en epígrafes anteriores.

```{r}
# Aplicamos las modificaciones estructurales al dataset completo
## Modificación del nombre de las variables
air_sample <- 
  air_sample |>
  dplyr::rename(Customer = `Customer Type`, Travel = `Type of Travel`,
         Distance = `Flight Distance`, WiFi_Sat = `Inflight wifi service`,
         Dep_Arr_Sat = `Departure/Arrival time convenient`, Online_Booking_Sat = `Ease of Online booking`,
         Gate_Sat = `Gate location`, Food_Sat = `Food and drink`,
         Online_Board_Sat = `Online boarding`, Seat_Sat = `Seat comfort`,
         Entertainment_Sat  = `Inflight entertainment`, On_board_Sat = `On-board service`,
         Leg_Sat = `Leg room service`, Checkin_Sat = `Checkin service`,
         Inflight_Sat  = `Inflight service`, Cleanliness_Sat = Cleanliness,
         Departure_Delay = `Departure Delay in Minutes`, Arrival_Delay = `Arrival Delay in Minutes`,
         Satisfaction  = satisfaction, Baggage_Sat = `Baggage handling`)

## Tratamiento de nuestra variable objetivo
air_sample <-
  air_sample |> 
  filter(!is.na(Satisfaction)) |> 
  mutate(Satisfaction = if_else(Satisfaction == "neutral or dissatisfied", 0, 1))

## Modificaciones en la tipología de las variables
air_sample <-
  air_sample |> 
  mutate_if(~!is.numeric(.), as.factor)

## Eliminación de variables por problemas de colinealidad
air_sample <- 
  air_sample |> 
  dplyr::select(-c(Online_Booking_Sat, Arrival_Delay, Cleanliness_Sat))

## Eliminación de variables por insustanciales
air_sample <- 
  air_sample |> 
  dplyr::select(-c(...1, id))
```

```{r echo=FALSE, results='hide'}
air_sample <- 
  air_sample |> 
  mutate_at(vars(-Distance, -Departure_Delay, -Age), as.factor)
```

# Fase 4: Feature Engineering

El **«Feature Engineering»**, también conocido como **ingeniería de características**, refiere al proceso de **creación de nuevas variables** o a la **transformación** de las ya existentes en un conjunto de datos para mejorar el rendimiento y la efectividad de los modelos de aprendizaje automático.
En esencia, el proceso de «Feature Engineering» implica **manipular, transformar o crear nuevas características** a partir de los datos originales con el objetivo de **capturar mejor las relaciones subyacentes o mejorar la representación de los datos**.

En esta sección intermedia, probaremos **dos mecanismos propios del campo de la ingeniería de características**: por un lado, la **creación de nuevas variables a partir de las ya existentes de manera manual**; y, por otro, probaremos la **configuración de autoencoders** sobre nuestras **variables categóricas** (la gran mayoría) a fin de mejorar la calidad de las mismas.

## Creación de nuevas variables manualmente

En este apartado, crearemos nuevas variables a partir de las ya existentes.
Concretamente crearemos **cuatro nuevas variables**:

-   **Variable** `Adult`: variable binaria creada a partir de la variable original `Age`. Aporta información sobre si el individuo es mayor de edad.
-   **Variable** `Time`: variable continua creada a partir de las variables `Distance` y `Arrival_Delay`. Aporta información acerca del tiempo que tarda un vuelo en llegar a su destino (en minutos).
-   **Variable** `Overtake`: variable continua creada a partir de las variables `Departure_Delay` y `Arrival_Delay`. Aporta información acerca de las diferencia entre el retraso en la salida y en la llegada del avión (en minutos).
-   **Variable** `Comfort`: variable continua creada a partir de las variables `Food_Sat`, `Cleanliness_Sat` y `Seat_Sat`. Aporta información acerca de la comodidad general de cada individuo.

```{r eval=FALSE}
# Creación de nuevas variables
## Variable binaria, ¿adulto?
air_sample$Adult <-
  ifelse(air_sample$Age > 18, 1, 0)

## Variable continua, ¿cuánto tiempo en minutos tarda el avión en realizar el viaje?
air_sample$Time <-
  air_sample$Distance / 20 + air_sample$Arrival_Delay

## Variable continua, ¿cuál es la diferencia en términos de tiempo entre el retraso en la salida y en la llegada del avión?
air_sample$Overtake <- 
  air_sample$Arrival_Delay - air_sample$Departure_Delay

## Variable continua, ¿cuánto tiempo en minutos tarda el avión en realizar el viaje?
air_sample$Comfort <-
  air_sample$Seat_Sat + air_sample$Cleanliness_Sat + air_sample$Food_Sat
```

Tras la creación de estas nuevas variables, vamos a probar a continuación a configurar el **autoencoder** proveído por el paquete `{h2o}` a fin de probar **otro método de los presentados en clase**.

## Autoencoders para variables categóricas

Con el objetivo de probar dentro de esta sección **algunos de los métodos de Feature Engineering vistos en clase**, vamos a aplicar a la selección de **variables categóricas un autoencoder** provisto por el paquete `{h2o}`.

Por lo general, los **autoencoders** son modelos de aprendizaje automático utilizados en la ingeniería de características para resumir **representaciones latentes más efectivas de los datos**.
Pueden extraer características no lineales, reducir la dimensionalidad, eliminar ruido y detectar anomalías en los datos.
También pueden **generar variables sintéticas y facilitar la transferencia de características a otros modelos**.
Esto último es lo que trataremos de hacer a continuación.

Vamos a aplicar el autoencoder sobre las **principales variables categóricas del dataset**.
En total son 12 variables.
Dejaremos la mitad de capas ocultas, en este caso 6.

```{r}
# Iniciamos el paquete
h2o.init()

# Separamos del dataset general las variables categóricas con más categorías
df <- air_sample[,c("WiFi_Sat","Dep_Arr_Sat","Gate_Sat","Food_Sat",
                    "Online_Board_Sat","Seat_Sat","Entertainment_Sat","On_board_Sat",
                    "Leg_Sat","Baggage_Sat","Checkin_Sat","Inflight_Sat")]

# Almacenamos el dataset
train <- 
  as.h2o(df)

# Ejecutamos la función
autoencoder <- 
  h2o.deeplearning(x = 1:12, training_frame = train,
    autoencoder = TRUE, hidden = 6, 
    activation = 'Tanh')

# Almacenamos los resultados
ae1_codings <- h2o.deepfeatures(autoencoder, train, layer = 1)
results_encod <- as.data.frame(ae1_codings)
head(results_encod)
```

A continuación las **integramos y eliminamos las anteriores del dataset**.
En función de los **procesos de selección de variables** posteriores, podrán incluirse o no en los **sets de variables tentativos** a aplicar en los modelos.

```{r eval=FALSE}
air_sample <- cbind(results_encod, air_sample)
```

# Fase 5: Receta general para todos los modelos

Para que los distintos métodos de selección de modelos puedan **seleccionar las mejores variables**, vamos a generar una primera **receta inicial** con el **total** de variables **predictoras** que tenemos en el dataset.
Se muestra a continuación el proceso **paso a paso**.

## Aplicación de roles

En este primer apartado **definimos nuestra receta** indicándole el conjunto de datos, y enfrentando nuestra variable objetivo `Satisfaction` a todas las demás.
Después, **asignamos posibles roles**, sujetos a modificación, que nos permitan diferenciar acciones entre las variables (sobre todo en la sección outliers).

```{r}
# Receta
air_rec <-
  # Fórmula y datos
  recipe(data = air_sample, Satisfaction ~ .)|>
  # Roles
  add_role(where(is.factor), 
           new_role = "cualitativa") |> 
  add_role(where(is.numeric), 
           new_role = "cuantitativa") |> 
  add_role(Distance, Departure_Delay,
           new_role = "mediana") |> 
  add_role(Age, 
           new_role = "media") |> 
  add_role(all_nominal_predictors(),
           new_role = "moda")
```

## Reagrupación de las variables cualitativas

En esta receta, como ya comentamos en fases anteriores, reagruparemos las categorías de **todas las variables relacionadas con el nivel de satisfacción del cliente** en **tres niveles únicos** (en vez de la escala 1-5 original, optaremos por la escala 1-3).
Esto lo haremos para evitar crear **demasiadas variables dummy** que **complejicen y sobreajusten** los modelos posteriores.
Iremos agrupando las categorías que presenten **distribuciones similares respecto de nuestra objetivo** para no alterar en exceso las proporciones del dataset original.

Por otro lado, también reagruparemos la categoría `Eco Plus` de la variable `Class` **transformándola en binaria**.
Como ya se comentó, esta categoría contenía **bastantes menos registros que sus compañeras** y seguía la misma distribución que la clase `Eco`, por lo que, finalmente, **optaremos por unirlas**.

```{r}
air_rec <- 
  air_rec |> 
  step_mutate(WiFi_Sat = 
                forcats::fct_collapse(WiFi_Sat, 
                             "1" = c("1", "2", "3"),
                             "2" = "4",
                             "3" = c("0", "5"))) |>
  step_mutate(Food_Sat = 
                forcats::fct_collapse(Food_Sat,
                             "2" = c("0", "2", "3"),
                             "3" = c("4", "5"))) |> 
  step_mutate(Dep_Arr_Sat = 
                forcats::fct_collapse(Dep_Arr_Sat, 
                             "1" = c("0", "1"),
                             "2" = c("2", "3"),
                             "3" = c("4", "5"))) |>
  step_mutate(Online_Board_Sat = 
                forcats::fct_collapse(Online_Board_Sat, 
                             "1" = c("1", "2", "3"),
                             "2" = c("0", "4"),
                             "3" = "5")) |>
  step_mutate(Gate_Sat = 
                forcats::fct_collapse(Gate_Sat, 
                             "1" = c("1", "2"),
                             "2" = c("0", "3", "4"),
                             "3" = "5")) |>
  step_mutate(Seat_Sat = 
                forcats::fct_collapse(Seat_Sat, 
                             "1" = c("0", "1", "2", "3"),
                             "2" = "4",
                             "3" = "5")) |>
  step_mutate(Entertainment_Sat = 
                forcats::fct_collapse(Entertainment_Sat, 
                             "1" = c("0", "1"),
                             "2" = c("2", "3"),
                             "3" = c("4", "5"))) |>
  step_mutate(Baggage_Sat = 
                forcats::fct_collapse(Baggage_Sat, 
                             "1" = c("1", "2", "3"),
                             "2" = "4",
                             "3" = "5")) |>
  step_mutate(On_board_Sat = 
                forcats::fct_collapse(On_board_Sat, 
                             "1" = c("0", "1", "2", "3"),
                             "2" = "4",
                             "3" = "5")) |>
  step_mutate(Checkin_Sat = 
                forcats::fct_collapse(Checkin_Sat, 
                             "1" = c("0", "1", "2"),
                             "2" = c("3", "4"),
                             "3" = "5")) |>
  step_mutate(Leg_Sat = 
                forcats::fct_collapse(Leg_Sat, 
                             "1" = c("0", "1", "2", "3"),
                             "2" = "4",
                             "3" = "5")) |>
  step_mutate(Inflight_Sat = 
                forcats::fct_collapse(Inflight_Sat, 
                             "1" = c("0", "1", "2", "3"),
                             "2" = "4",
                             "3" = "5")) |>
  step_mutate(Class = 
                forcats::fct_collapse(Class, 
                             "Eco Plus" = "Eco"))
```

## Recategorización de las variables cuantitativas

En los métodos que emplearemos posteriormente, la **recategorización** de las variables **cuantitativas no** es estrictamente **necesaria**, por lo que conservaremos nuestras tres variables cuantitativas continuas (`Age`, `Distance` y `Departure_Delay`) tal y como son.

## Tratamiento de outliers y valores ausentes

```{r}
box1 <- 
  ggplot(air_sample, aes(Satisfaction, Age)) +
  geom_boxplot() +
  theme_minimal() +
  coord_flip()
box2 <- 
  ggplot(air_sample, aes(Satisfaction, Distance)) +
  geom_boxplot() +
  theme_minimal() +
  coord_flip()
box3 <- 
  ggplot(air_sample, aes(Satisfaction, Departure_Delay)) +
  geom_boxplot() +
  theme_minimal() +
  coord_flip()

Rmisc::multiplot(box1, box2, box3)
```

Si observamos estos gráficos de cajas y bigotes, de nuestras tres variables **cuantitativas continuas**, dos son **asimétricas**, por lo que se detectarán los outliers y se imputarán los ausentes por la **mediana**.
Para el caso de la variable `Age`, nuestra única variable cuantitativa **simétrica**, se detectarán los outliers y se imputarán los ausentes por la **media**.
Para el resto de variables **cualitativas**, **semicualitativas** y **binarias**, **imputamos los ausentes** directamente por la **moda**.

```{r}
air_rec <-
  air_rec |> 
  # Detección de outliers por la mediana y por la media
  step_mutate(across(has_role("mediana"), function(x) { ifelse(abs(scores(x, type = "mad")) > 3 & !is.na(x), NA, x) })) |>
  step_mutate(across(has_role("media"), function(x) { ifelse(abs(scores(x, type = "z")) > 2.5 & !is.na(x), NA, x) })) |>  
  # Imputación de ausentes por la mediana, la media y la moda
  step_impute_median(has_role("mediana")) |>
  step_impute_mean(has_role("media")) |>
  step_impute_mode(has_role("moda"))
```

## Normalización por rango

**Normalizamos** nuestras variables por rango para que todas tengan **el mismo peso**.

```{r}
air_rec <-
  air_rec |> 
  step_normalize(all_numeric_predictors()) 
```

## Creación de variables dummy

**Dummyficaremos** también nuestras variables cualitativas.
Para ello, tomamos **todas las nominales, menos nuestra variable objetivo**.

```{r}
air_rec <-
  air_rec |>
  step_dummy(all_nominal_predictors())
```

## Filtro de cero varianza

Aplicamos el **filtro de cero varianza** a todas nuestras variables **predictoras**.

```{r}
air_rec <-
  air_rec |>
  step_zv(all_predictors())
```

## Horneado

Por último, **horneamos** nuestra receta para comprobar que todas nuestras **nuevas variables** recategorizadas se hayan creado **correctamente**.
Todas nuestras variables **numéricas** están **estandarizadas**, y todas nuestras **categóricas dummyficadas**.
Tampoco existen ya valores ausentes ni outliers que alteren las distribuciones.

```{r}
air_prep <- 
  bake(air_rec |>  prep(), new_data = NULL)
air_prep
```

```{r echo=FALSE, results='hide'}
air_prep <- 
  air_prep |> 
  mutate_at(vars(Satisfaction), as.numeric)
```

# Fase 6: Chequeo intuitivo inicial: Regresión Logística y Random Forest preliminares

En esta fase se propone una **primera aproximación a los modelos a aplicar al dataset**.
Aplicaremos el método de selección de modelos BIC sin alterar para que nos seleccione un **set preliminar de variables**, y lo aplicaremos a un **modelo simple de regresión logística** y a un **Random Forest sin tunear**.
Con ello obtendremos las **estadísticas básicas sobre el dataset y una primera matriz de confusión** a fin de definir un estadío preliminar sobre el cual empezar a trabajar.

En primer lugar, seleccionamos las variables:

```{r echo=FALSE, results='hide'}
# Modificamos Satisfaction a factor
air_prep <- air_prep |> mutate_at(vars(Satisfaction), as.factor)

# Ajuste
ajuste_air <- 
  glm(data = air_prep, Satisfaction ~ ., family = binomial(link = "logit"))
ajuste_null <- 
  glm(data = air_prep, Satisfaction ~ 1, family = binomial(link = "logit"))
```

```{r results='hide'}
#Fijamos semilla
set.seed(12346)

# Aplicación del stepAIC con la penalización del criterio BIC
BIC <-
  MASS::stepAIC(ajuste_null, scope = list(upper = ajuste_air), 
                direction="both", family = binomial(link = "logit"), 
                k = log(nrow(air_prep)))
```

Resumimos la selección tras su procesado con `summary()`:

```{r}
# Extracción de las variables
BIC_vars <- (names(BIC[[1]]))
dput(BIC_vars)
```

## Primera aproximación: Regresión Logística

Una vez tenemos definido nuestro set de variables preliminar, lo aplicamos a un primer modelo de regresión logística.
Para que no haya problemas, sustituimos las categorías de nuestra variable objetivo `Satisfaction` por `Yes` y `No`.
De esta manera, el modelo interpretará automáticamente que debe aplicar regresión logística.

```{r}
# Sustitución de categorías de la variable `Satisfaction`
air_prep$Satisfaction <- 
  ifelse(air_prep$Satisfaction==1, "Yes", "No")
```

A continuación, aplicamos el modelo:

```{r}
# Aplicamos validación cruzada repetida
control <- 
  trainControl(method = "repeatedcv", number = 4,
                      repeats = 5, classProbs = TRUE, savePredictions = "all")

# Definimos el modelo, enfrentando la objetivo a nuestro set de variables preliminar
logi <- 
  train(Satisfaction ~ Online_Board_Sat_X1+Travel_Personal.Travel+WiFi_Sat_X1+
          Customer_Loyal.Customer+WiFi_Sat_X2+Baggage_Sat_X3+Baggage_Sat_X2+
          Class_Eco.Plus+Online_Board_Sat_X3+Checkin_Sat_X3+Dep_Arr_Sat_X3+
          Seat_Sat_X3+Inflight_Sat_X3+Checkin_Sat_X2, 
        data = air_prep, method = "glm", trControl = control)

summary(logi)
```

Como se puede observar en el modelo, todas las variables son significativas.
Calculemos a continuación la matriz de confusión y las estadísticas básicas:

```{r}
# Extraemos la matriz de confusión y las estadísticas básicas del modelo
sal <- logi$pred
salconfu <- 
  confusionMatrix(sal$pred, sal$obs, positive = "Yes")
salconfu
```

```{r}
# Extraemos los valores para la curva ROC
curvaroc <- 
  roc(response = sal$obs, predictor = sal$Yes)
auc <- curvaroc$auc
plot(roc(response=sal$obs,predictor=sal$Yes))
```

Como se puede observar, los resultados son bastante positivos.
Un resumen de los estadísticos:

-   **Precisión**: el modelo alcanza una tasa de accuracy del **92.85 %**.
-   **Sensibilidad (porcentaje de verdaderos positivos)**: el modelo alcanza una tasa de sensibilidad del **94.77 %**. De **26495 verdaderos positivos** (valores totales de la clase **Yes**) el modelo ha logrado clasificar correctamente **25108**.
-   **Especificidad (porcentaje de verdaderos negativos)**: el modelo alcanza una tasa de especificidad del **91.29 %**. De **20260 verdaderos negativos** (valores totales de la clase **No**) el modelo ha logrado clasificar correctamente **18496**.
-   **Valor curva ROC**: el modelo alcanza un valor para la curva ROC de **97.63 %**.

Además, cabe destacar cómo **la proporción entre datos de la clase positiva y negativa es bastante igualitaria** (26495 datos positivos vs. 20260 datos negativos).

## Segunda aproximación: Random Forest

A pesar de los resultados tan positivos que nos ha ofrecido la regresión logística, **vamos a probar con un modelo un poco más complejo**.
A continuación aplicaremos un **Random Forest sin tunear**, simplemente para comprobar **si merecerá la pena aplicar otros algoritmos con separaciones no lineales al dataset**.
En primer lugar, comprobaremos del total de variables **cuáles considera el algoritmo Random Forest como más importantes**:

```{r}
# Generamos la rejilla
rfgrid <- 
  expand.grid(mtry=c(3))

# Le indicamos validación cruzada
control <- 
  trainControl(method = "cv", number = 10, savePredictions = "all",
               classProbs = TRUE)

# Lanzamos el modelo enfrentando todas nuestras variables a la objetivo
rf <- 
  train(factor(Satisfaction)~., data = air_prep,
           method = "rf", trControl = control, tuneGrid = rfgrid,
           linout = FALSE, ntree = 200, nodesize = 10, replace = TRUE,
           importance = TRUE)

# Generamos el dataframe y lo ordenamos por importancia
tabla <- as.data.frame(importance(rf$finalModel))
tabla <- tabla[order(-tabla$MeanDecreaseAccuracy),]
head(tabla)
```

En la tabla de la salida anterior podemos observar el **orden de importancia de las variables según el Random Forest**.
Están ordenadas en función de su contribución particular al accuracy total del modelo.
Vamos a graficar esta información para visualizar mejor las variables.

```{r fig.width = 9, fig.asp = 0.62}
ggplot(tabla, aes(x = reorder(rownames(tabla), -MeanDecreaseAccuracy), y = MeanDecreaseAccuracy)) +
  geom_bar(stat = "identity", fill = "steelblue") +
  labs(title = "Importancia de las variables según su contribución al accuracy general", x = "Variables", y = "Mean Decrease Accuracy") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1),
        text = element_text(face = "bold", size = 10),
        plot.title = element_text(hjust = 0.5),
        axis.title.x = element_text(vjust = -0.5))
```

Como se puede observar, el **grado de importancia de las variables coincide en gran medida con la selección del criterio BIC** llevada a cabo en el apartado anterior.
Está claro que `WiFi_Sat_X1`, `Travel_Personal.Travel`, `Online_Board_Sat_X1`, `Customer_Loyal.Customer` y `WiFi_Sat_X2` son las cinco variables más relevantes de nuestro dataset, de acuerdo con el criterio de selección BIC y el criterio de ordenación de importancia del algoritmo Random Forest.

A continuación **analizaremos los resultados del modelo Random Forest**.
Los compararemos con los de la regresión logística para ver cuál de los dos algoritmos **(el primero más tradicional, y este segundo más complejo)** es mejor.

```{r}
rf$results
rf$finalModel
```

Como se puede observar, los resultados son también bastante positivos.
Un resumen de los estadísticos:

-   **Precisión**: el modelo alcanza una tasa de accuracy del **91.62 %**.
-   **Sensibilidad (porcentaje de verdaderos positivos)**: el modelo alcanza una tasa de sensibilidad del **95.85 %**. De **5299 verdaderos positivos** el modelo ha logrado clasificar correctamente **5079**.
-   **Especificidad (porcentaje de verdaderos negativos)**: el modelo alcanza una tasa de especificidad del **91.54%**. De **4052 verdaderos negativos** (valores totales de la clase **No**) el modelo ha logrado clasificar correctamente **3709**.
-   **Valor curva ROC**: el modelo alcanza un valor para la curva ROC de **97.85 %**.

Ambos modelos ofrecen **muy buenos resultados**.
Como siempre, **ante un par de modelos con resultados similares, seleccionaremos el que menor complejidad ofrezca**.
En este caso concreto, yo me quedaría con la **regresión logística al ser un modelo mucho más simple y tradicional que el Random Forest**.
Aún con todo, en posteriores apartados probaremos distintos algoritmos con otros sets de variables para tratar de **mejorar aún más el resultado**.

## Respuesta a las preguntas planteadas

### ¿Cuantas observaciones de la clase minoritaria vs. mayoritaria?

```{r}
air_prep |>
  count(Satisfaction) |>
  drop_na() |> 
  mutate(porc = 100 * n / sum(n))
```

Como se puede observar, **la variable objetivo está bastante balanceada**.
La clase minoritaria sería `Yes`, con un 13 % menos de tuplas que la clase mayoritaria `No`.

### ¿Es preferible la separación lineal o la no lineal en relación con la complejidad?

```{r}
estadisticos <- 
  data.frame(
  Model = c("Regresión Logística", "Random Forest"),
  Accuracy = c(0.9285, 0.9162),
  Sensibility = c(0.9477, 0.9585),
  Specificity = c(0.9129, 0.9154),
  ROC_Curve = c(0.9763, 0.9785))
estadisticos
```

Como se puede observar, los resultados de los modelos **son muy similares**.
Ante estas dos opciones, seguramente será mejor la **separación lineal clásica con modelos con menor complejidad** (como la regresión logística).
Complejizar el modelo en estos casos no merece la pena porque la mejora en términos de precisión es **ínfima**

### ¿Existen problemas de sensitividad o especificidad?

```{r}
conf <- data.frame(
  Reference = c("Reference_No", "Reference_Yes"),
  Prediction_No = c(18496, 1764),
  Prediction_Yes = c(1387, 25108))

rownames(conf) <- conf$Reference
conf$Reference <- NULL

conf
```

Dado que las categorías de nuestra variable objetivo están **muy balanceadas**, no hay problemas de **sensitividad ni de especificidad**.
Tanto en Regresión Logística como en Random Forest ambas estadísticas superan el **90 %**.

### ¿Cuantas variables input potenciales selecciona el step wise básico?, ¿muchas o pocas?

```{r}
dput(BIC_vars)
```

De **32 variables** que tenía el dataset tras la dummyficación, el **criterio BIC ha seleccionado 14 variables**.
Con 14 variables se han obtenido resultados muy positivos, pero es posible que eliminando alguna más el modelo obtenga **resultados similares**.
En posteriores epígrafes se comprobará esta cuestión mediante la aplicación del **resto de métodos de selección de variables**.

### Del documento «decisión en clasificación binaria.pdf» a qué ejemplo se parecen más vuestros datos en términos de sensitividad, AUC, accuracy, etc.?

Del documento **«decisión en clasificación binaria.pdf»**, el dataset que estamos tratando se parece más al **ejemplo 3 de la página 20**.
Tenemos las categorías de la variable dependiente bastante **bien distribuidas**, y disfrutamos de unos **niveles de sensitividad y especificidad bastante altos**.

Aún con todo, **vamos a generar nuestros propios gráficos para regresión logística y Random Forest** con el paquete `{visualpred}`.
Comenzaremos por la visualización del **modelo para GLM**:

#### Visualización del dataset con GLM

```{r}
# Cargamos los archivos necesarios
source("/Users/leztin/Downloads/Tema 11 Decision en clasificacion binaria/funcion resultadosglm.R")
source("/Users/leztin/Downloads/Tema 11 Decision en clasificacion binaria/funcion resultadosrf.R")
source("/Users/leztin/Downloads/Tema 11 Decision en clasificacion binaria/funcion seleccionar 2.0.R")
source("/Users/leztin/Downloads/Tema 11 Decision en clasificacion binaria/toydata 2.0.R")

# Generamos nuestro dataframe para cargar el modelo
variables <- 
  c("Online_Board_Sat_X1", "Travel_Personal.Travel", 
    "WiFi_Sat_X1", "Customer_Loyal.Customer", "WiFi_Sat_X2", "Baggage_Sat_X3", 
    "Baggage_Sat_X2", "Class_Eco.Plus", "Online_Board_Sat_X3", "Checkin_Sat_X3", 
    "Dep_Arr_Sat_X3", "Seat_Sat_X3", "Inflight_Sat_X3", "Checkin_Sat_X2")
dependiente <-
  "Satisfaction"
dataf <- 
  as.data.frame(air_prep[,c(variables, dependiente)])

# Generamos el modelo GLM
result <- 
  famdcontour(dataf=dataf, listclass=variables, listconti = NULL, vardep=dependiente,
              title="Modelo GLM",title2=" ",selec=0,modelo="glm",classvar=0)

# Ploteamos el resultado
result[[2]]
```

Como se puede observar, **la división que realiza el modelo GLM es bastante satisfactoria**.
Identifica correctamente las áreas en donde existe **más densidad de datos de la clase negativa y de la clase positiva**.
A la clase negativa parece asignarle valores de probabilidad cercanos a 1 **(sombreados de un gris más oscuro)**, y a los de la clase positiva valores de probabilidad más ligados al 0 **(sombreados de un gris más claro)**.
A continuación se muestra el **archivo txt** en el que aparecen generadas las estadísticas básicas del dataset para GLM.

```{r eval=FALSE}
# Generamos el txt con la información
resultadosglm(dataf = dataf, vardep = vardep, corte = 0.5)
```

```{r echo=FALSE}
knitr::include_graphics("/Users/leztin/Desktop/Captura de pantalla 2023-05-11 a las 12.12.02.png")  
```

Si se atiende a la imagen, podremos observar que **los resultados son muy positivos**.
Las categorías de la variable dependiente están **bastante balanceadas (43 % vs. 57 %)** y los valores de sensitividad y especificidad **superan el 90 %**.
El valor para la curva ROC es del **97.41 %**.

Son sin duda resultados muy positivos que parecen indicar que, para este dataset en concreto, los modelos más adecuados son los **modelos lineales más clásicos**.
Aún con todo, probaremos a realizar a continuación el mismo proceso para el **algoritmo Random Forest**.

#### Visualización del dataset con Random Forest

```{r}
# Generamos el modelo GLM
result <- 
  famdcontour(dataf=dataf, listclass=variables, listconti = NULL, vardep=dependiente,
              title="Modelo Random Forest",title2=" ",selec=0,modelo="rf",classvar=0)

# Ploteamos el resultado
result[[2]]
```

Como se puede observar en el gráfico, la **densidad de las probabilidades parece estar peor distribuida** que en el caso del modelo GLM anterior.
Las zonas en las que existe mayor concentración de puntos sí que son **identificadas correctamente**, pero en donde confluyen ambas categorías se puede observar como el modelo presenta \***mayores dificultadas para clasificar** con acierto.
A continuación se muestra el **archivo txt** en el que aparecen generadas las estadísticas básicas del dataset para Random Forest.

```{r eval=FALSE}
# Generamos el txt con la información
resultadosrf(dataf = dataf, vardep = vardep, corte = 0.45)
```

```{r echo=FALSE}
knitr::include_graphics("/Users/leztin/Desktop/Captura de pantalla 2023-05-11 a las 12.23.40.png")  
```

Si se atiende a la imagen, podremos observar que **los resultados son positivos**, pero peores que con la regresión logística anterior.
Las categorías de la variable dependiente están **bastante balanceadas (43 % vs. 57 %)** y los valores de sensitividad y especificidad **superan el 90 %**.
El valor para la curva ROC es del **97.34 %**.

Una vez realizado el **chequeo intuitivo inicial**, podemos **presuponer cierta linealidad en la distribución de nuestros datos**.
A continuación comenzaremos con el **proceso de selección de variables** para obtener el set de variables tentativo a aplicar **en el resto de modelos programados para esta práctica**.

# Fase 7.1: Proceso de selección de variables

En este apartado, pasaremos a **seleccionar las variables más interesantes de nuestra receta** según distintos **criterios de selección y de información**.
En concreto emplearemos los siguientes métodos:

1.  Filtro `SBF()` del paquete `{caret}`

2.  Wrapper `RFE()` del paquete `{caret}`

3.  Algoritmo `MMPC()` del paquete `{MXM}`

4.  Algoritmo `SES()` del paquete `{MXM}`

5.  Algoritmo `Boruta()` del paquete `{Boruta}`

6.  Criterio de Información AIC con `stepAIC()` del paquete `{MASS}`

7.  Criterio de Información BIC con `stepAIC()` del paquete `{MASS}`

8.  Step repetido con el Criterio de Información AIC

9.  Step repetido con el Criterio de Información BIC

Vamos a activar **los procesos de paralización en nuestro ordenador** para que el procedimiento de selección vaya un poco **más rápido**.

```{r}
# Inicializamos la paralelización
clusters <- detectCores() - 1
make_cluster <- makeCluster(clusters)
registerDoParallel(make_cluster)
```

## Filtro SBF()

En primer lugar, probaremos con el **filtro SBF (Sequential Backward Feature Selection)** del paquete `{caret}`.
El filtro SBF es una técnica de selección de variables que se utiliza en machine learning para reducir el número de variables de un conjunto de datos.
Es una **técnica de selección hacia atrás** (backward), que comienza con un modelo que utiliza todas las variables disponibles y luego va eliminando iterativamente las variables menos importantes.
Comprobemos ahora cuáles decide seleccionar de nuestra receta:

```{r}
# Fijamos semilla
set.seed(12346)

# Aplicación del filtro SBF
SBF <- 
  sbf(x = air_rec, data = air_sample,
      sbfControl = sbfControl(functions = rfSBF,
                              method = "cv"))

# Extracción de las variables
SBF_select <-
  SBF$optVariables
```

Tras hacer varias pruebas con diferentes semillas, el filtro SBF siempre selecciona en torno a **28 variables de 32** y son las siguientes:

```{r}
dput(SBF$optVariables)
```

## Wrapper RFE()

En segundo lugar, probaremos con el **wrapper RFE (Recursive Feature Elimination)** del paquete `{caret}`.
Básicamente, la función RFE funciona eliminando recursivamente el conjunto de variables menos importantes del conjunto de datos y evaluando el rendimiento del modelo con el subconjunto de variables restantes.
El proceso de eliminación se repite hasta que se alcanza el **número deseado de variables o un nivel de precisión determinado**.
Comprobemos ahora cuáles decide seleccionar de nuestra receta:

```{r}
# Fijamos semilla
set.seed(12346)

# Aplicación del wrapper RFE
RFE <-
  rfe(x = air_rec, data = air_sample, sizes = 2^(2:4),
      rfeControl = rfeControl(functions = rfFuncs,
                              method = "cv", 
                              number = 15))

# Extracción de las variables
RFE_select <-
  RFE$optVariables
```

Tras hacer varias pruebas con diferentes semillas e hiperparámetros, el filtro RFE siempre selecciona en torno a **12 variables de 32** y son las siguientes:

```{r}
dput(RFE$optVariables[1:12])
```

## Algoritmo SES()

En tercer lugar, probaremos con el **algoritmo SES** del paquete `{MXM}`.
Comprobemos ahora cuáles decide seleccionar de nuestra receta:

```{r}
# Fijamos semilla
set.seed(12346)

# Sustitución de categorías de la variable `Satisfaction`
air_prep$Satisfaction <- 
  ifelse(air_prep$Satisfaction=="Yes", 1, 0)

# Aplicación del algoritmo SES
data <-
  as.matrix(air_prep)

SES <- 
  SES(target = "Satisfaction", dataset = data, 
      max_k = 3, hash = TRUE, test = "testIndLogistic")
```

Tras hacer varias pruebas con diferentes semillas e hiperparámetros, el algoritmo SES siempre selecciona en torno a **11 variables de 32** y son las siguientes:

```{r}
dput(names(air_prep[,c(SES@selectedVars)]))
```

## Algortimo MMPC()

En cuarto lugar, probaremos con el **algoritmo MMPC** del paquete `{MXM}`, un método similar al algoritmo SES cuya diferencia es que no generar múltiples subconjuntos de variables en el proceso.
Comprobemos ahora cuáles decide seleccionar de nuestra receta:

```{r}
# Fijamos semilla
set.seed(12346)

# Aplicación del algoritmo MMPC
data <-
  as.matrix(air_prep)

MMPC <- 
  MMPC(target = "Satisfaction", dataset = data, 
      max_k = 3, hash = TRUE, test = "testIndLogistic")
```

Tras hacer varias pruebas con diferentes semillas e hiperparámetros, el algoritmo MMPC siempre selecciona en torno a **11 variables de 23** y son las siguientes:

```{r}
dput(names(air_prep[,c(MMPC@selectedVars)]))
```

## Algoritmo Boruta()

En quinto lugar, probaremos con el **algoritmo Boruta** del paquete `{Boruta}`.
Boruta es un algoritmo wrapper de selección de variables capaz de trabajar con cualquier método de clasificación que genere una **medida de la relevancia de las variables**.
Por defecto, Boruta usa Random Forest.
Comprobemos ahora cuáles decide seleccionar de nuestra receta:

```{r}
# Fijamos semilla
set.seed(12346)

# Aplicación del algoritmo Boruta
Boruta <- 
  Boruta(Satisfaction~., data = air_prep)

# Extracción de las variables
Boruta_select <-
  data.frame(Boruta$finalDecision)

Boruta_select <-
  Boruta_select[which(Boruta_select$Boruta.finalDecision=="Confirmed"),,drop=FALSE]
```

Tras hacer varias pruebas con diferentes semillas e hiperparámetros, el algoritmo Boruta siempre selecciona en torno a **31 de 32 variables** y son las siguientes:

```{r}
dput(row.names(Boruta_select))
```

## Criterio de información AIC

Para la selección de modelos con AIC y BIC, pasaremos directamente la receta a `glm()` para proceder a la regresión contra las variables escogidas.

```{r}
# Modificamos Satisfaction a factor
air_prep <- air_prep |> mutate_at(vars(Satisfaction), as.factor)

# Ajuste
ajuste_air <- 
  glm(data = air_prep, Satisfaction ~ ., family = binomial(link = "logit"))
ajuste_null <- 
  glm(data = air_prep, Satisfaction ~ 1, family = binomial(link = "logit"))
```

En sexto lugar, probaremos con el **método de selección de modelos AIC (Criterio de Información de Akaike)** a través de la función `stepAIC` del paquete `{MASS}`.
El AIC es un **método de selección de modelos** que evalúa la calidad de cada modelo y **penaliza** aquellos que son demasiado complejos.
La función `stepAIC` utiliza el AIC para **comparar modelos con diferentes conjuntos de variables** explicativas y seleccionar el mejor de ellos.
Comprobemos ahora cuáles decide seleccionar de nuestra receta:

```{r results='hide'}
# Fijamos semilla
set.seed(12346)

# Aplicación del stepAIC para el criterio AIC
AIC <-
  MASS::stepAIC(ajuste_null, scope = list(upper = ajuste_air), 
                direction="both", family = binomial(link = "logit"))
```

Resumimos la selección tras su procesado con `summary()`:

```{r}
# Extracción de las variables
AIC_vars <- (names(AIC[[1]]))
dput(AIC_vars)
```

Tras hacer varias pruebas con diferentes semillas e hiperparámetros, la función `stepAIC()` siempre selecciona en torno a **21 de 32 variables** variables.

## Criterio de información BIC

En séptimo lugar, emplearemos el **método de selección de modelos BIC (Criterio de Información de Bayesiana)** a través de la función `stepAIC` del paquete `{MASS}`.
Este método es muy similar al del Criterio de Información de Akaike, con la diferencia de que BIC introduce un componente penalizador a la complejidad del modelo más contundente.
Para su cálculo, aplicaremos a la función `stepAIC` una **penalización** a través del hiperparámetro `k`.
Esta penalización es igual al **logaritmo del número de filas de nuestro dataset**.
Comprobemos ahora cuáles decide seleccionar de nuestra receta:

```{r results='hide'}
#Fijamos semilla
set.seed(12346)

# Aplicación del stepAIC con la penalización del criterio BIC
BIC <-
  MASS::stepAIC(ajuste_null, scope = list(upper = ajuste_air), 
                direction="both", family = binomial(link = "logit"), 
                k = log(nrow(air_prep)))
```

Resumimos la selección tras su procesado con `summary()`:

```{r}
# Extracción de las variables
BIC_vars <- (names(BIC[[1]]))
dput(BIC_vars)
```

Tras hacer varias pruebas con diferentes semillas e hiperparámetros, la función `stepAIC()` **en su versión BIC** siempre selecciona en torno a **14 de 32 variables** variables.

## Step repetido con el Criterio de Información AIC

Por último, probaremos las funciones `steprepetidobinaria()` propuestas por el profesor tanto para el **Criterio de Información AIC**, como el **BIC**.
Comprobemos ahora cuáles decide seleccionar de nuestra receta:

```{r}
# Cargamos la fuente de la función
source("/Users/leztin/Library/Mobile Documents/com~apple~CloudDocs/Universidad/Máster/Segundo cuatrimestre/Técnicas de Machine Learning/Tema 6/funcion steprepetido binaria.R")
air_prep$Satisfaction <- ifelse(air_prep$Satisfaction == 1, "Yes", "No")

# Inicializamos la paralelización
clusters <- detectCores() - 1
make_cluster <- makeCluster(clusters)
registerDoParallel(make_cluster)

#Fijamos semilla
set.seed(12346)

# Aplicación del step repetido con AIC
Repetido_AIC <-
  steprepetidobinaria(data = air_prep, vardep = c("Satisfaction"),
               listconti = c("Age", "Distance", "Departure_Delay", "Gender_Male", 
                             "Customer_Loyal.Customer", "Travel_Personal.Travel", "Class_Eco.Plus", 
                             "WiFi_Sat_X1", "WiFi_Sat_X2", "Dep_Arr_Sat_X2", "Dep_Arr_Sat_X3", 
                             "Gate_Sat_X2", "Gate_Sat_X3", "Food_Sat_X1", "Food_Sat_X3", "Online_Board_Sat_X1", 
                             "Online_Board_Sat_X3", "Seat_Sat_X2", "Seat_Sat_X3", "Entertainment_Sat_X2", 
                             "Entertainment_Sat_X3", "On_board_Sat_X2", "On_board_Sat_X3", 
                             "Leg_Sat_X2", "Leg_Sat_X3", "Baggage_Sat_X2", "Baggage_Sat_X3", 
                             "Checkin_Sat_X2", "Checkin_Sat_X3", "Inflight_Sat_X2", "Inflight_Sat_X3"),
               sinicio = 12346, sfinal = 12385, porcen = 0.8, criterio = "AIC")
```

Tras hacer varias pruebas con diferentes semillas e hiperparámetros, la función `steprepetidobinaria()` **en su versión AIC** siempre selecciona en torno a **20 de 32 variables** variables.
Se han seleccionado dos sets:

```{r}
dput(Repetido_AIC[[2]][[1]])
```

Y el segundo set:

```{r}
dput(Repetido_AIC[[2]][[2]])
```

## Step repetido con el Criterio de Información BIC

Repetimos de nuevo pero ahora a partir del **Criterio de Información BIC**:

```{r}
#Fijamos semilla
set.seed(12346)

# Aplicación del step repetido con BIC
Repetido_BIC <-
  steprepetidobinaria(data = air_prep, vardep = c("Satisfaction"),
               listconti = c("Age", "Distance", "Departure_Delay", "Gender_Male", 
                             "Customer_Loyal.Customer", "Travel_Personal.Travel", "Class_Eco.Plus", 
                             "WiFi_Sat_X1", "WiFi_Sat_X2", "Dep_Arr_Sat_X2", "Dep_Arr_Sat_X3", 
                             "Gate_Sat_X2", "Gate_Sat_X3", "Food_Sat_X1", "Food_Sat_X3", "Online_Board_Sat_X1", 
                             "Online_Board_Sat_X3", "Seat_Sat_X2", "Seat_Sat_X3", "Entertainment_Sat_X2", 
                             "Entertainment_Sat_X3", "On_board_Sat_X2", "On_board_Sat_X3", 
                             "Leg_Sat_X2", "Leg_Sat_X3", "Baggage_Sat_X2", "Baggage_Sat_X3", 
                             "Checkin_Sat_X2", "Checkin_Sat_X3", "Inflight_Sat_X2", "Inflight_Sat_X3"),
               sinicio = 12346, sfinal = 12385, porcen = 0.8, criterio = "BIC")
```

Tras hacer varias pruebas con diferentes semillas e hiperparámetros, la función `steprepetidobinaria()` **en su versión BIC** siempre selecciona en torno a **13 - 14 de 32 variables** variables.
Se han seleccionado dos sets:

```{r}
dput(Repetido_BIC[[2]][[1]])
```

Y el segundo set:

```{r}
dput(Repetido_BIC[[2]][[2]])
```

Una vez probados todos los métodos de selección, finalizamos los procesos de paralelización del ordenador.

```{r}
# Finalizamos la paralelización
stopCluster(make_cluster)
registerDoSEQ()
```

# Fase 7.2: Regresión logística: comparación de los criterios de selección

## Configuración inicial de los modelos de regresión logística para cada criterio de selección

A continuación procedemos a comparar cada set de variables de cada uno de los criterios de selección a través de distintas **regresiones logísticas con validación cruzada repetida** (función `cruzadalogistica()`).
Se ha optado por aplicar **25 repeticiones por regresión** (con el hiperparámetro `repe =`), y, como hasta ahora, **se han probado distintas semillas a fin de cerciorarnos de la verdadera medida del error de los distintos modelos**.

```{r}
# Cargamos la fuente de la función
source("/Users/leztin/Library/Mobile Documents/com~apple~CloudDocs/Universidad/Máster/Segundo cuatrimestre/Técnicas de Machine Learning/Tema 6/cruzadas avnnet y log binaria.R")

air_prep_matrix <- air_prep |> as.data.frame()

# Calculamos las regresiones logísticas con los distintos sets de variables de los distintos algoritmos
graf_SBF <- 
  cruzadalogistica(data = air_prep_matrix, vardep = "Satisfaction", 
             listconti = c("Age", "Distance", "Departure_Delay", "Customer_Loyal.Customer", 
                           "Travel_Personal.Travel", "Class_Eco.Plus", "WiFi_Sat_X1", "WiFi_Sat_X2", 
                           "Dep_Arr_Sat_X3", "Gate_Sat_X2", "Gate_Sat_X3", "Food_Sat_X1", 
                           "Food_Sat_X3", "Online_Board_Sat_X1", "Online_Board_Sat_X3", 
                           "Seat_Sat_X2", "Seat_Sat_X3", "Entertainment_Sat_X2", "Entertainment_Sat_X3", 
                           "On_board_Sat_X2", "On_board_Sat_X3", "Leg_Sat_X2", "Leg_Sat_X3",
                           "Baggage_Sat_X2", "Baggage_Sat_X3", "Checkin_Sat_X3", "Inflight_Sat_X2",
                           "Inflight_Sat_X3"),
             listclass = c(""), grupos = 4, sinicio = 12346, repe = 25)

graf_SBF$Modelo = "Reg. logist. \n Filtro SBF"
graf_SBF$N_variables = "28"

graf_RFE <- 
  cruzadalogistica(data = air_prep_matrix, vardep = "Satisfaction", 
             listconti = c("WiFi_Sat_X1", "Travel_Personal.Travel", "Online_Board_Sat_X1", 
                           "Class_Eco.Plus", "Customer_Loyal.Customer", "Entertainment_Sat_X3", 
                           "Online_Board_Sat_X3", "Seat_Sat_X3", "Baggage_Sat_X3", "Age", 
                           "Checkin_Sat_X3", "Inflight_Sat_X3"),
             listclass = c(""), grupos = 4, sinicio = 12346, repe = 25)

graf_RFE$Modelo = "Reg. logist. \n Wrapper RFE"
graf_RFE$N_variables = "12"

graf_SES <- 
  cruzadalogistica(data = air_prep_matrix, vardep = "Satisfaction", 
             listconti = c("Customer_Loyal.Customer", "Travel_Personal.Travel", "Class_Eco.Plus", 
                           "WiFi_Sat_X1", "Online_Board_Sat_X1", "Online_Board_Sat_X3", 
                           "Entertainment_Sat_X3", "On_board_Sat_X3", "Leg_Sat_X2", "Leg_Sat_X3", 
                           "Checkin_Sat_X3"),
             listclass = c(""), grupos = 4, sinicio = 12346, repe = 25)

graf_SES$Modelo = "Reg. logist. \n Algoritmo SES"
graf_SES$N_variables = "11"

graf_MMPC <- 
  cruzadalogistica(data = air_prep_matrix, vardep = "Satisfaction", 
             listconti = c("Customer_Loyal.Customer", "Travel_Personal.Travel", "Class_Eco.Plus", 
                           "WiFi_Sat_X1", "Online_Board_Sat_X1", "Online_Board_Sat_X3", 
                           "Entertainment_Sat_X3", "On_board_Sat_X3", "Leg_Sat_X2", "Leg_Sat_X3", 
                           "Checkin_Sat_X3"),
             listclass = c(""), grupos = 4, sinicio = 12346, repe = 25)

graf_MMPC$Modelo = "Reg. logist. \n Algoritmo MMPC"
graf_MMPC$N_variables = "11"

graf_Boruta <- 
  cruzadalogistica(data = air_prep_matrix, vardep = "Satisfaction", 
             listconti = c("Age", "Distance", "Departure_Delay", "Gender_Male", "Customer_Loyal.Customer",
                           "Travel_Personal.Travel", "Class_Eco.Plus", "WiFi_Sat_X1", "WiFi_Sat_X2", 
                           "Dep_Arr_Sat_X2", "Dep_Arr_Sat_X3", "Gate_Sat_X2", "Gate_Sat_X3", 
                           "Food_Sat_X1", "Food_Sat_X3", "Online_Board_Sat_X1", "Online_Board_Sat_X3", 
                           "Seat_Sat_X2", "Seat_Sat_X3", "Entertainment_Sat_X2", "Entertainment_Sat_X3", 
                           "On_board_Sat_X2", "On_board_Sat_X3", "Leg_Sat_X2", "Leg_Sat_X3", 
                           "Baggage_Sat_X2", "Baggage_Sat_X3", "Checkin_Sat_X2", "Checkin_Sat_X3", 
                           "Inflight_Sat_X2", "Inflight_Sat_X3"),
             listclass = c(""), grupos = 4, sinicio = 12346, repe = 25)

graf_Boruta$Modelo = "Reg. logist. \n Algoritmo Boruta"
graf_Boruta$N_variables = "31"

graf_AIC <- 
  cruzadalogistica(data = air_prep_matrix, vardep = "Satisfaction", 
             listconti = c("Online_Board_Sat_X1", "Travel_Personal.Travel", 
                           "WiFi_Sat_X1", "Customer_Loyal.Customer", "WiFi_Sat_X2", "Baggage_Sat_X3", 
                           "Baggage_Sat_X2", "Class_Eco.Plus", "Online_Board_Sat_X3", "Checkin_Sat_X3", 
                           "Dep_Arr_Sat_X3", "Seat_Sat_X3", "Inflight_Sat_X3", "Checkin_Sat_X2", 
                           "Gate_Sat_X3", "Food_Sat_X1", "Distance", "Departure_Delay", 
                           "On_board_Sat_X3", "Leg_Sat_X2", "Leg_Sat_X3"),
             listclass = c(""), grupos = 4, sinicio = 12346, repe = 25)

graf_AIC$Modelo = "Reg. logist. \n Criterio AIC"
graf_AIC$N_variables = "21"

graf_BIC <- 
  cruzadalogistica(data = air_prep_matrix, vardep = "Satisfaction", 
             listconti = c("Online_Board_Sat_X1", "Travel_Personal.Travel", 
                           "WiFi_Sat_X1", "Customer_Loyal.Customer", "WiFi_Sat_X2", "Baggage_Sat_X3", 
                           "Baggage_Sat_X2", "Class_Eco.Plus", "Online_Board_Sat_X3", "Checkin_Sat_X3", 
                           "Dep_Arr_Sat_X3", "Seat_Sat_X3", "Inflight_Sat_X3", "Checkin_Sat_X2"),
             listclass = c(""), grupos = 4, sinicio = 12346, repe = 25)

graf_BIC$Modelo = "Reg. logist. \n Criterio BIC"
graf_BIC$N_variables = "14"

graf_repetido_AIC_set1 <- 
  cruzadalogistica(data = air_prep_matrix, vardep = "Satisfaction", 
             listconti = c("Online_Board_Sat_X1", "Travel_Personal.Travel", "WiFi_Sat_X1", 
                           "Customer_Loyal.Customer", "WiFi_Sat_X2", "Baggage_Sat_X3", "Baggage_Sat_X2", 
                           "Online_Board_Sat_X3", "Class_Eco.Plus", "Dep_Arr_Sat_X3", "Checkin_Sat_X3", 
                           "Seat_Sat_X3", "Checkin_Sat_X2", "Inflight_Sat_X3", "Gate_Sat_X3", 
                           "Inflight_Sat_X2", "Food_Sat_X1", "Departure_Delay", "Distance", 
                           "On_board_Sat_X3"),
             listclass = c(""), grupos = 4, sinicio = 12346, repe = 25)

graf_repetido_AIC_set1$Modelo = "Reg. logist. \n Step Repetido AIC (set 1)"
graf_repetido_AIC_set1$N_variables = "20"

graf_repetido_BIC_set1 <- 
  cruzadalogistica(data = air_prep_matrix, vardep = "Satisfaction", 
             listconti = c("Online_Board_Sat_X1", "Travel_Personal.Travel", "WiFi_Sat_X1", 
                           "Customer_Loyal.Customer", "WiFi_Sat_X2", "Baggage_Sat_X3", "Baggage_Sat_X2", 
                           "Class_Eco.Plus", "Checkin_Sat_X3", "Online_Board_Sat_X3", "Dep_Arr_Sat_X3", 
                           "Inflight_Sat_X3", "Seat_Sat_X3"),
             listclass = c(""), grupos = 4, sinicio = 12346, repe = 25)

graf_repetido_BIC_set1$Modelo = "Reg. logist. \n Step Repetido BIC (set 1)"
graf_repetido_BIC_set1$N_variables = "13"

graf_repetido_AIC_set2 <- 
  cruzadalogistica(data = air_prep_matrix, vardep = "Satisfaction", 
             listconti = c("Online_Board_Sat_X1", "Class_Eco.Plus", "WiFi_Sat_X1", "WiFi_Sat_X2", 
                           "Travel_Personal.Travel", "Customer_Loyal.Customer", "Checkin_Sat_X3", 
                           "Baggage_Sat_X3", "Baggage_Sat_X2", "Dep_Arr_Sat_X3", "Online_Board_Sat_X3", 
                           "Inflight_Sat_X3", "Checkin_Sat_X2", "Gate_Sat_X3", "Seat_Sat_X3", 
                           "Distance", "On_board_Sat_X3", "Departure_Delay", "Leg_Sat_X2", 
                           "Food_Sat_X1"),
             listclass = c(""), grupos = 4, sinicio = 12346, repe = 25)

graf_repetido_AIC_set2$Modelo = "Reg. logist. \n Step Repetido AIC (set 2)"
graf_repetido_AIC_set2$N_variables = "20"

graf_repetido_BIC_set2 <- 
  cruzadalogistica(data = air_prep_matrix, vardep = "Satisfaction", 
             listconti = c("Online_Board_Sat_X1", "Travel_Personal.Travel", "WiFi_Sat_X1", 
                           "Customer_Loyal.Customer", "WiFi_Sat_X2", "Baggage_Sat_X3", "Baggage_Sat_X2",
                           "Online_Board_Sat_X3", "Class_Eco.Plus", "Dep_Arr_Sat_X3", "Checkin_Sat_X3", 
                          "Seat_Sat_X3", "Checkin_Sat_X2", "Inflight_Sat_X3"),
             listclass = c(""), grupos = 4, sinicio = 12346, repe = 25)

graf_repetido_BIC_set2$Modelo="Reg. logist. \n Step Repetido BIC (set 2)"
graf_repetido_BIC_set2$N_variables = "14"
```

Una vez ejecutados los **11 modelos**, procedemos a **unirlos** todos en un dataframe para su posterior representación.

```{r}
# Unimos todos los valores en un dataframe
select_final <-
  rbind(graf_SBF, graf_RFE, graf_SES, graf_MMPC, graf_Boruta, graf_AIC, 
        graf_BIC, graf_repetido_AIC_set1, graf_repetido_BIC_set1, graf_repetido_BIC_set2,
        graf_repetido_AIC_set2)
```

## Representación de la tasa de fallos y del AUC de los modelos de regresión logística

A continuación generamos un `ggplot()` en modo boxplot que relacione cada **modelo** con su **error promedio**.
Se ha incluido también una **etiqueta** que especifica el **número de variables que contiene cada modelo**.

```{r layout="l-body-outset", fig.width=20, fig.asp = .99}
# Boxplot de la tasa de error para cada modelo
 a <- ggplot(data = select_final, aes(x = reorder(Modelo, tasa), y = tasa)) +
  geom_boxplot() +
  labs(x = NULL, y = "Tasa de error", title = "Distribución del error según los distintos modelos seleccionados") +
  theme_minimal() +
  theme(text = element_text(face = "bold", size = 15), plot.title = element_text(hjust = 0.5), 
        axis.title.x = element_text(vjust=-0.5)) +
  geom_label(aes(label = N_variables, y = 0.06), size = 6) +
  scale_x_discrete(guide = guide_axis(angle = 55))

# Boxplot de la tasa AUC para cada modelo
 b <- ggplot(data = select_final, aes(x = reorder(Modelo, -auc), y = auc)) +
  geom_boxplot() +
  labs(x = NULL, y = "AUC", title = "Distribución de la tasa AUC según los distintos modelos seleccionados") +
  theme_minimal() +
  theme(text = element_text(face = "bold", size = 15), plot.title = element_text(hjust = 0.5), 
        axis.title.x = element_text(vjust=-0.5)) +
  geom_label(aes(label = N_variables, y = 0.96), size = 6) +
  scale_x_discrete(guide = guide_axis(angle = 55))
 
 Rmisc::multiplot(a, b)
```

Todos los modelos ofrecen muy buenos resultados, pero teniendo en cuenta el *trade off* entre **el error del modelo y su complejidad**, representada por el número de variables, tenemos dos posibles candidatos:

1.  **Modelo propuesto por el Algoritmo MMPC:** Presenta un error medio de 0.09, un AUC de 0.96, y cuenta con tan solo **11 variables** de 32 totales.

2.  **Modelo propuesto por el Step Repetido con el Criterio de Información BIC (set 1):** Presenta un error medio de 0.07, un AUC de 0.97, y cuenta con **13 variables** de 32 totales.

De entre estos dos modelos, quizá el del **Algoritmo MMPC sea el mejor**: presenta **2 variables menos** que el del Criterio BIC, mientras que el error **aumenta tan solo en 0.02** puntos.
Aún así, para aportar variedad, probaremos en las siguientes fases a introducir ambos sets de variables en los **distintos modelos a aplicar**.

Además, conviene destacar cómo **la mayoría de modelos que ofrece la regresión logística presentan reducida varianza**.

```{r echo=FALSE}
graf_MMPC$Modelo = "Reg. logist. \n Primer set"
graf_repetido_BIC_set1$Modelo = "Reg. logist. \n Segundo set"
```

# Fase 7.3: Red neuronal: comparación de los criterios de selección

En este primer apartado, aplicaremos a ambos sets de variables un **modelo de red neuronal con parámetros tuneados según los nodos máximos de los modelos**.
Tras ello, **compararemos los resultados** para ver si **mejoran** los de la regresión logística

## Aplicación al primer set de variables (Algoritmo MMPC)

En este set tenemos **once variables**.
Si dividimos el total de las **observaciones** entre **30** (el número máximo promedio de observaciones por parámetro), resultarían **260 parámetros como máximo**.
Si aplicamos la fórmula $h = 260/(k + 2)$, siendo $k = 11$, Esto equivaldría a **20 nodos** para el tuneo como máximo.
Por otro lado, vamos también a incrementar las opciones del hiperparámetro `decay` con 0.01, 0.1, 0.001, 0.0001.
Por último, y tras varias pruebas, tunearemos las **iteraciones** con el parámetro `maxit` **desde las 10 hasta las 5000**.

```{r eval=FALSE}
#Fijamos semilla
set.seed(12346)

# Inicializamos la paralelización
clusters <- detectCores() - 1
make_cluster <- makeCluster(clusters)
registerDoParallel(make_cluster)

# Le indicamos validación cruzada repetida
control <- 
  trainControl(method = "repeatedcv", number = 5, savePredictions = "all")

# Creamos el grid tuneado
avnnetgrid <-
  expand.grid(size = c(5, 10, 15, 20), decay = c(0.01, 0.1, 0.001, 0.0001), 
              bag = FALSE)

# Lanzamos la función del modelo con 11 variables con iteraciones
completo_1 <- data.frame()
iteraciones <- c(10, 50, 200, 300, 500, 1000, 2000, 3000, 4000, 5000)

for (i in iteraciones)
{
  redavnnet_1 <- train(factor(Satisfaction)~Customer_Loyal.Customer+Travel_Personal.Travel+
                         Class_Eco.Plus+WiFi_Sat_X1+Online_Board_Sat_X1+Online_Board_Sat_X3+
                         Entertainment_Sat_X3+On_board_Sat_X3+Leg_Sat_X2+Leg_Sat_X3+Checkin_Sat_X3,
                       data=air_prep, method="avNNet",linout = FALSE, maxit = i,
                       trControl = control, repeats = 5, tuneGrid = avnnetgrid, trace = F)
  # Añado la columna del parámetro de iteraciones
  redavnnet_1$results$itera <- i
  # Voy incorporando los resultados a completo
  completo_1 <- rbind(completo_1, redavnnet_1$results)
}

redavnnet_1
pred_redavnnet_1 <-
  redavnnet_1$pred

# Finalizamos la paralelización
stopCluster(make_cluster)
registerDoSEQ()
```

Independientemente de lo que nos ofrezca `{caret}`, **vamos a graficar los valores** para todos los **nodos**, todas las **iteraciones** y todos los **decay** para elegir manualmente el modelo que consideremos **más estable**.

```{r eval = FALSE}
ggplot(completo_1, aes(x = factor(itera), y = Accuracy, 
                     color = factor(decay), pch = factor(size))) +
  geom_point(position = position_dodge(width = 0.5), size = 3) +
  theme_minimal()
```

```{r layout="l-body-outset", fig.width=50, fig.asp = .99, echo=FALSE}
knitr::include_graphics("/Users/leztin/Desktop/RED-1.png")  
```

Para no sobreajustar creando un modelo demasiado complejo, creo que me decantaré por los **15 nodos**.
Filtremos el gráfico por esta cantidad para determinar finalmente el **número de iteraciones** y el **decay**.

```{r eval=FALSE}
completo_1 |> 
  filter(size == 15) |> 
  ggplot(aes(x = factor(itera), y = Accuracy,
             color = factor(decay), pch = factor(size))) +
  geom_point(position = position_dodge(width = 0.5), size = 3) +
  theme_minimal()
```

```{r layout="l-body-outset", fig.width=50, fig.asp = .99, echo=FALSE}
knitr::include_graphics("/Users/leztin/Desktop/RED-1-(DETALLE).png")  
```

No parece necesario incrementar a tal nivel las iteraciones, **a partir de las 300 parece que empeora ligeramente**.
Vamos a quedarnos finalmente con **15 nodos**, **300 iteraciones** y **0.1 de decay**.
En este sentido, el modelo parece estabilizarse en torno a un $Accuracy$ del **92 %**.
Conviene recordar cómo **se han probado distintas combinaciones de hiperparámetros con diferentes semillas** y siempre alcanzamos la misma horquilla ($Accuracy = 90-91 %$).

Como se puede observar, los resultados son **un poco peores que con la regresión logística**.
Este dataset parece responder mejor a la **separación lineal** provista por los métodos tradicionales de regresión.
A continuación probaremos a tunear nuestro segundo set de variables.

## Aplicación al segundo set de variables (Step repetido con el Criterio de Información BIC)

En este segundo set tenemos **trece variables**.
Si dividimos el total de las **observaciones** entre **30** (el número máximo promedio de observaciones por parámetro), resultarían **260 parámetros como máximo**.
Si aplicamos la fórmula $h = 260/(k + 2)$, siendo $k = 13$, Esto equivaldría a **17 nodos** para el tuneo como máximo.
Por otro lado, vamos también a incrementar las opciones del hiperparámetro `decay` con 0.01, 0.1, 0.001, 0.0001.
Por último, y tras varias pruebas, tunearemos las **iteraciones** con el parámetro `maxit` **desde las 10 hasta las 5000**.

```{r eval=FALSE}
#Fijamos semilla
set.seed(12346)

# Inicializamos la paralelización
clusters <- detectCores() - 1
make_cluster <- makeCluster(clusters)
registerDoParallel(make_cluster)

# Le indicamos validación cruzada repetida
control <- 
  trainControl(method = "repeatedcv", number = 5, savePredictions = "all")

# Creamos el grid tuneado
avnnetgrid <-
  expand.grid(size = c(5, 10, 15, 17), decay = c(0.01, 0.1, 0.001, 0.0001), 
              bag = FALSE)

# Lanzamos la función del modelo de 13 variables con iteraciones
completo_2 <- data.frame()
iteraciones <- c(10, 50, 200, 300, 500, 1000, 2000, 3000, 4000, 5000)

for (i in iteraciones)
{
  redavnnet_2 <- train(factor(Satisfaction)~Online_Board_Sat_X1+Travel_Personal.Travel+
                         WiFi_Sat_X1+Customer_Loyal.Customer+WiFi_Sat_X2+Baggage_Sat_X3+
                         +Baggage_Sat_X2+Class_Eco.Plus+Checkin_Sat_X3+Online_Board_Sat_X3+
                         Dep_Arr_Sat_X3+Inflight_Sat_X3+Seat_Sat_X3,
                    data=air_prep, method="avNNet",linout = TRUE, maxit = i,
                    trControl = control, repeats = 5, tuneGrid = avnnetgrid, trace = F)
  # Añado la columna del parámetro de iteraciones
  redavnnet_2$results$itera <- i
  # Voy incorporando los resultados a completo
  completo_2 <- rbind(completo_2, redavnnet_2$results)
}

redavnnet_2
pred_redavnnet_2 <-
  redavnnet_2$pred

# Finalizamos la paralelización
stopCluster(make_cluster)
registerDoSEQ()
```

De nuevo, independientemente de lo que nos ofrezca `{caret}`, **vamos a graficar los valores** para todos los **nodos**, todas las **iteraciones** y todos los **decay** para elegir manualmente el modelo que consideremos **más estable**.

```{r eval=FALSE}
ggplot(completo_2, aes(x = factor(itera), y = Accuracy, 
                     color = factor(decay), pch = factor(size))) +
  geom_point(position = position_dodge(width = 0.5), size = 3) +
  theme_minimal()
```

```{r layout="l-body-outset", fig.width=50, fig.asp = .99, echo=FALSE}
knitr::include_graphics("/Users/leztin/Desktop/RED-2.png")  
```

Al igual que en el anterior apartado, para no sobreajustar creando un modelo demasiado complejo, me decantaré esta vez por los **10 nodos**.
Filtremos el gráfico por esta cantidad para determinar finalmente el **número de iteraciones** y el **decay**.

```{r eval=FALSE}
completo_2 |> 
  filter(size == 10) |> 
  ggplot(aes(x = factor(itera), y = Accuracy,
             color = factor(decay), pch = factor(size))) +
  geom_point(position = position_dodge(width = 0.5), size = 3) +
  theme_minimal()
```

```{r layout="l-body-outset", fig.width=50, fig.asp = .99, echo=FALSE}
knitr::include_graphics("/Users/leztin/Desktop/RED-2-(DETALLE).png")  
```

Para este caso, vamos a quedarnos finalmente con **10 nodos**, **1000 iteraciones** y **0.1 de decay**.
El modelo parece estabilizarse en torno a un $Accuracy$ del **92-93 %**.
A nivel de resultados, este segundo set de variables es **mejor**: ofrece una **mayor precisión**, pero también a costa de incluir un **mayor número de variables** (de 11 variables que teníamos en el primer set a 13 en este último).
Las diferencias tanto en error como en variabilidad explicada **no son excesivamente significativas**.
A continuación, realizaremos una **comparativa parcial** entre ambos modelos.

Antes de ello, fijamos los mejores parámetros que hemos seleccionado para ambos modelos con la función `{cruzadaavnnetbin}`:

```{r cache = TRUE}
#Fijamos semilla
set.seed(12346)

# Inicializamos la paralelización
clusters <- detectCores() - 1
make_cluster <- makeCluster(clusters)
registerDoParallel(make_cluster)

Red_MMPC_tun <-
  cruzadaavnnetbin(data = air_prep, vardep = "Satisfaction",
                listconti = c("Customer_Loyal.Customer", "Travel_Personal.Travel", "Class_Eco.Plus", 
                           "WiFi_Sat_X1", "Online_Board_Sat_X1", "Online_Board_Sat_X3", 
                           "Entertainment_Sat_X3", "On_board_Sat_X3", "Leg_Sat_X2", "Leg_Sat_X3", 
                           "Checkin_Sat_X3"),
                listclass = c(""), grupos = 4, sinicio = 12346, repe = 25, repeticiones = 5,
                itera = 300, size = c(15), decay = c(0.1))

Red_MMPC_tun$Modelo = "Red neuronal tuneada \n Primer set"
Red_MMPC_tun$N_variables = "11"


Red_step_BIC_tun <-
  cruzadaavnnetbin(data = air_prep, vardep = "Satisfaction",
                listconti = c("Online_Board_Sat_X1", "Travel_Personal.Travel", "WiFi_Sat_X1", 
                           "Customer_Loyal.Customer", "WiFi_Sat_X2", "Baggage_Sat_X3", "Baggage_Sat_X2", 
                           "Class_Eco.Plus", "Checkin_Sat_X3", "Online_Board_Sat_X3", "Dep_Arr_Sat_X3", 
                           "Inflight_Sat_X3", "Seat_Sat_X3"),
                listclass = c(""), grupos = 4, sinicio = 12346, repe = 25, repeticiones = 5,
                itera = 1000, size = c(10), decay = c(0.1))

Red_step_BIC_tun$Modelo = "Red neuronal tuneada \n Segundo set"
Red_step_BIC_tun$N_variables = "13"

# Finalizamos la paralelización
stopCluster(make_cluster)
registerDoSEQ()
```

## Comparativa parcial entre los modelos elaborados hasta el momento

```{r}
# Unimos todos los valores en un dataframe
select_final <-
  rbind(graf_MMPC, graf_repetido_BIC_set1, Red_MMPC_tun, Red_step_BIC_tun)
```

```{r layout="l-body-outset", fig.width=15, fig.asp = .99}
# Boxplot de la tasa de error para cada modelo
 a <- ggplot(data = select_final, aes(x = reorder(Modelo, tasa), y = tasa)) +
  geom_boxplot() +
  labs(x = NULL, y = "Tasa de error", title = "Distribución del error según los distintos modelos seleccionados") +
  theme_minimal() +
  theme(text = element_text(face = "bold", size = 15), plot.title = element_text(hjust = 0.5), 
        axis.title.x = element_text(vjust=-0.5)) +
  geom_label(aes(label = N_variables, y = 0.06), size = 6) +
  scale_x_discrete(guide = guide_axis(angle = 55))

# Boxplot de la tasa AUC para cada modelo
 b <- ggplot(data = select_final, aes(x = reorder(Modelo, -auc), y = auc)) +
  geom_boxplot() +
  labs(x = NULL, y = "AUC", title = "Distribución de la tasa AUC según los distintos modelos seleccionados") +
  theme_minimal() +
  theme(text = element_text(face = "bold", size = 15), plot.title = element_text(hjust = 0.5), 
        axis.title.x = element_text(vjust=-0.5)) +
  geom_label(aes(label = N_variables, y = 0.96), size = 6) +
  scale_x_discrete(guide = guide_axis(angle = 55))
 
Rmisc::multiplot(a, b)
```

A simple vista ya se puede observar cómo **los modelos de red neuronal mejoran en cierta medida a los modelos de regresión logística** aunque, de nuevo, **a costa de incrementar su varianza**.
Aún con todo parece merecer la pena.
Con la red neuronal, el segundo set de variables ha alcanzado un **93 % de accuracy** y un **AUC del 98.5 %**.
El error **también ha disminuido** respecto del resto de modelos, aunque **a costa de incrementar ligeramente la varianza**.

Seguiremos probando a continuación **nuevos modelos** para ver si **podemos mejorar el resultado**.

# Fase 7.4: Bagging: comparación de los criterios de selección

En este segundo apartado, aplicaremos a ambos sets de variables un **modelo bagging según el número de variables independientes (predictoras) de cada set**.
Tras ello, **compararemos los resultados** para ver si **mejoran** los resultados de los anteriores modelos.

## Aplicación al primer set de variables (Algoritmo MMPC)

En este set tenemos **once variables**, por lo que el parámetro `mtry` **será igual a 11**.
Tras hacer varias pruebas con diferentes semillas, he decidido implementar un número máximo de árboles de **5000** (`ntree`).
Además, he mantenido el parámetro `nodesize` en **10**, que es el que **mejores resultados ofrecía**.

```{r eval=FALSE}
#Fijamos semilla
set.seed(12346)

# Inicializamos la paralelización
clusters <- detectCores() - 1
make_cluster <- makeCluster(clusters)
registerDoParallel(make_cluster)

# Le indicamos validación cruzada repetida
control <- 
  trainControl(method = "repeatedcv",number=5,savePredictions = "all",
               classProbs=TRUE) 

# Creamos el grid tuneado de nuestras 11 variables para este primer set
bagginggrid <-
  expand.grid(mtry=c(11))

# Lanzamos la función del modelo con 11 variables con iteraciones
bagging <- 
  train(data=air_prep,factor(Satisfaction)~Customer_Loyal.Customer+Travel_Personal.Travel+
                         Class_Eco.Plus+WiFi_Sat_X1+Online_Board_Sat_X1+Online_Board_Sat_X3+
                         Entertainment_Sat_X3+On_board_Sat_X3+Leg_Sat_X2+Leg_Sat_X3+Checkin_Sat_X3,
        method="rf",trControl=control,tuneGrid=bagginggrid,
        linout = FALSE,ntree=5000,nodesize=10,repeats=5,replace=TRUE, importance=T)
bagging

# Finalizamos la paralelización
stopCluster(make_cluster)
registerDoSEQ()
```

```{r layout="l-body-outset", fig.width=50, fig.asp = .99, echo=FALSE}
knitr::include_graphics("/Users/leztin/Desktop/Captura de pantalla 2023-05-16 a las 18.26.14.png")  
```

El modelo bagging, con `mtry = 11` (número total de predictoras), ofrece un **accuracy del 90.56 %**.
Comprobemos a continuación el error a través de la siguiente función.

Para conocer cómo tunear el parámetro `sampsize`, vamos a calcular su **máximo** en función de las **dimensiones de la muestra con la que estamos trabajando**.
El tamaño de nuestra muestra es de **2077 tuplas**, por lo que la fórmula quedaría tal que así: $(3/4)*2077=1558$.
A continuación, tunearemos el parámetro con un nivel medio sin superar nuestro máximo, **en torno a 1000**.

```{r eval=FALSE}
# Fijamos semilla
set.seed(1234)

# Lanzamos el modelo
rfbis <- randomForest(factor(Satisfaction)~Customer_Loyal.Customer+Travel_Personal.Travel+
                         Class_Eco.Plus+WiFi_Sat_X1+Online_Board_Sat_X1+Online_Board_Sat_X3+
                         Entertainment_Sat_X3+On_board_Sat_X3+Leg_Sat_X2+Leg_Sat_X3+Checkin_Sat_X3,
                    data=air_prep,
                    mtry=11,ntree=5000,sampsize=1000,nodesize=10,replace=TRUE)

# Ploteamos el modelo
plot(rfbis$err.rate[,1])
```

```{r layout="l-body-outset", fig.width=50, fig.asp = .99, echo=FALSE}
knitr::include_graphics("/Users/leztin/Desktop/Captura de pantalla 2023-05-16 a las 18.27.54.png")  
```

En el gráfico podemos observar cómo, **a medida que aumenta el número de árboles, el error se va estabilizando** (con un pequeño bache entre las 2000 y 3000).
Al principio aumenta enormemente, pero **a medida que avanzan las iteraciones se va estabilizando**.
Con `ntree = 1000` parece alcanzarse el menor error.

Comprobemos esta misma configuración para el **segundo set de variables**.

## Aplicación al segundo set de variables (Step repetido con el Criterio de Información BIC)

En este set tenemos **trece variables**, por lo que el parámetro `mtry` **será igual a 13**.
Tras hacer varias pruebas con diferentes semillas, he decidido implementar un número máximo de árboles de **5000** (`ntree`).
Además, he mantenido el parámetro `nodesize` en **10**, que es el que **mejores resultados ofrecía**.

```{r eval=FALSE}
#Fijamos semilla
set.seed(12346)

# Inicializamos la paralelización
clusters <- detectCores() - 1
make_cluster <- makeCluster(clusters)
registerDoParallel(make_cluster)

# Le indicamos validación cruzada repetida
control <- 
  trainControl(method = "repeatedcv",number=5,savePredictions = "all",
               classProbs=TRUE) 

# Creamos el grid tuneado de nuestras 13 variables para este primer set
bagginggrid <-
  expand.grid(mtry=c(13))

# Lanzamos la función del modelo con 13 variables con iteraciones
bagging2 <- 
  train(data=air_prep,factor(Satisfaction)~Online_Board_Sat_X1+Travel_Personal.Travel+
                         WiFi_Sat_X1+Customer_Loyal.Customer+WiFi_Sat_X2+Baggage_Sat_X3+
                         +Baggage_Sat_X2+Class_Eco.Plus+Checkin_Sat_X3+Online_Board_Sat_X3+
                         Dep_Arr_Sat_X3+Inflight_Sat_X3+Seat_Sat_X3,
        method="rf",trControl=control,tuneGrid=bagginggrid,
        linout = FALSE,ntree=5000,nodesize=10,repeats=5,replace=TRUE, importance=T)
bagging2

# Finalizamos la paralelización
stopCluster(make_cluster)
registerDoSEQ()
```

```{r layout="l-body-outset", fig.width=50, fig.asp = .99, echo=FALSE}
knitr::include_graphics("/Users/leztin/Desktop/Captura de pantalla 2023-05-16 a las 18.29.30.png")  
```

El modelo bagging, con `mtry = 13` (número total de predictoras), ofrece un **accuracy del 91.62 %**.
Comprobemos a continuación el error a través de la siguiente función.

Para conocer cómo tunear el parámetro `sampsize`, vamos a calcular su **máximo** en función de las **dimensiones de la muestra con la que estamos trabajando**.
El tamaño de nuestra muestra es de **2077 tuplas**, por lo que la fórmula quedaría tal que así: $(3/4)*2077=1558$.
A continuación, tunearemos el parámetro con un nivel medio, **en torno a 1000**.

```{r eval=FALSE}
# Fijamos semilla
set.seed(12223)

# Lanzamos el modelo
rfbis <- randomForest(factor(Satisfaction)~Online_Board_Sat_X1+Travel_Personal.Travel+
                         WiFi_Sat_X1+Customer_Loyal.Customer+WiFi_Sat_X2+Baggage_Sat_X3+
                         +Baggage_Sat_X2+Class_Eco.Plus+Checkin_Sat_X3+Online_Board_Sat_X3+
                         Dep_Arr_Sat_X3+Inflight_Sat_X3+Seat_Sat_X3,
                    data=air_prep,
                    mtry=13,ntree=5000,sampsize=1000,nodesize=10,replace=TRUE)

# Ploteamos el modelo
plot(rfbis$err.rate[,1])
```

```{r layout="l-body-outset", fig.width=50, fig.asp = .99, echo=FALSE}
knitr::include_graphics("/Users/leztin/Desktop/Captura de pantalla 2023-05-16 a las 18.32.03.png")  
```

De nuevo, en el gráfico podemos observar cómo, **a medida que aumenta el número de árboles, el error se va estabilizando**.
Al principio aumenta enormemente, pero **a medida que avanzan las iteraciones se va estabilizando**.
De nuevo, con `ntree = 500` parece alcanzarse el menor error.

## Tuneado del parámetro `sampsize`: primer set de variables

A continuación, fijamos los mejores parámetros y **probamos el parámetro** `sampsize` **hasta el máximo que habíamos calculado (1558)** para ambos modelos con la función `{cruzadarfbin}`:

```{r eval=FALSE}
source ("/Users/leztin/Library/Mobile Documents/com~apple~CloudDocs/Universidad/Máster/Segundo cuatrimestre/Técnicas de Machine Learning/Tema 7/cruzada rf binaria.R")

# Inicializamos la paralelización
clusters <- detectCores() - 1
make_cluster <- makeCluster(clusters)
registerDoParallel(make_cluster)

Bag_MMPC_1 <- cruzadarfbin(data=air_prep, vardep="Satisfaction",
                           listconti=c("Customer_Loyal.Customer", "Travel_Personal.Travel",
                                       "Class_Eco.Plus", "WiFi_Sat_X1", "Online_Board_Sat_X1",
                                       "Online_Board_Sat_X3", "Entertainment_Sat_X3", "On_board_Sat_X3",
                                       "Leg_Sat_X2", "Leg_Sat_X3", "Checkin_Sat_X3"),
                           listclass=c(""),
                           grupos=5,sinicio=1234,repe=5,nodesize=10,
                           mtry=11,ntree=1000,replace=TRUE,sampsize=100)

Bag_MMPC_1$Modelo = "Bagging tuneado (100) \n Primer set"
    
Bag_MMPC_2 <- cruzadarfbin(data=air_prep, vardep="Satisfaction",
                           listconti=c("Customer_Loyal.Customer", "Travel_Personal.Travel",
                                       "Class_Eco.Plus", "WiFi_Sat_X1", "Online_Board_Sat_X1",
                                       "Online_Board_Sat_X3", "Entertainment_Sat_X3", "On_board_Sat_X3",
                                       "Leg_Sat_X2", "Leg_Sat_X3", "Checkin_Sat_X3"),
                           listclass=c(""),
                           grupos=5,sinicio=1234,repe=5,nodesize=10,
                           mtry=11,ntree=1000,replace=TRUE,sampsize=300)

Bag_MMPC_2$Modelo = "Bagging tuneado (300) \n Primer set"
    
Bag_MMPC_3 <- cruzadarfbin(data=air_prep, vardep="Satisfaction",
                           listconti=c("Customer_Loyal.Customer", "Travel_Personal.Travel",
                                       "Class_Eco.Plus", "WiFi_Sat_X1", "Online_Board_Sat_X1",
                                       "Online_Board_Sat_X3", "Entertainment_Sat_X3", "On_board_Sat_X3",
                                       "Leg_Sat_X2", "Leg_Sat_X3", "Checkin_Sat_X3"),
                           listclass=c(""),
                           grupos=5,sinicio=1234,repe=5,nodesize=10,
                           mtry=11,ntree=1000,replace=TRUE,sampsize=500)

Bag_MMPC_3$Modelo = "Bagging tuneado (500) \n Primer set"

Bag_MMPC_4 <- cruzadarfbin(data=air_prep, vardep="Satisfaction",
                           listconti=c("Customer_Loyal.Customer", "Travel_Personal.Travel",
                                       "Class_Eco.Plus", "WiFi_Sat_X1", "Online_Board_Sat_X1",
                                       "Online_Board_Sat_X3", "Entertainment_Sat_X3", "On_board_Sat_X3",
                                       "Leg_Sat_X2", "Leg_Sat_X3", "Checkin_Sat_X3"),
                           listclass=c(""),
                           grupos=5,sinicio=1234,repe=5,nodesize=10,
                           mtry=11,ntree=1000,replace=TRUE,sampsize=700)

Bag_MMPC_4$Modelo = "Bagging tuneado (700) \n Primer set"

Bag_MMPC_5 <- cruzadarfbin(data=air_prep, vardep="Satisfaction",
                           listconti=c("Customer_Loyal.Customer", "Travel_Personal.Travel",
                                       "Class_Eco.Plus", "WiFi_Sat_X1", "Online_Board_Sat_X1",
                                       "Online_Board_Sat_X3", "Entertainment_Sat_X3", "On_board_Sat_X3",
                                       "Leg_Sat_X2", "Leg_Sat_X3", "Checkin_Sat_X3"),
                           listclass=c(""),
                           grupos=5,sinicio=1234,repe=5,nodesize=10,
                           mtry=11,ntree=1000,replace=TRUE,sampsize=1000)

Bag_MMPC_5$Modelo = "Bagging tuneado (1000) \n Primer set"

Bag_MMPC_6 <- cruzadarfbin(data=air_prep, vardep="Satisfaction",
                           listconti=c("Customer_Loyal.Customer", "Travel_Personal.Travel",
                                       "Class_Eco.Plus", "WiFi_Sat_X1", "Online_Board_Sat_X1",
                                       "Online_Board_Sat_X3", "Entertainment_Sat_X3", "On_board_Sat_X3",
                                       "Leg_Sat_X2", "Leg_Sat_X3", "Checkin_Sat_X3"),
                           listclass=c(""),
                           grupos=5,sinicio=1234,repe=5,nodesize=10,
                           mtry=11,ntree=1000,replace=TRUE,sampsize=1200)

Bag_MMPC_6$Modelo = "Bagging tuneado (1200) \n Primer set"

Bag_MMPC_7 <- cruzadarfbin(data=air_prep, vardep="Satisfaction",
                           listconti=c("Customer_Loyal.Customer", "Travel_Personal.Travel",
                                       "Class_Eco.Plus", "WiFi_Sat_X1", "Online_Board_Sat_X1",
                                       "Online_Board_Sat_X3", "Entertainment_Sat_X3", "On_board_Sat_X3",
                                       "Leg_Sat_X2", "Leg_Sat_X3", "Checkin_Sat_X3"),
                           listclass=c(""),
                           grupos=5,sinicio=1234,repe=5,nodesize=10,
                           mtry=11,ntree=1000,replace=TRUE)

Bag_MMPC_7$Modelo = "Bagging tuneado (Base) \n Primer set"

# Finalizamos la paralelización
stopCluster(make_cluster)
registerDoSEQ()
```

Unimos todos los resultados en un único dataset:

```{r eval=FALSE}
select_bag_1 <- 
  rbind(Bag_MMPC_1,Bag_MMPC_2,Bag_MMPC_3,Bag_MMPC_4,Bag_MMPC_5,Bag_MMPC_6,Bag_MMPC_7)
```

```{r eval=FALSE}
ggplot(data = select_bag_1, aes(x = reorder(Modelo, tasa), y = tasa)) +
  geom_boxplot() +
  labs(x = "Modelos", y = "Tasa de error", title = "Distribución del error según los distintos modelos seleccionados") +
  theme_minimal() +
  theme(text = element_text(face = "bold", size = 25), plot.title = element_text(hjust = 0.5), 
        axis.title.x = element_text(vjust=-0.5)) +
  scale_x_discrete(guide = guide_axis(angle = 55))
```

```{r layout="l-body-outset", fig.width=50, fig.asp = .99, echo=FALSE}
knitr::include_graphics("/Users/leztin/Desktop/Captura de pantalla 2023-05-16 a las 18.37.11.png")  
```

Parece que con **500** de `sampsize` es suficiente para obtener un error adecuado.
Comprobemos esta cuestión en el segundo set de variables:

## Tuneado del parámetro `sampsize`: segundo set de variables

A continuación, fijamos los mejores parámetros y **probamos el parámetro** `sampsize` **hasta el máximo que habíamos calculado (1558)** para el segundo set de variables con la función `{cruzadarfbin}`:

```{r eval=FALSE}
# Inicializamos la paralelización
clusters <- detectCores() - 1
make_cluster <- makeCluster(clusters)
registerDoParallel(make_cluster)

Bag_BIC_1 <- cruzadarfbin(data=air_prep, vardep="Satisfaction",
                           listconti=c("Online_Board_Sat_X1", "Travel_Personal.Travel", "WiFi_Sat_X1", 
                           "Customer_Loyal.Customer", "WiFi_Sat_X2", "Baggage_Sat_X3", "Baggage_Sat_X2", 
                           "Class_Eco.Plus", "Checkin_Sat_X3", "Online_Board_Sat_X3", "Dep_Arr_Sat_X3", 
                           "Inflight_Sat_X3", "Seat_Sat_X3"),
                           listclass=c(""),
                           grupos=5,sinicio=1234,repe=5,nodesize=10,
                           mtry=13,ntree=500,replace=TRUE,sampsize=100)

Bag_BIC_1$Modelo = "Bagging tuneado (100) \n Segundo set"
    
Bag_BIC_2 <- cruzadarfbin(data=air_prep, vardep="Satisfaction",
                           listconti=c("Online_Board_Sat_X1", "Travel_Personal.Travel", "WiFi_Sat_X1", 
                           "Customer_Loyal.Customer", "WiFi_Sat_X2", "Baggage_Sat_X3", "Baggage_Sat_X2", 
                           "Class_Eco.Plus", "Checkin_Sat_X3", "Online_Board_Sat_X3", "Dep_Arr_Sat_X3", 
                           "Inflight_Sat_X3", "Seat_Sat_X3"),
                           listclass=c(""),
                           grupos=5,sinicio=1234,repe=5,nodesize=10,
                           mtry=13,ntree=500,replace=TRUE,sampsize=300)

Bag_BIC_2$Modelo = "Bagging tuneado (300) \n Segundo set"
    
Bag_BIC_3 <- cruzadarfbin(data=air_prep, vardep="Satisfaction",
                           listconti=c("Online_Board_Sat_X1", "Travel_Personal.Travel", "WiFi_Sat_X1", 
                           "Customer_Loyal.Customer", "WiFi_Sat_X2", "Baggage_Sat_X3", "Baggage_Sat_X2", 
                           "Class_Eco.Plus", "Checkin_Sat_X3", "Online_Board_Sat_X3", "Dep_Arr_Sat_X3", 
                           "Inflight_Sat_X3", "Seat_Sat_X3"),
                           listclass=c(""),
                           grupos=5,sinicio=1234,repe=5,nodesize=10,
                           mtry=13,ntree=500,replace=TRUE,sampsize=500)

Bag_BIC_3$Modelo = "Bagging tuneado (500) \n Segundo set"

Bag_BIC_4 <- cruzadarfbin(data=air_prep, vardep="Satisfaction",
                           listconti=c("Online_Board_Sat_X1", "Travel_Personal.Travel", "WiFi_Sat_X1", 
                           "Customer_Loyal.Customer", "WiFi_Sat_X2", "Baggage_Sat_X3", "Baggage_Sat_X2", 
                           "Class_Eco.Plus", "Checkin_Sat_X3", "Online_Board_Sat_X3", "Dep_Arr_Sat_X3", 
                           "Inflight_Sat_X3", "Seat_Sat_X3"),
                           listclass=c(""),
                           grupos=5,sinicio=1234,repe=5,nodesize=10,
                           mtry=13,ntree=500,replace=TRUE,sampsize=700)

Bag_BIC_4$Modelo = "Bagging tuneado (700) \n Segundo set"

Bag_BIC_5 <- cruzadarfbin(data=air_prep, vardep="Satisfaction",
                           listconti=c("Online_Board_Sat_X1", "Travel_Personal.Travel", "WiFi_Sat_X1", 
                           "Customer_Loyal.Customer", "WiFi_Sat_X2", "Baggage_Sat_X3", "Baggage_Sat_X2", 
                           "Class_Eco.Plus", "Checkin_Sat_X3", "Online_Board_Sat_X3", "Dep_Arr_Sat_X3", 
                           "Inflight_Sat_X3", "Seat_Sat_X3"),
                           listclass=c(""),
                           grupos=5,sinicio=1234,repe=5,nodesize=10,
                           mtry=13,ntree=500,replace=TRUE,sampsize=1000)

Bag_BIC_5$Modelo = "Bagging tuneado (1000) \n Segundo set"

Bag_BIC_6 <- cruzadarfbin(data=air_prep, vardep="Satisfaction",
                           listconti=c("Online_Board_Sat_X1", "Travel_Personal.Travel", "WiFi_Sat_X1", 
                           "Customer_Loyal.Customer", "WiFi_Sat_X2", "Baggage_Sat_X3", "Baggage_Sat_X2", 
                           "Class_Eco.Plus", "Checkin_Sat_X3", "Online_Board_Sat_X3", "Dep_Arr_Sat_X3", 
                           "Inflight_Sat_X3", "Seat_Sat_X3"),
                           listclass=c(""),
                           grupos=5,sinicio=1234,repe=5,nodesize=10,
                           mtry=13,ntree=500,replace=TRUE,sampsize=1200)

Bag_BIC_6$Modelo = "Bagging tuneado (1200) \n Segundo set"

Bag_BIC_7 <- cruzadarfbin(data=air_prep, vardep="Satisfaction",
                           listconti=c("Online_Board_Sat_X1", "Travel_Personal.Travel", "WiFi_Sat_X1", 
                           "Customer_Loyal.Customer", "WiFi_Sat_X2", "Baggage_Sat_X3", "Baggage_Sat_X2", 
                           "Class_Eco.Plus", "Checkin_Sat_X3", "Online_Board_Sat_X3", "Dep_Arr_Sat_X3", 
                           "Inflight_Sat_X3", "Seat_Sat_X3"),
                           listclass=c(""),
                           grupos=5,sinicio=1234,repe=5,nodesize=10,
                           mtry=13,ntree=500,replace=TRUE)

Bag_BIC_7$Modelo = "Bagging tuneado (Base) \n Segundo set"

# Finalizamos la paralelización
stopCluster(make_cluster)
registerDoSEQ()
```

Unimos todos los resultados en un único dataset:

```{r eval=FALSE}
select_bag_2 <- 
  rbind(Bag_BIC_1,Bag_BIC_2,Bag_BIC_3,Bag_BIC_4,Bag_BIC_5,Bag_BIC_6,Bag_BIC_7)
```

```{r eval=FALSE}
ggplot(data = select_bag_2, aes(x = reorder(Modelo, tasa), y = tasa)) +
  geom_boxplot() +
  labs(x = "Modelos", y = "Tasa de error", title = "Distribución del error según los distintos modelos seleccionados") +
  theme_minimal() +
  theme(text = element_text(face = "bold", size = 25), plot.title = element_text(hjust = 0.5), 
        axis.title.x = element_text(vjust=-0.5)) +
  scale_x_discrete(guide = guide_axis(angle = 55))
```

```{r layout="l-body-outset", fig.width=50, fig.asp = .99, echo=FALSE}
knitr::include_graphics("/Users/leztin/Desktop/Captura de pantalla 2023-05-16 a las 18.39.11.png")  
```

Parece que con **300** de `sampsize` es suficiente para obtener un error adecuado.
Comparemos a continuación los **modelos de bagging seleccionados con el resto de modelos que llevamos hasta el momento**.

## Comparativa parcial entre los modelos elaborados hasta el momento

```{r echo=FALSE, results='hide'}
source("/Users/leztin/Library/Mobile Documents/com~apple~CloudDocs/Universidad/Máster/Segundo cuatrimestre/Técnicas de Machine Learning/Tema 7/cruzada rf binaria.R")

Bag_MMPC_3 <- cruzadarfbin(data=air_prep, vardep="Satisfaction",
                           listconti=c("Customer_Loyal.Customer", "Travel_Personal.Travel",
                                       "Class_Eco.Plus", "WiFi_Sat_X1", "Online_Board_Sat_X1",
                                       "Online_Board_Sat_X3", "Entertainment_Sat_X3", "On_board_Sat_X3",
                                       "Leg_Sat_X2", "Leg_Sat_X3", "Checkin_Sat_X3"),
                           listclass=c(""),
                           grupos=5,sinicio=1234,repe=5,nodesize=10,
                           mtry=11,ntree=5000,replace=TRUE,sampsize=500)

Bag_MMPC_3$Modelo = "Bagging tuneado (500) \n Primer set"
Bag_MMPC_3$N_variables = "11"

Bag_BIC_2 <- cruzadarfbin(data=air_prep, vardep="Satisfaction",
                           listconti=c("Online_Board_Sat_X1", "Travel_Personal.Travel", "WiFi_Sat_X1", 
                           "Customer_Loyal.Customer", "WiFi_Sat_X2", "Baggage_Sat_X3", "Baggage_Sat_X2", 
                           "Class_Eco.Plus", "Checkin_Sat_X3", "Online_Board_Sat_X3", "Dep_Arr_Sat_X3", 
                           "Inflight_Sat_X3", "Seat_Sat_X3"),
                           listclass=c(""),
                           grupos=5,sinicio=1234,repe=5,nodesize=10,
                           mtry=13,ntree=5000,replace=TRUE,sampsize=300)

Bag_BIC_2$Modelo = "Bagging tuneado (300) \n Segundo set"
Bag_BIC_2$N_variables = "13"
```

```{r}
# Unimos todos los valores en un dataframe
select_final <-
  rbind(graf_MMPC, graf_repetido_BIC_set1, Red_MMPC_tun, 
        Red_step_BIC_tun, Bag_MMPC_3, Bag_BIC_2)
```

```{r layout="l-body-outset", fig.width=20, fig.asp = .99}
# Boxplot de la tasa de error para cada modelo
 a <- ggplot(data = select_final, aes(x = reorder(Modelo, tasa), y = tasa)) +
  geom_boxplot() +
  labs(x = NULL, y = "Tasa de error", title = "Distribución del error según los distintos modelos seleccionados") +
  theme_minimal() +
  theme(text = element_text(face = "bold", size = 15), plot.title = element_text(hjust = 0.5), 
        axis.title.x = element_text(vjust=-0.5)) +
  geom_label(aes(label = N_variables, y = 0.06), size = 6) +
  scale_x_discrete(guide = guide_axis(angle = 50))

# Boxplot de la tasa AUC para cada modelo
 b <- ggplot(data = select_final, aes(x = reorder(Modelo, -auc), y = auc)) +
  geom_boxplot() +
  labs(x = NULL, y = "AUC", title = "Distribución de la tasa AUC según los distintos modelos seleccionados") +
  theme_minimal() +
  theme(text = element_text(face = "bold", size = 15), plot.title = element_text(hjust = 0.5), 
        axis.title.x = element_text(vjust=-0.5)) +
  geom_label(aes(label = N_variables, y = 0.96), size = 6) +
  scale_x_discrete(guide = guide_axis(angle = 50))
 
Rmisc::multiplot(a, b)
```

Los **modelos de bagging** generados **no parecen introducir cambios significativos** respecto de las estadísticas de los modelos anteriores.
Hasta ahora, la **red neuronal tuneada de nuestro segundo set de variables tentativo** es la que **mayor AUC presenta**.
Continuamos en la siguiente sección con la elaboración de nuevos modelos de **Random Forest**.

# Fase 7.5: Random Forest: comparación de los criterios de selección

En este tercer apartado, aplicaremos a ambos sets de variables **modelos Random Forest**.
Tras ello, **compararemos los resultados** para ver si **mejoran** los resultados de los anteriores modelos.

## Aplicación al primer set de variables (Algoritmo MMPC)

En este set tenemos **once variables**, por lo que el parámetro `mtry` **lo tunearemos hasta 11**.
Tras hacer varias pruebas con diferentes semillas, he decidido implementar un número máximo de árboles de **5000** (`ntree`).
Además, he mantenido el parámetro `nodesize` en **10**, que es el que **mejores resultados ofrecía**.

```{r eval=FALSE}
# Fijamos semilla
set.seed(12346)

# Inicializamos la paralelización
clusters <- detectCores() - 1
make_cluster <- makeCluster(clusters)
registerDoParallel(make_cluster)

# Le indicamos validación cruzada repetida
control <- 
  trainControl(method = "repeatedcv",number=5,savePredictions = "all",
               classProbs=TRUE) 

# Creamos el grid tuneado 
rfgrid <-
  expand.grid(mtry=c(2,3,4,5,6,7,8,9,10,11))

# Lanzamos la función del modelo
rf1 <- train(factor(Satisfaction)~Customer_Loyal.Customer+Travel_Personal.Travel+
                         Class_Eco.Plus+WiFi_Sat_X1+Online_Board_Sat_X1+Online_Board_Sat_X3+
                         Entertainment_Sat_X3+On_board_Sat_X3+Leg_Sat_X2+Leg_Sat_X3+Checkin_Sat_X3,
           data=air_prep,method="rf",trControl=control,tuneGrid=rfgrid, linout = FALSE,
           ntree=5000,nodesize=10,repeats=5,replace=TRUE,importance=TRUE)
rf1

# Finalizamos la paralelización
stopCluster(make_cluster)
registerDoSEQ()
```

```{r layout="l-body-outset", fig.width=50, fig.asp = .99, echo=FALSE}
knitr::include_graphics("/Users/leztin/Desktop/Captura de pantalla 2023-05-16 a las 18.48.42.png")  
```

Este modelo Random Forest sobre el primer set de variables, con `mtry = 6` (el mejor mtry según caret), ofrece un **accuracy del 91.29 %**.
Probemos con el segundo set de variables:

## Aplicación al segundo set de variables (Step repetido con el Criterio de Información BIC)

En este segundo set tenemos **trece variables**, por lo que el parámetro `mtry` **lo tunearemos hasta 13**.
Tras hacer varias pruebas con diferentes semillas, he decidido implementar un número máximo de árboles de **5000** (`ntree`).
Además, he mantenido el parámetro `nodesize` en **10**, que es el que **mejores resultados ofrecía**.

```{r eval=FALSE}
# Fijamos semilla
set.seed(12346)

# Inicializamos la paralelización
clusters <- detectCores() - 1
make_cluster <- makeCluster(clusters)
registerDoParallel(make_cluster)

# Le indicamos validación cruzada repetida
control <- 
  trainControl(method = "repeatedcv",number=5,savePredictions = "all",
               classProbs=TRUE) 

# Creamos el grid tuneado 
rfgrid <-
  expand.grid(mtry=c(2,3,4,5,6,7,8,9,10,11,12,13))

# Lanzamos la función del modelo
rf2 <- train(factor(Satisfaction)~Online_Board_Sat_X1+Travel_Personal.Travel+
                         WiFi_Sat_X1+Customer_Loyal.Customer+WiFi_Sat_X2+Baggage_Sat_X3+
                         +Baggage_Sat_X2+Class_Eco.Plus+Checkin_Sat_X3+Online_Board_Sat_X3+
                         Dep_Arr_Sat_X3+Inflight_Sat_X3+Seat_Sat_X3,data=air_prep,
           method="rf",trControl=control,tuneGrid=rfgrid, linout = FALSE,
           ntree=5000,nodesize=10,repeats=5,replace=TRUE,importance=TRUE)
rf2

# Finalizamos la paralelización
stopCluster(make_cluster)
registerDoSEQ()
```

```{r layout="l-body-outset", fig.width=50, fig.asp = .99, echo=FALSE}
knitr::include_graphics("/Users/leztin/Desktop/Captura de pantalla 2023-05-16 a las 18.53.49.png")  
```

Este modelo Random Forest sobre el segundo set de variables, con `mtry = 9` (el mejor mtry según caret), ofrece un **accuracy del 92.54 %**.

A continuación utilizamos `cruzadarfbin()` aplicando **el mejor** `mtry` para cada set de variables.

```{r}
RF_MMPC <- cruzadarfbin(data=air_prep, vardep="Satisfaction",
                           listconti=c("Customer_Loyal.Customer", "Travel_Personal.Travel",
                                       "Class_Eco.Plus", "WiFi_Sat_X1", "Online_Board_Sat_X1",
                                       "Online_Board_Sat_X3", "Entertainment_Sat_X3", "On_board_Sat_X3",
                                       "Leg_Sat_X2", "Leg_Sat_X3", "Checkin_Sat_X3"),
                           listclass=c(""),
                           grupos=5,sinicio=1234,repe=5,nodesize=10,
                           mtry=6,ntree=5000,replace=TRUE,sampsize=1000)

RF_MMPC$Modelo = "Random Forest \n Primer set"
RF_MMPC$N_variables = "11"

RF_BIC<- cruzadarfbin(data=air_prep, vardep="Satisfaction",
                           listconti=c("Online_Board_Sat_X1", "Travel_Personal.Travel", "WiFi_Sat_X1",
                                       "Customer_Loyal.Customer", "WiFi_Sat_X2", "Baggage_Sat_X3",
                                       "Baggage_Sat_X2", "Class_Eco.Plus", "Checkin_Sat_X3",
                                       "Online_Board_Sat_X3", "Dep_Arr_Sat_X3", "Inflight_Sat_X3",
                                       "Seat_Sat_X3"),
                           listclass=c(""),
                           grupos=5,sinicio=1234,repe=5,nodesize=10,
                           mtry=9,ntree=5000,replace=TRUE,sampsize=1000)

RF_BIC$Modelo = "Random Forest \n Segundo set"
RF_BIC$N_variables = "13"
```

## Comparativa parcial entre los modelos elaborados hasta el momento

```{r}
# Unimos todos los valores en un dataframe
select_final <-
  rbind(graf_MMPC, graf_repetido_BIC_set1, Red_MMPC_tun, 
        Red_step_BIC_tun, Bag_MMPC_3, Bag_BIC_2, RF_MMPC, RF_BIC)
```

```{r layout="l-body-outset", fig.width=20, fig.asp = .99}
# Boxplot de la tasa de error para cada modelo
 a <- ggplot(data = select_final, aes(x = reorder(Modelo, tasa), y = tasa)) +
  geom_boxplot() +
  labs(x = NULL, y = "Tasa de error", title = "Distribución del error según los distintos modelos seleccionados") +
  theme_minimal() +
  theme(text = element_text(face = "bold", size = 15), plot.title = element_text(hjust = 0.5), 
        axis.title.x = element_text(vjust=-0.5)) +
  geom_label(aes(label = N_variables, y = 0.06), size = 6) +
  scale_x_discrete(guide = guide_axis(angle = 50))

# Boxplot de la tasa AUC para cada modelo
 b <- ggplot(data = select_final, aes(x = reorder(Modelo, -auc), y = auc)) +
  geom_boxplot() +
  labs(x = NULL, y = "AUC", title = "Distribución de la tasa AUC según los distintos modelos seleccionados") +
  theme_minimal() +
  theme(text = element_text(face = "bold", size = 15), plot.title = element_text(hjust = 0.5), 
        axis.title.x = element_text(vjust=-0.5)) +
  geom_label(aes(label = N_variables, y = 0.96), size = 6) +
  scale_x_discrete(guide = guide_axis(angle = 50))
 
Rmisc::multiplot(a, b)
```

Como se puede observar, el **Random Forest con el set de 13 variables** ha logrado posicionarse en el **segundo puesto**, justo después de la red neuronal.
De momento, la **red neuronal sobre el set de 13 variables es la que se sigue posicionando en primer lugar**.
A continuación probaremos con el algoritmo **Gradient Boosting**.

# Fase 7.6: Gradient Boosting

En este cuarto apartado, aplicaremos a ambos sets de variables **modelos Gradient Boosting**.
Tras ello, **compararemos los resultados** para ver si **mejoran** los resultados de los anteriores modelos.

## Aplicación al primer set de variables (Algoritmo MMPC)

Recordemos que este primer set presenta **once variables predictoras**.
El **grid** para el modelo **Gradient Boosting presenta bastantes opciones de tuneo**, por lo que, antes de mostrar los resultados, voy a comentar las opciones por las que me he ido decantando.
Tras varias pruebas, la configuración final es la siguiente:

1.  `shrinkage`: El vector para este parámetro es el siguiente: `c(0.1,0.07,0.05,0.03,0.01)`. Tras probar con varias horquillas, me decanté por esta porque el valor `0.05` es el que, finalmente, **maximiza el ajuste**.
2.  `n.minobsinnode`: El vector para este parámetro es el siguiente: `c(7,10,15,20)`. Teniendo en cuenta el número de variables de este set y las dimensiones totales de mi muestra, **no es posible establecer un número de nodos demasiado alto**, por lo que el máximo dentro del vector se sitúa en 20.
3.  `n.trees`: El vector para este parámetro es el siguiente: `c(800,900,1000,1100,1200)`. Tras probar varias horquillas, el número de árboles óptimo siempre rondaba los 1000, por lo que la horquilla final se sitúa cercana a esa cifra.
4.  `interaction.depth`: Este parámetro permanece en `2` para árboles binarios.
5.  `bag.fraction`: Este parámetro lo he mantenido en `1` por defecto.

```{r eval=FALSE}
# Fijamos semilla
set.seed(12346)

# Inicializamos la paralelización
clusters <- detectCores() - 1
make_cluster <- makeCluster(clusters)
registerDoParallel(make_cluster)

# Le indicamos validación cruzada repetida
control <- trainControl(method = "repeatedcv",number=5,repeats=5,savePredictions = "all",
                        classProbs=TRUE) 

# Creamos el grid tuneado
gbmgrid <- expand.grid(shrinkage=c(0.1,0.07,0.05,0.03,0.01),
                       n.minobsinnode=c(7,10,15,20),
                       n.trees=c(800,900,1000,1100,1200),
                       interaction.depth=c(2))

# Lanzamos la función del modelo
gbm <- train(factor(Satisfaction)~Customer_Loyal.Customer+Travel_Personal.Travel+
                         Class_Eco.Plus+WiFi_Sat_X1+Online_Board_Sat_X1+Online_Board_Sat_X3+
                         Entertainment_Sat_X3+On_board_Sat_X3+Leg_Sat_X2+Leg_Sat_X3+Checkin_Sat_X3,
             data=air_prep,method="gbm",trControl=control,tuneGrid=gbmgrid,
             distribution="bernoulli",bag.fraction=1,verbose=FALSE)
gbm

# Finalizamos la paralelización
stopCluster(make_cluster)
registerDoSEQ()
```

```{r layout="l-body-outset", fig.width=50, fig.asp = .99, echo=FALSE}
knitr::include_graphics("/Users/leztin/Desktop/Captura de pantalla 2023-05-16 a las 18.55.53.png")  
```

Finalmente, el **modelo Gradient Boosting** para el primer set de variables ha encontrado su configuración óptima con los **hiperparámetros que se muestran a continuación**.

```{r eval=FALSE}
gbm$bestTune
```

```{r layout="l-body-outset", fig.width=50, fig.asp = .99, echo=FALSE}
knitr::include_graphics("/Users/leztin/Desktop/Captura de pantalla 2023-05-16 a las 18.58.11.png")  
```

Y los resultados en cuanto a **accuracy** son los siguientes:

```{r eval=FALSE}
gbm$results |> filter(n.trees == gbm$bestTune$n.trees &
                        interaction.depth == gbm$bestTune$interaction.depth &
                        shrinkage == gbm$bestTune$shrinkage &
                        n.minobsinnode == gbm$bestTune$n.minobsinnode)
```

```{r layout="l-body-outset", fig.width=50, fig.asp = .99, echo=FALSE}
knitr::include_graphics("/Users/leztin/Desktop/Captura de pantalla 2023-05-16 a las 18.59.18.png")  
```

A continuación probaremos el mismo modelo, pero para el **segundo set de variables**:

## Aplicación al segundo set de variables (Step repetido con el Criterio de Información BIC)

Recordemos que este segundo set presenta **trece variables predictoras**.
Al igual que en el anterior apartado, tras varias pruebas, la configuración final es la siguiente:

1.  `shrinkage`: El vector para este parámetro es el siguiente: `c(0.04, 0.03, 0.02)`. Tras probar con varias horquillas, me decanté por esta porque el valor `0.03` es el que, finalmente, **maximiza el ajuste**.
2.  `n.minobsinnode`: El vector para este parámetro es el siguiente: `c(7,10,15)`. Teniendo en cuenta el número de variables de este set y las dimensiones totales de mi muestra, **no es posible establecer un número de nodos demasiado alto**, por lo que el máximo dentro del vector se sitúa en 15.
3.  `n.trees`: El vector para este parámetro es el siguiente: `c(1000, 2000, 3000)`. Al tunear el parámetro v de regularización con valores tan bajos, se requería un mayor número de iteraciones. 2000 era el número medio que salía en todas las pruebas como óptimo.
4.  `interaction.depth`: Este parámetro permanece en `2` para árboles binarios.
5.  `bag.fraction`: Este parámetro lo he mantenido en `1` por defecto.

```{r eval=FALSE}
# Fijamos semilla
set.seed(12346)

# Inicializamos la paralelización
clusters <- detectCores() - 1
make_cluster <- makeCluster(clusters)
registerDoParallel(make_cluster)

# Le indicamos validación cruzada repetida
control <- trainControl(method = "repeatedcv",number=5,repeats=5,savePredictions = "all",
                        classProbs=TRUE) 

# Creamos el grid tuneado
gbmgrid<-expand.grid(shrinkage=c(0.04, 0.03, 0.02),
                     n.minobsinnode=c(7,10,15),
                     n.trees=c(1000, 2000, 3000),
                     interaction.depth=c(2))

# Lanzamos la función del modelo
gbm2 <- train(factor(Satisfaction)~Online_Board_Sat_X1+Travel_Personal.Travel+
                         WiFi_Sat_X1+Customer_Loyal.Customer+WiFi_Sat_X2+Baggage_Sat_X3+
                         +Baggage_Sat_X2+Class_Eco.Plus+Checkin_Sat_X3+Online_Board_Sat_X3+
                         Dep_Arr_Sat_X3+Inflight_Sat_X3+Seat_Sat_X3,
             data=air_prep,method="gbm",trControl=control,tuneGrid=gbmgrid,
             distribution="bernoulli",bag.fraction=1,verbose=FALSE)
gbm2

# Finalizamos la paralelización
stopCluster(make_cluster)
registerDoSEQ()
```

```{r layout="l-body-outset", fig.width=50, fig.asp = .99, echo=FALSE}
knitr::include_graphics("/Users/leztin/Desktop/Captura de pantalla 2023-05-16 a las 19.02.08.png")  
```

Finalmente, el **modelo Gradient Boosting** para el segundo set de variables ha encontrado su configuración óptima con los **hiperparámetros que se muestran a continuación**.

```{r eval=FALSE}
gbm2$bestTune
```

```{r layout="l-body-outset", fig.width=50, fig.asp = .99, echo=FALSE}
knitr::include_graphics("/Users/leztin/Desktop/Captura de pantalla 2023-05-16 a las 19.03.06.png")  
```

Y los resultados en cuanto a **accuracy** son los siguientes:

```{r eval=FALSE}
gbm2$results |> filter(n.trees == gbm$bestTune$n.trees &
                        interaction.depth == gbm$bestTune$interaction.depth &
                        shrinkage == gbm$bestTune$shrinkage &
                        n.minobsinnode == gbm$bestTune$n.minobsinnode)
```

```{r layout="l-body-outset", fig.width=50, fig.asp = .99, echo=FALSE}
knitr::include_graphics("/Users/leztin/Desktop/Captura de pantalla 2023-05-16 a las 19.03.46.png")  
```

A continuación utilizamos `cruzadarfbin()` aplicando **los mejores hiperparámetros** para cada set de variables.

```{r}
source("/Users/leztin/Downloads/Tema 12 Feature Engineering-2/cruzada gbm binaria.R")

GB_MMPC <- cruzadagbmbin(data=air_prep, vardep="Satisfaction",
                           listconti=c("Customer_Loyal.Customer", "Travel_Personal.Travel",
                                       "Class_Eco.Plus", "WiFi_Sat_X1", "Online_Board_Sat_X1",
                                       "Online_Board_Sat_X3", "Entertainment_Sat_X3", "On_board_Sat_X3",
                                       "Leg_Sat_X2", "Leg_Sat_X3", "Checkin_Sat_X3"),
                           listclass=c(""),
                      grupos=5,sinicio=1234,repe=5,n.minobsinnode=7,
                      shrinkage=0.07,n.trees=800,interaction.depth=2)

GB_MMPC$Modelo = "Gradient Boosting \n Primer set"
GB_MMPC$N_variables = "11"

GB_BIC<- cruzadagbmbin(data=air_prep, vardep="Satisfaction",
                           listconti=c("Online_Board_Sat_X1", "Travel_Personal.Travel", "WiFi_Sat_X1",
                                       "Customer_Loyal.Customer", "WiFi_Sat_X2", "Baggage_Sat_X3",
                                       "Baggage_Sat_X2", "Class_Eco.Plus", "Checkin_Sat_X3",
                                       "Online_Board_Sat_X3", "Dep_Arr_Sat_X3", "Inflight_Sat_X3",
                                       "Seat_Sat_X3"),
                           listclass=c(""),
                      grupos=5,sinicio=1234,repe=5,n.minobsinnode=7,
                      shrinkage=0.03,n.trees=2000,interaction.depth=2)

GB_BIC$Modelo = "Gradient Boosting \n Segundo set"
GB_BIC$N_variables = "13"
```

## Comparativa parcial entre los modelos elaborados hasta el momento

```{r}
# Unimos todos los valores en un dataframe
select_final <-
  rbind(graf_MMPC, graf_repetido_BIC_set1, Red_MMPC_tun, 
        Red_step_BIC_tun, Bag_MMPC_3, Bag_BIC_2, RF_MMPC, RF_BIC,
        GB_MMPC, GB_BIC)
```

```{r layout="l-body-outset", fig.width=20, fig.asp = .99}
# Boxplot de la tasa de error para cada modelo
 a <- ggplot(data = select_final, aes(x = reorder(Modelo, tasa), y = tasa)) +
  geom_boxplot() +
  labs(x = NULL, y = "Tasa de error", title = "Distribución del error según los distintos modelos seleccionados") +
  theme_minimal() +
  theme(text = element_text(face = "bold", size = 15), plot.title = element_text(hjust = 0.5), 
        axis.title.x = element_text(vjust=-0.5)) +
  geom_label(aes(label = N_variables, y = 0.06), size = 6) +
  scale_x_discrete(guide = guide_axis(angle = 50))

# Boxplot de la tasa AUC para cada modelo
 b <- ggplot(data = select_final, aes(x = reorder(Modelo, -auc), y = auc)) +
  geom_boxplot() +
  labs(x = NULL, y = "AUC", title = "Distribución de la tasa AUC según los distintos modelos seleccionados") +
  theme_minimal() +
  theme(text = element_text(face = "bold", size = 15), plot.title = element_text(hjust = 0.5), 
        axis.title.x = element_text(vjust=-0.5)) +
  geom_label(aes(label = N_variables, y = 0.96), size = 6) +
  scale_x_discrete(guide = guide_axis(angle = 50))
 
Rmisc::multiplot(a, b)
```

Como se puede observar, el **modelo Gradient Boosting con el set de 13 variables** ha logrado posicionarse en el **segundo puesto**, justo después de la red neuronal en términos de AUC.
También es el **tercero de todos los modelos con menor error**.
Por otro lado, ningún modelo presenta excesiva varianza.
De momento, la **red neuronal sobre el set de 13 variables es la que se sigue posicionando en primer lugar**.
A continuación probaremos con el algoritmo **XGBoost**.

# Fase 7.7: XGBoost

En este quinto apartado, aplicaremos a ambos sets de variables **modelos XGBoost**.
Tras ello, **compararemos los resultados** para ver si **mejoran** los resultados de los anteriores modelos.

## Aplicación al primer set de variables (Algoritmo MMPC)

Recordemos que este primer set presenta **once variables predictoras**.
El **grid** para el modelo **XGBoost presenta bastantes opciones de tuneo**, por lo que, antes de mostrar los resultados, voy a comentar las opciones por las que me he ido decantando.
Tras varias pruebas, la configuración final es la siguiente:

1.  `min_child_weight`: El vector para este parámetro es el siguiente: `c(5,10,15)`. Tras probar con varias horquillas, me decanté por esta porque el valor `10` es el que, finalmente, **maximiza el ajuste**.
2.  `eta`: El vector para este parámetro es el siguiente: `c(0.03,0.02,0.01,0.007,0.005)`. El valor óptimo se encontraba cerca del 0.01, por lo que generé un vector de números cercanos a ese valor principal.
3.  `nrounds`: El vector para este parámetro es el siguiente: `c(100,500,1000,2000,3000)`. Tras probar varias horquillas, el número de árboles óptimo siempre rondaba los 1000, por lo que la horquilla final se sitúa cercana a esa cifra.
4.  `max_depth`: Este parámetro lo subí a `10`. El modelo tardaba un poco más en ejecutarse, pero ofrecía mejores resultados.
5.  `gamma`: Este parámetro lo he mantenido en `0` por defecto.
6.  `colsample_bytree`: Este parámetro lo he mantenido en `1` por defecto. Solo funcionaba la función de esta manera.
7.  `subsample`: Este parámetro lo bajé a `0.9`. El modelo tardaba menos en ejecutarse y ofrecía mejores resultados.

```{r eval=FALSE}
# Fijamos semilla
set.seed(12346)

# Inicializamos la paralelización
clusters <- detectCores() - 1
make_cluster <- makeCluster(clusters)
registerDoParallel(make_cluster)

# Le indicamos validación cruzada repetida
control <- trainControl(method = "repeatedcv",number=5,repeats=5,savePredictions = "all",
                        classProbs=TRUE) 

# Creamos el grid tuneado
xgbmgrid <- expand.grid(min_child_weight=c(5,10,15),
                      eta=c(0.03,0.02,0.01,0.007,0.005),
                      nrounds=c(100,500,1000,2000,3000),
                      max_depth=10,gamma=0,
                      colsample_bytree=1,subsample=0.9)

# Lanzamos la función del modelo
xgbm1 <- train(factor(Satisfaction)~Customer_Loyal.Customer+Travel_Personal.Travel+
                         Class_Eco.Plus+WiFi_Sat_X1+Online_Board_Sat_X1+Online_Board_Sat_X3+
                         Entertainment_Sat_X3+On_board_Sat_X3+Leg_Sat_X2+Leg_Sat_X3+Checkin_Sat_X3,
              data=air_prep,method="xgbTree",trControl=control,tuneGrid=xgbmgrid,verbose=FALSE)
xgbm1
 
plot(xgbm1)

# Finalizamos la paralelización
stopCluster(make_cluster)
registerDoSEQ()
```

```{r layout="l-body-outset", fig.width=50, fig.asp = .99, echo=FALSE}
knitr::include_graphics("/Users/leztin/Desktop/Captura de pantalla 2023-05-16 a las 19.08.22.png")  
```

```{r layout="l-body-outset", fig.width=50, fig.asp = .99, echo=FALSE}
knitr::include_graphics("/Users/leztin/Desktop/Captura de pantalla 2023-05-16 a las 19.08.38.png")  
```

Finalmente, el **modelo XGBoost** para el primer set de variables ha encontrado su configuración óptima con los **hiperparámetros que se muestran a continuación**.

```{r eval=FALSE}
xgbm1$bestTune
```

```{r layout="l-body-outset", fig.width=50, fig.asp = .99, echo=FALSE}
knitr::include_graphics("/Users/leztin/Desktop/Captura de pantalla 2023-05-16 a las 19.11.02.png")  
```

Y los resultados en cuanto a **accuracy** son los siguientes:

```{r eval=FALSE}
xgbm1$results |> filter(nrounds == xgbm1$bestTune$nrounds & 
                         max_depth == xgbm1$bestTune$max_depth & 
                         eta == xgbm1$bestTune$eta & 
                         min_child_weight == xgbm1$bestTune$min_child_weight)
```

```{r layout="l-body-outset", fig.width=50, fig.asp = .99, echo=FALSE}
knitr::include_graphics("/Users/leztin/Desktop/Captura de pantalla 2023-05-16 a las 19.11.48.png")  
```

A continuación probaremos el mismo modelo, pero para el **segundo set de variables**:

## Aplicación al segundo set de variables (Step repetido con el Criterio de Información BIC)

Recordemos que este segundo set presenta **trece variables predictoras**.
Al igual que en el anterior apartado, tras varias pruebas, la configuración final es la siguiente:

1.  `min_child_weight`: El vector para este parámetro es el siguiente: `c(5,10,15)`. Tras probar con varias horquillas, me decanté por esta porque el valor `10` es el que, finalmente, **maximiza el ajuste**.
2.  `eta`: El vector para este parámetro es el siguiente: `c(0.1,0.08,0.07,0.06,0.05,0.04)`. El valor óptimo se encontraba cerca del 0.05, por lo que generé un vector de números cercanos a ese valor principal.
3.  `nrounds`: El vector para este parámetro es el siguiente: `c(100,500,1000,2000)`. Tras probar varias horquillas, el número de árboles óptimo siempre rondaba los 1000, por lo que la horquilla final se sitúa cercana a esa cifra.
4.  `max_depth`: Este parámetro lo subí a `10`. El modelo tardaba un poco más en ejecutarse, pero ofrecía mejores resultados.
5.  `gamma`: Este parámetro lo he mantenido en `0` por defecto.
6.  `colsample_bytree`: Este parámetro lo he mantenido en `1` por defecto. Solo funcionaba la función de esta manera.
7.  `subsample`: Este parámetro lo bajé a `0.9`. El modelo tardaba menos en ejecutarse y ofrecía mejores resultados.

```{r eval=FALSE}
# Fijamos semilla
set.seed(12346)

# Inicializamos la paralelización
clusters <- detectCores() - 1
make_cluster <- makeCluster(clusters)
registerDoParallel(make_cluster)

# Le indicamos validación cruzada repetida
control <- trainControl(method = "repeatedcv",number=5,repeats=5,savePredictions = "all",
                        classProbs=TRUE) 

# Creamos el grid tuneado
xgbmgrid <- expand.grid(min_child_weight=c(5,10,15),
                      eta=c(0.1,0.08,0.07,0.06,0.05,0.04),
                      nrounds=c(100,500,1000,2000),
                      max_depth=10,gamma=0,
                      colsample_bytree=1,subsample=0.9)

# Lanzamos la función del modelo
xgbm <- train(factor(Satisfaction)~Online_Board_Sat_X1+Travel_Personal.Travel+
                         WiFi_Sat_X1+Customer_Loyal.Customer+WiFi_Sat_X2+Baggage_Sat_X3+
                         +Baggage_Sat_X2+Class_Eco.Plus+Checkin_Sat_X3+Online_Board_Sat_X3+
                         Dep_Arr_Sat_X3+Inflight_Sat_X3+Seat_Sat_X3,
              data=air_prep,method="xgbTree",trControl=control,tuneGrid=xgbmgrid,verbose=FALSE)
xgbm
 
plot(xgbm)

# Finalizamos la paralelización
stopCluster(make_cluster)
registerDoSEQ()
```

```{r layout="l-body-outset", fig.width=50, fig.asp = .99, echo=FALSE}
knitr::include_graphics("/Users/leztin/Desktop/Captura de pantalla 2023-05-16 a las 19.14.27.png")  
```

```{r layout="l-body-outset", fig.width=50, fig.asp = .99, echo=FALSE}
knitr::include_graphics("/Users/leztin/Desktop/Captura de pantalla 2023-05-16 a las 19.14.23.png")  
```

Finalmente, el **modelo XGBoost** para el segundo set de variables ha encontrado su configuración óptima con los **hiperparámetros que se muestran a continuación**.

```{r eval=FALSE}
xgbm$bestTune
```

```{r layout="l-body-outset", fig.width=50, fig.asp = .99, echo=FALSE}
knitr::include_graphics("/Users/leztin/Desktop/Captura de pantalla 2023-05-16 a las 19.15.24.png")  
```

Y los resultados en cuanto a **accuracy** son los siguientes:

```{r eval=FALSE}
xgbm$results |> filter(nrounds == xgbm$bestTune$nrounds & 
                         max_depth == xgbm$bestTune$max_depth & 
                         eta == xgbm$bestTune$eta & 
                         min_child_weight == xgbm$bestTune$min_child_weight)
```

```{r layout="l-body-outset", fig.width=50, fig.asp = .99, echo=FALSE}
knitr::include_graphics("/Users/leztin/Desktop/Captura de pantalla 2023-05-16 a las 19.16.15.png")  
```

A continuación utilizamos `cruzadaxgbmbin()` aplicando **los mejores hiperparámetros** para cada set de variables.

```{r}
source("/Users/leztin/Library/Mobile Documents/com~apple~CloudDocs/Universidad/Máster/Segundo cuatrimestre/Técnicas de Machine Learning/Tema 7/cruzada xgboost binaria.R")

XGB_MMPC <- cruzadaxgbmbin(data=air_prep, vardep="Satisfaction",
                           listconti=c("Customer_Loyal.Customer", "Travel_Personal.Travel",
                                       "Class_Eco.Plus", "WiFi_Sat_X1", "Online_Board_Sat_X1",
                                       "Online_Board_Sat_X3", "Entertainment_Sat_X3", "On_board_Sat_X3",
                                       "Leg_Sat_X2", "Leg_Sat_X3", "Checkin_Sat_X3"),
                           listclass=c(""),
                          grupos=5,sinicio=1234,repe=5,
                          min_child_weight=10,eta=0.03,nrounds=1000,max_depth=10,
                          gamma=0,colsample_bytree=1,subsample=0.9,alpha=0,lambda=0)

XGB_MMPC$Modelo = "XGBoost \n Primer set"
XGB_MMPC$N_variables = "11"

XGB_BIC<- cruzadaxgbmbin(data=air_prep, vardep="Satisfaction",
                           listconti=c("Online_Board_Sat_X1", "Travel_Personal.Travel", "WiFi_Sat_X1",
                                       "Customer_Loyal.Customer", "WiFi_Sat_X2", "Baggage_Sat_X3",
                                       "Baggage_Sat_X2", "Class_Eco.Plus", "Checkin_Sat_X3",
                                       "Online_Board_Sat_X3", "Dep_Arr_Sat_X3", "Inflight_Sat_X3",
                                       "Seat_Sat_X3"),
                           listclass=c(""),
                        grupos=5,sinicio=1234,repe=5,
                        min_child_weight=10,eta=0.01,nrounds=2000,max_depth=10,
                        gamma=0,colsample_bytree=1,subsample=0.9,alpha=0,lambda=0)

XGB_BIC$Modelo = "XGBoost \n Segundo set"
XGB_BIC$N_variables = "13"
```

## Comparativa parcial entre los modelos elaborados hasta el momento

```{r}
# Unimos todos los valores en un dataframe
select_final <-
  rbind(graf_MMPC, graf_repetido_BIC_set1, Red_MMPC_tun, 
        Red_step_BIC_tun, Bag_MMPC_3, Bag_BIC_2, RF_MMPC, RF_BIC,
        GB_MMPC, GB_BIC, XGB_MMPC, XGB_BIC)
```

```{r layout="l-body-outset", fig.width=20, fig.asp = .99}
# Boxplot de la tasa de error para cada modelo
 a <- ggplot(data = select_final, aes(x = reorder(Modelo, tasa), y = tasa)) +
  geom_boxplot() +
  labs(x = NULL, y = "Tasa de error", title = "Distribución del error según los distintos modelos seleccionados") +
  theme_minimal() +
  theme(text = element_text(face = "bold", size = 15), plot.title = element_text(hjust = 0.5), 
        axis.title.x = element_text(vjust=-0.5)) +
  geom_label(aes(label = N_variables, y = 0.06), size = 6) +
  scale_x_discrete(guide = guide_axis(angle = 50))

# Boxplot de la tasa AUC para cada modelo
 b <- ggplot(data = select_final, aes(x = reorder(Modelo, -auc), y = auc)) +
  geom_boxplot() +
  labs(x = NULL, y = "AUC", title = "Distribución de la tasa AUC según los distintos modelos seleccionados") +
  theme_minimal() +
  theme(text = element_text(face = "bold", size = 15), plot.title = element_text(hjust = 0.5), 
        axis.title.x = element_text(vjust=-0.5)) +
  geom_label(aes(label = N_variables, y = 0.96), size = 6) +
  scale_x_discrete(guide = guide_axis(angle = 50))
 
Rmisc::multiplot(a, b)
```

Como se puede observar, el **modelo XGBoost con el set de 13 variables** ha logrado posicionarse en el **segundo puesto**, muy cercana a la red neuronal en términos de AUC.
También es el **segundo de todos los modelos con menor error**.
Además, los resultados proporcionados por los modelos XGBoost parecen tener aún menor varianza que el resto de modelos.
De momento, la **red neuronal sobre el set de 13 variables es la que se sigue posicionando en primer lugar**.
A continuación probaremos con distintos modelos **SVM**.

# Fase 7.8: Support Vector Machine (SVM)

En este sexto apartado, aplicaremos a ambos sets de variables **modelos Support Vector Machine (SVM)**.
Concretamente, aplicaremos **tres tipos** de modelos SVM: el **SVM Lineal**, el **SVM Polinomial** y el **SVM Radial**.
Tras ello, **compararemos los resultados** para ver si **mejoran** los resultados de los anteriores modelos.

## SVM Lineal

El **SVM (Support Vector Machine) Lineal** es una variante del algoritmo SVM cuyo funcionamiento se basa en encontrar una **función lineal** que pueda separar de manera óptima las muestras pertenecientes a diferentes clases **en un espacio de alta dimensionalidad**.

### Aplicación al primer set de variables (Algoritmo MMPC)

Recordemos que este primer set presenta **once variables predictoras**.
El **grid** para el modelo **SVM Lineal presenta únicamente el parámetro** `C`, por lo que, antes de mostrar los resultados, voy a comentar el vector que he seleccionado para este hiperparámetro.
El vector es el siguiente: `c(0.01,0.02,0.03,0.04,0.05,0.06,0.07,0.8,0.1)`.
El valor óptimo resultó posicionarse en torno al `0.06`, por lo que el resto de valores son cercanos a esa cifra.

```{r eval=FALSE}
# Fijamos semilla
set.seed(12346)

# Inicializamos la paralelización
clusters <- detectCores() - 1
make_cluster <- makeCluster(clusters)
registerDoParallel(make_cluster)

# Le indicamos validación cruzada repetida
control <- trainControl(method = "repeatedcv",number=5,repeats=5,savePredictions = "all",
                        classProbs=TRUE) 

# Creamos el grid tuneado
SVMgrid <- expand.grid(C=c(0.01,0.02,0.03,0.04,0.05,0.06,0.07,0.08,0.1))

# Lanzamos la función del modelo
SVMLin1 <- train(factor(Satisfaction)~Customer_Loyal.Customer+Travel_Personal.Travel+
                         Class_Eco.Plus+WiFi_Sat_X1+Online_Board_Sat_X1+Online_Board_Sat_X3+
                         Entertainment_Sat_X3+On_board_Sat_X3+Leg_Sat_X2+Leg_Sat_X3+Checkin_Sat_X3,
              data=air_prep,method="svmLinear",trControl=control,tuneGrid=SVMgrid,verbose=FALSE)
SVMLin1$results
 
plot(SVMLin1$results$C,SVMLin1$results$Accuracy)

# Finalizamos la paralelización
stopCluster(make_cluster)
registerDoSEQ()
```

```{r layout="l-body-outset", fig.width=50, fig.asp = .99, echo=FALSE}
knitr::include_graphics("/Users/leztin/Desktop/Captura de pantalla 2023-05-16 a las 19.18.50.png")  
```

```{r layout="l-body-outset", fig.width=50, fig.asp = .99, echo=FALSE}
knitr::include_graphics("/Users/leztin/Desktop/Captura de pantalla 2023-05-16 a las 19.18.35.png")  
```

Finalmente, el **modelo SVM Lineal** para el primer set de variables ha encontrado su configuración óptima con el **hiperparámetro** `C` **que se muestra a continuación**.

```{r eval=FALSE}
SVMLin1$bestTune
```

```{r layout="l-body-outset", fig.width=50, fig.asp = .99, echo=FALSE}
knitr::include_graphics("/Users/leztin/Desktop/Captura de pantalla 2023-05-16 a las 19.19.48.png")  
```

Y los resultados en cuanto a **accuracy** son los siguientes:

```{r eval=FALSE}
SVMLin1$results |> filter(C == SVMLin1$bestTune$C)
```

```{r layout="l-body-outset", fig.width=50, fig.asp = .99, echo=FALSE}
knitr::include_graphics("/Users/leztin/Desktop/Captura de pantalla 2023-05-16 a las 19.20.41.png")  
```

A continuación probaremos el mismo modelo, pero para el **segundo set de variables**:

### Aplicación al segundo set de variables (Step repetido con el Criterio de Información BIC)

Recordemos que este primer set presenta **trece variables predictoras**.
El **grid** para el modelo **SVM Lineal presenta únicamente el parámetro** `C`, por lo que, antes de mostrar los resultados, voy a comentar el vector que he seleccionado para este hiperparámetro.
El vector es el siguiente: `c(1.1,1.3,1.4,1.5,1.7)`.
El valor óptimo resultó posicionarse en torno al `1.4`, por lo que el resto de valores son cercanos a esa cifra.

```{r eval=FALSE}
# Fijamos semilla
set.seed(12346)

# Inicializamos la paralelización
clusters <- detectCores() - 1
make_cluster <- makeCluster(clusters)
registerDoParallel(make_cluster)

# Le indicamos validación cruzada repetida
control <- trainControl(method = "repeatedcv",number=5,repeats=5,savePredictions = "all",
                        classProbs=TRUE) 

# Creamos el grid tuneado
SVMgrid <- expand.grid(C=c(1,1.1,1.3,1.4,1.5,1.7))

# Lanzamos la función del modelo
SVMLin <- train(factor(Satisfaction)~Online_Board_Sat_X1+Travel_Personal.Travel+
                         WiFi_Sat_X1+Customer_Loyal.Customer+WiFi_Sat_X2+Baggage_Sat_X3+
                         +Baggage_Sat_X2+Class_Eco.Plus+Checkin_Sat_X3+Online_Board_Sat_X3+
                         Dep_Arr_Sat_X3+Inflight_Sat_X3+Seat_Sat_X3,
              data=air_prep,method="svmLinear",trControl=control,tuneGrid=SVMgrid,verbose=FALSE)
SVMLin$results
 
plot(SVMLin$results$C,SVMLin$results$Accuracy)

# Finalizamos la paralelización
stopCluster(make_cluster)
registerDoSEQ()
```

```{r layout="l-body-outset", fig.width=50, fig.asp = .99, echo=FALSE}
knitr::include_graphics("/Users/leztin/Desktop/Captura de pantalla 2023-05-16 a las 19.22.51.png")  
```

```{r layout="l-body-outset", fig.width=50, fig.asp = .99, echo=FALSE}
knitr::include_graphics("/Users/leztin/Desktop/Captura de pantalla 2023-05-16 a las 19.22.43.png")  
```

Finalmente, el **modelo SVM Lineal** para el segundo set de variables ha encontrado su configuración óptima con el **hiperparámetro** `C` **que se muestra a continuación**.

```{r eval=FALSE}
SVMLin$bestTune
```

```{r layout="l-body-outset", fig.width=50, fig.asp = .99, echo=FALSE}
knitr::include_graphics("/Users/leztin/Desktop/Captura de pantalla 2023-05-16 a las 19.23.50.png")  
```

Y los resultados en cuanto a **accuracy** son los siguientes:

```{r eval=FALSE}
SVMLin$results |> filter(C == SVMLin$bestTune$C)
```

```{r layout="l-body-outset", fig.width=50, fig.asp = .99, echo=FALSE}
knitr::include_graphics("/Users/leztin/Desktop/Captura de pantalla 2023-05-16 a las 19.24.32.png")  
```

A continuación utilizamos `cruzadaSVMbin()` aplicando **los mejores hiperparámetros** para cada set de variables.

```{r}
source("/Users/leztin/Library/Mobile Documents/com~apple~CloudDocs/Universidad/Máster/Segundo cuatrimestre/Técnicas de Machine Learning/SVM machine learning/cruzada SVM binaria lineal.R")

SVMLin_MMPC <- cruzadaSVMbin(data=air_prep, vardep="Satisfaction",
                           listconti=c("Customer_Loyal.Customer", "Travel_Personal.Travel",
                                       "Class_Eco.Plus", "WiFi_Sat_X1", "Online_Board_Sat_X1",
                                       "Online_Board_Sat_X3", "Entertainment_Sat_X3", "On_board_Sat_X3",
                                       "Leg_Sat_X2", "Leg_Sat_X3", "Checkin_Sat_X3"),
                           listclass=c(""),
                       grupos=5,sinicio=1234,repe=5,C=0.06)

SVMLin_MMPC$Modelo = "SVM Lineal \n Primer set"
SVMLin_MMPC$N_variables = "11"

SVMLin_BIC <- cruzadaSVMbin(data=air_prep, vardep="Satisfaction",
                           listconti=c("Online_Board_Sat_X1", "Travel_Personal.Travel", "WiFi_Sat_X1",
                                       "Customer_Loyal.Customer", "WiFi_Sat_X2", "Baggage_Sat_X3",
                                       "Baggage_Sat_X2", "Class_Eco.Plus", "Checkin_Sat_X3",
                                       "Online_Board_Sat_X3", "Dep_Arr_Sat_X3", "Inflight_Sat_X3",
                                       "Seat_Sat_X3"),
                           listclass=c(""),
                       grupos=5,sinicio=1234,repe=5,C=1.5)

SVMLin_BIC$Modelo = "SVM Lineal \n Segundo set"
SVMLin_BIC$N_variables = "13"
```

### Comparativa parcial entre los modelos elaborados hasta el momento

```{r}
# Unimos todos los valores en un dataframe
select_final <-
  rbind(graf_MMPC, graf_repetido_BIC_set1, Red_MMPC_tun, 
        Red_step_BIC_tun, Bag_MMPC_3, Bag_BIC_2, RF_MMPC, RF_BIC,
        GB_MMPC, GB_BIC, XGB_MMPC, XGB_BIC, SVMLin_MMPC, SVMLin_BIC)
```

```{r layout="l-body-outset", fig.width=20, fig.asp = .99}
# Boxplot de la tasa de error para cada modelo
 a <- ggplot(data = select_final, aes(x = reorder(Modelo, tasa), y = tasa)) +
  geom_boxplot() +
  labs(x = NULL, y = "Tasa de error", title = "Distribución del error según los distintos modelos seleccionados") +
  theme_minimal() +
  theme(text = element_text(face = "bold", size = 15), plot.title = element_text(hjust = 0.5), 
        axis.title.x = element_text(vjust=-0.5)) +
  geom_label(aes(label = N_variables, y = 0.06), size = 6) +
  scale_x_discrete(guide = guide_axis(angle = 50))

# Boxplot de la tasa AUC para cada modelo
 b <- ggplot(data = select_final, aes(x = reorder(Modelo, -auc), y = auc)) +
  geom_boxplot() +
  labs(x = NULL, y = "AUC", title = "Distribución de la tasa AUC según los distintos modelos seleccionados") +
  theme_minimal() +
  theme(text = element_text(face = "bold", size = 15), plot.title = element_text(hjust = 0.5), 
        axis.title.x = element_text(vjust=-0.5)) +
  geom_label(aes(label = N_variables, y = 0.96), size = 6) +
  scale_x_discrete(guide = guide_axis(angle = 50))
 
Rmisc::multiplot(a, b)
```

Como se puede observar, los **modelos SVM lineales no han obtenido resultados muy satisfactorios** en comparación con el resto de modelos.
De hecho, **el resultado en relación al AUC** con el primer set es el peor de entre todos los modelos que llevamos.
A continuación probaremos con otra tipología de SVM conocida como **SVM polinomial**.

## SVM Polinomial

El **SVM (Support Vector Machine) Polinomial** es una variante del algoritmo SVM que utiliza una función de **kernel polinomial** para mapear los datos a un espacio de mayor dimensión, **donde las muestras pueden ser separadas por un hiperplano**.

### Aplicación al primer set de variables (Algoritmo MMPC)

Recordemos que este primer set presenta **once variables predictoras**.
El **grid** para el modelo **SVM Polinomial presenta tres parámetros para tunear**, por lo que, antes de mostrar los resultados, voy a comentar las opciones por las que me he ido decantando.
Tras varias pruebas, la configuración final es la siguiente:

1.  `C`: El vector para este parámetro es el siguiente: `c(0.7,0.8,0.9,1,1.1,1.2,1.3)`. El valor óptimo se encontraba cerca del 0.9, por lo que generé un vector de números cercanos a ese valor principal.
2.  `degree`: El vector para este parámetro es el siguiente: `c(5,6,7)`. El valor óptimo se encontraba cerca del 6, finalmente nos decantamos por el sexto grado.
3.  `scale`: El vector para este parámetro es el siguiente: `c(0.001,0.003,0.005,0.01,0.05,0.1)`. El valor óptimo se encontraba cerca del 0.01, por lo que generé un vector de números cercanos a ese valor principal.

```{r eval=FALSE}
# Fijamos semilla
set.seed(12346)

# Inicializamos la paralelización
clusters <- detectCores() - 1
make_cluster <- makeCluster(clusters)
registerDoParallel(make_cluster)

# Le indicamos validación cruzada repetida
control <- trainControl(method = "repeatedcv",number=5,repeats=5,savePredictions = "all",
                        classProbs=TRUE) 

# Creamos el grid tuneado
SVMgrid <- expand.grid(C=c(0.7,0.8,0.9,1,1.1,1.2,1.3),
                       degree=c(5,6,7),scale=c(0.001,0.003,0.005,0.01,0.05,0.1))

# Lanzamos la función del modelo
SVMPol1 <- train(factor(Satisfaction)~Customer_Loyal.Customer+Travel_Personal.Travel+
                         Class_Eco.Plus+WiFi_Sat_X1+Online_Board_Sat_X1+Online_Board_Sat_X3+
                         Entertainment_Sat_X3+On_board_Sat_X3+Leg_Sat_X2+Leg_Sat_X3+Checkin_Sat_X3,
              data=air_prep,method="svmPoly",trControl=control,tuneGrid=SVMgrid,verbose=FALSE)
SVMPol1$results
 
plot(SVMPol1$results$C,SVMPol1$results$Accuracy)

# Finalizamos la paralelización
stopCluster(make_cluster)
registerDoSEQ()
```

```{r layout="l-body-outset", fig.width=50, fig.asp = .99, echo=FALSE}
knitr::include_graphics("/Users/leztin/Desktop/Captura de pantalla 2023-05-16 a las 19.28.33.png")  
```

```{r layout="l-body-outset", fig.width=50, fig.asp = .99, echo=FALSE}
knitr::include_graphics("/Users/leztin/Desktop/Captura de pantalla 2023-05-16 a las 19.28.27.png")  
```

Finalmente, el **modelo SVM Polinomial** para el primer set de variables ha encontrado su configuración óptima con los **hiperparámetros que se muestran a continuación**.

```{r eval=FALSE}
SVMPol1$bestTune
```

```{r layout="l-body-outset", fig.width=50, fig.asp = .99, echo=FALSE}
knitr::include_graphics("/Users/leztin/Desktop/Captura de pantalla 2023-05-16 a las 19.29.37.png")  
```

Y los resultados en cuanto a **accuracy** son los siguientes:

```{r eval=FALSE}
SVMPol1$results |> filter(C == SVMPol1$bestTune$C &
                         degree == SVMPol1$bestTune$degree & 
                         scale == SVMPol1$bestTune$scale)
```

```{r layout="l-body-outset", fig.width=50, fig.asp = .99, echo=FALSE}
knitr::include_graphics("/Users/leztin/Desktop/Captura de pantalla 2023-05-16 a las 19.30.27.png")  
```

A continuación probaremos el mismo modelo, pero para el **segundo set de variables**:

### Aplicación al segundo set de variables (Step repetido con el Criterio de Información BIC)

Recordemos que este segundo set presenta **trece variables predictoras**.
Al igual que en el anterior apartado, tras varias pruebas, la configuración final es la siguiente:

1.  `C`: El vector para este parámetro es el siguiente: `c(0.4,0.5,0.6,0.7,0.8,0.9)`. El valor óptimo se encontraba cerca del 0.6, por lo que generé un vector de números cercanos a ese valor principal.
2.  `degree`: El vector para este parámetro es el siguiente: `c(2,3,4)`. El valor óptimo se encontraba cerca del 3, finalmente nos decantamos por el tercer grado.
3.  `scale`: El vector para este parámetro es el siguiente: `c(0.01,0.03,0.04,0.05,0.06,0.07,0.1)`. El valor óptimo se encontraba cerca del 0.04, por lo que generé un vector de números cercanos a ese valor principal.

```{r eval=FALSE}
# Fijamos semilla
set.seed(12346)

# Inicializamos la paralelización
clusters <- detectCores() - 1
make_cluster <- makeCluster(clusters)
registerDoParallel(make_cluster)

# Le indicamos validación cruzada repetida
control <- trainControl(method = "repeatedcv",number=5,repeats=5,savePredictions = "all",
                        classProbs=TRUE) 

# Creamos el grid tuneado
SVMgrid <- expand.grid(C=c(0.4,0.5,0.6,0.7,0.8,0.9),
                       degree=c(2,3,4),scale=c(0.01,0.03,0.04,0.05,0.06,0.07,0.1))

# Lanzamos la función del modelo
SVMPol <- train(factor(Satisfaction)~Online_Board_Sat_X1+Travel_Personal.Travel+
                         WiFi_Sat_X1+Customer_Loyal.Customer+WiFi_Sat_X2+Baggage_Sat_X3+
                         +Baggage_Sat_X2+Class_Eco.Plus+Checkin_Sat_X3+Online_Board_Sat_X3+
                         Dep_Arr_Sat_X3+Inflight_Sat_X3+Seat_Sat_X3,
              data=air_prep,method="svmPoly",trControl=control,tuneGrid=SVMgrid,verbose=FALSE)
SVMPol$results
 
plot(SVMPol$results$C,SVMPol$results$Accuracy)

# Finalizamos la paralelización
stopCluster(make_cluster)
registerDoSEQ()
```

```{r layout="l-body-outset", fig.width=50, fig.asp = .99, echo=FALSE}
knitr::include_graphics("/Users/leztin/Desktop/Captura de pantalla 2023-05-16 a las 19.31.35.png")  
```

```{r layout="l-body-outset", fig.width=50, fig.asp = .99, echo=FALSE}
knitr::include_graphics("/Users/leztin/Desktop/Captura de pantalla 2023-05-16 a las 19.31.33.png")  
```

Finalmente, el **modelo SVM Polinomial** para el segundo set de variables ha encontrado su configuración óptima con los **hiperparámetros que se muestran a continuación**.

```{r eval=FALSE}
SVMPol$bestTune
```

```{r layout="l-body-outset", fig.width=50, fig.asp = .99, echo=FALSE}
knitr::include_graphics("/Users/leztin/Desktop/Captura de pantalla 2023-05-16 a las 19.32.50.png")  
```

Y los resultados en cuanto a **accuracy** son los siguientes:

```{r eval=FALSE}
SVMPol$results |> filter(C == SVMPol$bestTune$C &
                         degree == SVMPol$bestTune$degree & 
                         scale == SVMPol$bestTune$scale)
```

```{r layout="l-body-outset", fig.width=50, fig.asp = .99, echo=FALSE}
knitr::include_graphics("/Users/leztin/Desktop/Captura de pantalla 2023-05-16 a las 19.33.32.png")  
```

A continuación utilizamos `cruzadaSVMbinPoly()` aplicando **los mejores hiperparámetros** para cada set de variables.

```{r}
source("/Users/leztin/Library/Mobile Documents/com~apple~CloudDocs/Universidad/Máster/Segundo cuatrimestre/Técnicas de Machine Learning/SVM machine learning/cruzada SVM binaria polinomial.R")

SVMPol_MMPC <- cruzadaSVMbinPoly(data=air_prep, vardep="Satisfaction",
                           listconti=c("Customer_Loyal.Customer", "Travel_Personal.Travel",
                                       "Class_Eco.Plus", "WiFi_Sat_X1", "Online_Board_Sat_X1",
                                       "Online_Board_Sat_X3", "Entertainment_Sat_X3", "On_board_Sat_X3",
                                       "Leg_Sat_X2", "Leg_Sat_X3", "Checkin_Sat_X3"),
                           listclass=c(""),
                       grupos=5,sinicio=1234,repe=5,C=1.2,degree=6,scale=0.005)

SVMPol_MMPC$Modelo = "SVM Polinomial \n Primer set"
SVMPol_MMPC$N_variables = "11"

SVMPol_BIC <- cruzadaSVMbinPoly(data=air_prep, vardep="Satisfaction",
                           listconti=c("Online_Board_Sat_X1", "Travel_Personal.Travel", "WiFi_Sat_X1",
                                       "Customer_Loyal.Customer", "WiFi_Sat_X2", "Baggage_Sat_X3",
                                       "Baggage_Sat_X2", "Class_Eco.Plus", "Checkin_Sat_X3",
                                       "Online_Board_Sat_X3", "Dep_Arr_Sat_X3", "Inflight_Sat_X3",
                                       "Seat_Sat_X3"),
                           listclass=c(""),
                       grupos=5,sinicio=1234,repe=5,C=0.7,degree=3,scale=0.03)

SVMPol_BIC$Modelo = "SVM Polinomial \n Segundo set"
SVMPol_BIC$N_variables = "13"
```

### Comparativa parcial entre los modelos elaborados hasta el momento

```{r}
# Unimos todos los valores en un dataframe
select_final <-
  rbind(graf_MMPC, graf_repetido_BIC_set1, Red_MMPC_tun, 
        Red_step_BIC_tun, Bag_MMPC_3, Bag_BIC_2, RF_MMPC, RF_BIC,
        GB_MMPC, GB_BIC, XGB_MMPC, XGB_BIC, SVMLin_MMPC, SVMLin_BIC,
        SVMPol_MMPC, SVMPol_BIC)
```

```{r layout="l-body-outset", fig.width=20, fig.asp = .99}
# Boxplot de la tasa de error para cada modelo
 a <- ggplot(data = select_final, aes(x = reorder(Modelo, tasa), y = tasa)) +
  geom_boxplot() +
  labs(x = NULL, y = "Tasa de error", title = "Distribución del error según los distintos modelos seleccionados") +
  theme_minimal() +
  theme(text = element_text(face = "bold", size = 15), plot.title = element_text(hjust = 0.5), 
        axis.title.x = element_text(vjust=-0.5)) +
  geom_label(aes(label = N_variables, y = 0.06), size = 6) +
  scale_x_discrete(guide = guide_axis(angle = 50))

# Boxplot de la tasa AUC para cada modelo
 b <- ggplot(data = select_final, aes(x = reorder(Modelo, -auc), y = auc)) +
  geom_boxplot() +
  labs(x = NULL, y = "AUC", title = "Distribución de la tasa AUC según los distintos modelos seleccionados") +
  theme_minimal() +
  theme(text = element_text(face = "bold", size = 15), plot.title = element_text(hjust = 0.5), 
        axis.title.x = element_text(vjust=-0.5)) +
  geom_label(aes(label = N_variables, y = 0.955), size = 6) +
  scale_x_discrete(guide = guide_axis(angle = 50))
 
Rmisc::multiplot(a, b)
```

Como se puede observar, los **modelos SVM polinomiales tampoco han obtenido resultados muy satisfactorios** en comparación con el resto de modelos, **al menos en lo que respecta al AUC**.
Si atendemos a la **tasa de error**, el **modelo SVM Polinomial del segundo set** es el que **menos error ha obtenido en sus predicciones**: cerca del **0.065**.
A continuación probaremos con la última tipología de SVM conocida como **SVM Radial**.

## SVM Radial

El **SVM (Support Vector Machine) Radial** es una variante del algoritmo SVM que utiliza una función de **kernel radial**, como la **función Gaussiana**, para realizar la clasificación de datos.
Permite capturar **relaciones no lineales y manejar problemas de clasificación en los que los datos no son linealmente separables en el espacio de entrada original**.
El parámetro **sigma** controla la forma y el tamaño de las regiones de influencia de las muestras en la función de kernel radial.

### Aplicación al primer set de variables (Algoritmo MMPC)

Recordemos que este primer set presenta **once variables predictoras**.
El **grid** para el modelo **SVM Radial presenta dos parámetros para tunear**, por lo que, antes de mostrar los resultados, voy a comentar las opciones por las que me he ido decantando.
Tras varias pruebas, la configuración final es la siguiente:

1.  `C`: El vector para este parámetro es el siguiente: `c(7,8,9,10,11,12,13)`. El valor óptimo se encontraba cerca del 10, por lo que generé un vector de números cercanos a ese valor principal.
2.  `sigma`: El vector para este parámetro es el siguiente: `c(0.001,0.003,0.005,0.007,0.009)`. El valor óptimo se encontraba cerca del 0.005, por lo que generé un vector de números cercanos a ese valor principal.

```{r eval=FALSE}
# Fijamos semilla
set.seed(12346)

# Inicializamos la paralelización
clusters <- detectCores() - 1
make_cluster <- makeCluster(clusters)
registerDoParallel(make_cluster)

# Le indicamos validación cruzada repetida
control <- trainControl(method = "repeatedcv",number=5,repeats=5,savePredictions = "all",
                        classProbs=TRUE) 

# Creamos el grid tuneado
SVMgrid <- expand.grid(C=c(7,8,9,10,11,12,13),
                     sigma=c(0.001,0.003,0.005,0.007,0.009))

# Lanzamos la función del modelo
SVMRad1 <- train(factor(Satisfaction)~Customer_Loyal.Customer+Travel_Personal.Travel+
                         Class_Eco.Plus+WiFi_Sat_X1+Online_Board_Sat_X1+Online_Board_Sat_X3+
                         Entertainment_Sat_X3+On_board_Sat_X3+Leg_Sat_X2+Leg_Sat_X3+Checkin_Sat_X3,
              data=air_prep,method="svmRadial",trControl=control,tuneGrid=SVMgrid,verbose=FALSE)
SVMRad1$results
 
plot(SVMRad1$results$C,SVMRad1$results$Accuracy)

# Finalizamos la paralelización
stopCluster(make_cluster)
registerDoSEQ()
```

```{r layout="l-body-outset", fig.width=50, fig.asp = .99, echo=FALSE}
knitr::include_graphics("/Users/leztin/Desktop/Captura de pantalla 2023-05-16 a las 19.36.41.png")  
```

```{r layout="l-body-outset", fig.width=50, fig.asp = .99, echo=FALSE}
knitr::include_graphics("/Users/leztin/Desktop/Captura de pantalla 2023-05-16 a las 19.36.39.png")  
```

Finalmente, el **modelo SVM Radial** para el primer set de variables ha encontrado su configuración óptima con los **hiperparámetros que se muestran a continuación**.

```{r eval=FALSE}
SVMRad1$bestTune
```

```{r layout="l-body-outset", fig.width=50, fig.asp = .99, echo=FALSE}
knitr::include_graphics("/Users/leztin/Desktop/Captura de pantalla 2023-05-16 a las 19.37.42.png")  
```

Y los resultados en cuanto a **accuracy** son los siguientes:

```{r eval=FALSE}
SVMRad1$results |> filter(C == SVMRad1$bestTune$C,
                         sigma == SVMRad1$bestTune$sigma)
```

```{r layout="l-body-outset", fig.width=50, fig.asp = .99, echo=FALSE}
knitr::include_graphics("/Users/leztin/Desktop/Captura de pantalla 2023-05-16 a las 19.38.32.png")  
```

A continuación probaremos el mismo modelo, pero para el **segundo set de variables**:

### Aplicación al segundo set de variables (Step repetido con el Criterio de Información BIC)

Recordemos que este segundo set presenta **trece variables predictoras**.
Al igual que en el anterior apartado, tras varias pruebas, la configuración final es la siguiente:

1.  `C`: El vector para este parámetro es el siguiente: `c(9,10,11,12,13,14,15)`. El valor óptimo se encontraba cerca del 12, por lo que generé un vector de números cercanos a ese valor principal.
2.  `sigma`: El vector para este parámetro es el siguiente: `c(0.007,0.009,0.01,0.02,0.03,0.04)`. El valor óptimo se encontraba cerca del 0.01, por lo que generé un vector de números cercanos a ese valor principal.

```{r eval=FALSE}
# Fijamos semilla
set.seed(12346)

# Inicializamos la paralelización
clusters <- detectCores() - 1
make_cluster <- makeCluster(clusters)
registerDoParallel(make_cluster)

# Le indicamos validación cruzada repetida
control <- trainControl(method = "repeatedcv",number=5,repeats=5,savePredictions = "all",
                        classProbs=TRUE) 

# Creamos el grid tuneado
SVMgrid <- expand.grid(C=c(9,10,11,12,13,14,15),
                     sigma=c(0.007,0.009,0.01,0.02,0.03,0.04))

# Lanzamos la función del modelo
SVMRad <- train(factor(Satisfaction)~Online_Board_Sat_X1+Travel_Personal.Travel+
                         WiFi_Sat_X1+Customer_Loyal.Customer+WiFi_Sat_X2+Baggage_Sat_X3+
                         +Baggage_Sat_X2+Class_Eco.Plus+Checkin_Sat_X3+Online_Board_Sat_X3+
                         Dep_Arr_Sat_X3+Inflight_Sat_X3+Seat_Sat_X3,
              data=air_prep,method="svmRadial",trControl=control,tuneGrid=SVMgrid,verbose=FALSE)
SVMRad$results
 
plot(SVMRad$results$C,SVMRad$results$Accuracy)

# Finalizamos la paralelización
stopCluster(make_cluster)
registerDoSEQ()
```

```{r layout="l-body-outset", fig.width=50, fig.asp = .99, echo=FALSE}
knitr::include_graphics("/Users/leztin/Desktop/Captura de pantalla 2023-05-16 a las 19.39.28.png")  
```

```{r layout="l-body-outset", fig.width=50, fig.asp = .99, echo=FALSE}
knitr::include_graphics("/Users/leztin/Desktop/Captura de pantalla 2023-05-16 a las 19.39.26.png")  
```

Finalmente, el **modelo SVM Radial** para el segundo set de variables ha encontrado su configuración óptima con los **hiperparámetros que se muestran a continuación**.

```{r eval=FALSE}
SVMRad$bestTune
```

```{r layout="l-body-outset", fig.width=50, fig.asp = .99, echo=FALSE}
knitr::include_graphics("/Users/leztin/Desktop/Captura de pantalla 2023-05-16 a las 19.40.31.png")  
```

Y los resultados en cuanto a **accuracy** son los siguientes:

```{r eval=FALSE}
SVMRad$results |> filter(C == SVMRad$bestTune$C,
                         sigma == SVMRad$bestTune$sigma)
```

```{r layout="l-body-outset", fig.width=50, fig.asp = .99, echo=FALSE}
knitr::include_graphics("/Users/leztin/Desktop/Captura de pantalla 2023-05-16 a las 19.41.06.png")  
```

A continuación utilizamos `cruzadaSVMbinRBF()` aplicando **los mejores hiperparámetros** para cada set de variables.

```{r}
source("/Users/leztin/Library/Mobile Documents/com~apple~CloudDocs/Universidad/Máster/Segundo cuatrimestre/Técnicas de Machine Learning/SVM machine learning/cruzada SVM binaria RBF.R")

SVMRad_MMPC <- cruzadaSVMbinRBF(data=air_prep, vardep="Satisfaction",
                           listconti=c("Customer_Loyal.Customer", "Travel_Personal.Travel",
                                       "Class_Eco.Plus", "WiFi_Sat_X1", "Online_Board_Sat_X1",
                                       "Online_Board_Sat_X3", "Entertainment_Sat_X3", "On_board_Sat_X3",
                                       "Leg_Sat_X2", "Leg_Sat_X3", "Checkin_Sat_X3"),
                           listclass=c(""),
                       grupos=5,sinicio=1234,repe=5,C=10,sigma=0.005)

SVMRad_MMPC$Modelo = "SVM Radial \n Primer set"
SVMRad_MMPC$N_variables = "11"

SVMRad_BIC <- cruzadaSVMbinRBF(data=air_prep, vardep="Satisfaction",
                           listconti=c("Online_Board_Sat_X1", "Travel_Personal.Travel", "WiFi_Sat_X1",
                                       "Customer_Loyal.Customer", "WiFi_Sat_X2", "Baggage_Sat_X3",
                                       "Baggage_Sat_X2", "Class_Eco.Plus", "Checkin_Sat_X3",
                                       "Online_Board_Sat_X3", "Dep_Arr_Sat_X3", "Inflight_Sat_X3",
                                       "Seat_Sat_X3"),
                           listclass=c(""),
                       grupos=5,sinicio=1234,repe=5,C=11,sigma=0.02)

SVMRad_BIC$Modelo = "SVM Radial \n Segundo set"
SVMRad_BIC$N_variables = "13"
```

### Comparativa parcial entre los modelos elaborados hasta el momento

```{r}
# Unimos todos los valores en un dataframe
select_final <-
  rbind(graf_MMPC, graf_repetido_BIC_set1, Red_MMPC_tun, 
        Red_step_BIC_tun, Bag_MMPC_3, Bag_BIC_2, RF_MMPC, RF_BIC,
        GB_MMPC, GB_BIC, XGB_MMPC, XGB_BIC, SVMLin_MMPC, SVMLin_BIC,
        SVMPol_MMPC, SVMPol_BIC, SVMRad_MMPC, SVMRad_BIC)
```

```{r layout="l-body-outset", fig.width=20, fig.asp = .99}
# Boxplot de la tasa de error para cada modelo
 a <- ggplot(data = select_final, aes(x = reorder(Modelo, tasa), y = tasa)) +
  geom_boxplot() +
  labs(x = NULL, y = "Tasa de error", title = "Distribución del error según los distintos modelos seleccionados") +
  theme_minimal() +
  theme(text = element_text(face = "bold", size = 15), plot.title = element_text(hjust = 0.5), 
        axis.title.x = element_text(vjust=-0.5)) +
  geom_label(aes(label = N_variables, y = 0.06), size = 6) +
  scale_x_discrete(guide = guide_axis(angle = 50))

# Boxplot de la tasa AUC para cada modelo
 b <- ggplot(data = select_final, aes(x = reorder(Modelo, -auc), y = auc)) +
  geom_boxplot() +
  labs(x = NULL, y = "AUC", title = "Distribución de la tasa AUC según los distintos modelos seleccionados") +
  theme_minimal() +
  theme(text = element_text(face = "bold", size = 15), plot.title = element_text(hjust = 0.5), 
        axis.title.x = element_text(vjust=-0.5)) +
  geom_label(aes(label = N_variables, y = 0.955), size = 6) +
  scale_x_discrete(guide = guide_axis(angle = 50))
 
Rmisc::multiplot(a, b)
```

Como se puede observar, los **modelos SVM radiales tampoco han obtenido resultados muy satisfactorios** en comparación con el resto de modelos, **al menos en lo que respecta al AUC**.
Si atendemos a la **tasa de error**, el **modelo SVM Radial del segundo set** es el que **menos error ha obtenido en sus predicciones**: cerca del **0.06**.
A continuación probaremos con las **técnicas de ensamblado**, a través de las cuales podremos combinar los mejores modelos para obtener **nuevos resultados**.

# Fase 7.9: Ensamblado

El **ensamblado** en Machine Learning es una técnica que consiste en **combinar las predicciones de múltiples modelos base para obtener una predicción final más precisa y robusta**.
El objetivo del ensamblado es aprovechar la diversidad y la complementariedad de los modelos base para mejorar el **rendimiento general del modelo**.

## Aplicación al primer set de variables (Algoritmo MMPC)

Para calcular las **predicciones** que nos servirán para el ensamblado emplearemos las funciones provistas en el archivo **«cruzadas ensamblado binaria fuente.R»**.
Antes de ejecutarlas, añadiremos a cada una de ellas los **mejores hiperparámetros** que fuimos configurando en anteriores apartados para cada uno de los modelos.

```{r echo=FALSE}
source("/Users/leztin/Library/Mobile Documents/com~apple~CloudDocs/Universidad/Máster/Segundo cuatrimestre/Técnicas de Machine Learning/Ensamblado/cruzadas ensamblado binaria fuente.R")
```

```{r eval=FALSE}
# Aplicamos las funciones provistas en el siguiente script
source("/Users/leztin/Library/Mobile Documents/com~apple~CloudDocs/Universidad/Máster/Segundo cuatrimestre/Técnicas de Machine Learning/Ensamblado/cruzadas ensamblado binaria fuente.R")

# Regresión logística
graf_MMPC_ensam <- 
  cruzadalogistica(data = air_prep_matrix, vardep = "Satisfaction", 
             listconti = c("Customer_Loyal.Customer", "Travel_Personal.Travel", "Class_Eco.Plus", 
                           "WiFi_Sat_X1", "Online_Board_Sat_X1", "Online_Board_Sat_X3", 
                           "Entertainment_Sat_X3", "On_board_Sat_X3", "Leg_Sat_X2", "Leg_Sat_X3", 
                           "Checkin_Sat_X3"),
             listclass = c(""), grupos = 5, sinicio = 12346, repe = 10)

graf_MMPC_ensam$Modelo = "Reg. logist. \n Primer set"
graf_MMPC_ensam$N_variables = "11"

graf_MMPC_bis <- as.data.frame(graf_MMPC_ensam[1])
graf_MMPC_pred <- as.data.frame(graf_MMPC_ensam[2])
graf_MMPC_pred$logi <- graf_MMPC_pred$Yes

# Red neuronal
Red_MMPC_tun_ensam <-
  cruzadaavnnetbin(data = air_prep, vardep = "Satisfaction",
                listconti = c("Customer_Loyal.Customer", "Travel_Personal.Travel", "Class_Eco.Plus", 
                           "WiFi_Sat_X1", "Online_Board_Sat_X1", "Online_Board_Sat_X3", 
                           "Entertainment_Sat_X3", "On_board_Sat_X3", "Leg_Sat_X2", "Leg_Sat_X3", 
                           "Checkin_Sat_X3"),
                listclass = c(""), grupos = 5, sinicio = 12346, repe = 10, repeticiones = 5,
                itera = 300, size = c(5), decay = c(0.1))

Red_MMPC_tun_ensam$Modelo = "Red neuronal tuneada \n Primer set"
Red_MMPC_tun_ensam$N_variables = "11"

Red_MMPC_tun_bis <- as.data.frame(Red_MMPC_tun_ensam[1])
Red_MMPC_tun_pred <- as.data.frame(Red_MMPC_tun_ensam[2])
Red_MMPC_tun_pred$avnnet <- Red_MMPC_tun_pred$Yes

# Bagging
Bag_MMPC_3_ensam <- 
  cruzadarfbin(data=air_prep, vardep="Satisfaction",
               listconti=c("Customer_Loyal.Customer","Travel_Personal.Travel","Class_Eco.Plus",
                           "WiFi_Sat_X1", "Online_Board_Sat_X1", "Online_Board_Sat_X3",
                           "Entertainment_Sat_X3", "On_board_Sat_X3", "Leg_Sat_X2", "Leg_Sat_X3",
                           "Checkin_Sat_X3"),
               listclass=c(""),grupos=5,sinicio=1234,repe=25,nodesize=10,mtry=11,
               ntree=5000,replace=TRUE,sampsize=500)

Bag_MMPC_3_ensam$Modelo = "Bagging \n Primer set"
Bag_MMPC_3_ensam$N_variables = "11"

Bag_MMPC_3_bis <- as.data.frame(Bag_MMPC_3_ensam[1])
Bag_MMPC_3_pred <- as.data.frame(Bag_MMPC_3_ensam[2])
Bag_MMPC_3_pred$bagging <- Bag_MMPC_3_pred$Yes

# Random Forest
RF_MMPC_ensam <- cruzadarfbin(data=air_prep, vardep="Satisfaction",
                           listconti=c("Customer_Loyal.Customer", "Travel_Personal.Travel",
                                       "Class_Eco.Plus", "WiFi_Sat_X1", "Online_Board_Sat_X1",
                                       "Online_Board_Sat_X3", "Entertainment_Sat_X3", "On_board_Sat_X3",
                                       "Leg_Sat_X2", "Leg_Sat_X3", "Checkin_Sat_X3"),
                           listclass=c(""),
                           grupos=5,sinicio=1234,repe=25,nodesize=10,
                           mtry=6,ntree=5000,replace=TRUE,sampsize=1000)

RF_MMPC_ensam$Modelo = "Random Forest \n Primer set"
RF_MMPC_ensam$N_variables = "11"

RF_MMPC_bis <- as.data.frame(RF_MMPC_ensam[1])
RF_MMPC_pred <- as.data.frame(RF_MMPC_ensam[2])
RF_MMPC_pred$rf <- RF_MMPC_pred$Yes

# Gradient Boosting
GB_MMPC_ensam <- cruzadagbmbin(data=air_prep, vardep="Satisfaction",
                           listconti=c("Customer_Loyal.Customer", "Travel_Personal.Travel",
                                       "Class_Eco.Plus", "WiFi_Sat_X1", "Online_Board_Sat_X1",
                                       "Online_Board_Sat_X3", "Entertainment_Sat_X3", "On_board_Sat_X3",
                                       "Leg_Sat_X2", "Leg_Sat_X3", "Checkin_Sat_X3"),
                           listclass=c(""),
                      grupos=5,sinicio=1234,repe=25,n.minobsinnode=7,
                      shrinkage=0.07,n.trees=800,interaction.depth=2)

GB_MMPC_ensam$Modelo = "Gradient Boosting \n Primer set"
GB_MMPC_ensam$N_variables = "11"

GB_MMPC_bis <- as.data.frame(GB_MMPC_ensam[1])
GB_MMPC_pred <- as.data.frame(GB_MMPC_ensam[2])
GB_MMPC_pred$gbm <- GB_MMPC_pred$Yes

# XGBoost
XGB_MMPC_ensam <- cruzadaxgbmbin(data=air_prep, vardep="Satisfaction",
                           listconti=c("Customer_Loyal.Customer", "Travel_Personal.Travel",
                                       "Class_Eco.Plus", "WiFi_Sat_X1", "Online_Board_Sat_X1",
                                       "Online_Board_Sat_X3", "Entertainment_Sat_X3", "On_board_Sat_X3",
                                       "Leg_Sat_X2", "Leg_Sat_X3", "Checkin_Sat_X3"),
                           listclass=c(""),
                          grupos=5,sinicio=1234,repe=25,
                          min_child_weight=10,eta=0.03,nrounds=1000,max_depth=10,
                          gamma=0,colsample_bytree=1,subsample=0.9,alpha=0,lambda=0)

XGB_MMPC_ensam$Modelo = "XGBoost \n Primer set"
XGB_MMPC_ensam$N_variables = "11"

XGB_MMPC_bis <- as.data.frame(XGB_MMPC_ensam[1])
XGB_MMPC_pred <- as.data.frame(XGB_MMPC_ensam[2])
XGB_MMPC_pred$xgbm <- XGB_MMPC_pred$Yes

# SVM Lineal
SVMLin_MMPC_ensam <- cruzadaSVMbin(data=air_prep, vardep="Satisfaction",
                           listconti=c("Customer_Loyal.Customer", "Travel_Personal.Travel",
                                       "Class_Eco.Plus", "WiFi_Sat_X1", "Online_Board_Sat_X1",
                                       "Online_Board_Sat_X3", "Entertainment_Sat_X3", "On_board_Sat_X3",
                                       "Leg_Sat_X2", "Leg_Sat_X3", "Checkin_Sat_X3"),
                           listclass=c(""),
                       grupos=5,sinicio=12345,repe=25,C=0.06)

SVMLin_MMPC_ensam$Modelo = "SVM Lineal \n Primer set"
SVMLin_MMPC_ensam$N_variables = "11"

SVMLin_MMPC_bis <- as.data.frame(SVMLin_MMPC_ensam[1])
SVMLin_MMPC_pred <- as.data.frame(SVMLin_MMPC_ensam[2])
SVMLin_MMPC_pred$svmLinear <- SVMLin_MMPC_pred$Yes

# SVM Polinomial
SVMPol_MMPC_ensam <- cruzadaSVMbinPoly(data=air_prep, vardep="Satisfaction",
                           listconti=c("Customer_Loyal.Customer", "Travel_Personal.Travel",
                                       "Class_Eco.Plus", "WiFi_Sat_X1", "Online_Board_Sat_X1",
                                       "Online_Board_Sat_X3", "Entertainment_Sat_X3", "On_board_Sat_X3",
                                       "Leg_Sat_X2", "Leg_Sat_X3", "Checkin_Sat_X3"),
                           listclass=c(""),
                       grupos=5,sinicio=1234,repe=25,C=1.2,degree=6,scale=0.005)

SVMPol_MMPC_ensam$Modelo = "SVM Polinomial \n Primer set"
SVMPol_MMPC_ensam$N_variables = "11"

SVMPol_MMPC_bis <- as.data.frame(SVMPol_MMPC_ensam[1])
SVMPol_MMPC_pred <- as.data.frame(SVMPol_MMPC_ensam[2])
SVMPol_MMPC_pred$svmPoly <- SVMPol_MMPC_pred$Yes

# SVM Radial
SVMRad_MMPC_ensam <- cruzadaSVMbinRBF(data=air_prep, vardep="Satisfaction",
                           listconti=c("Customer_Loyal.Customer", "Travel_Personal.Travel",
                                       "Class_Eco.Plus", "WiFi_Sat_X1", "Online_Board_Sat_X1",
                                       "Online_Board_Sat_X3", "Entertainment_Sat_X3", "On_board_Sat_X3",
                                       "Leg_Sat_X2", "Leg_Sat_X3", "Checkin_Sat_X3"),
                           listclass=c(""),
                       grupos=5,sinicio=12346,repe=25,C=10,sigma=0.005)

SVMRad_MMPC_ensam$Modelo = "SVM Radial \n Primer set"
SVMRad_MMPC_ensam$N_variables = "11"

SVMRad_MMPC_bis <- as.data.frame(SVMRad_MMPC_ensam[1])
SVMRad_MMPC_pred <- as.data.frame(SVMRad_MMPC_ensam[2])
SVMRad_MMPC_pred$svmRadial <- SVMRad_MMPC_pred$Yes
```

Una vez calculadas las funciones, **unimos las predicciones en un único dataset**.

```{r eval=FALSE}
# Generamos el dataframe con las predicciones de todos los modelos elaborados
predicciones <- 
  cbind(graf_MMPC_pred,Red_MMPC_tun_pred,
        RF_MMPC_pred,GB_MMPC_pred,XGB_MMPC_pred,SVMLin_MMPC_pred,
        SVMPol_MMPC_pred,SVMRad_MMPC_pred)

# Eliminamos posibles columnas duplicadas
predicciones <- 
  predicciones[, !duplicated(colnames(predicciones))]
```

### Combinaciones dobles de modelos

Por último, ejecutamos las combinaciones de todos los modelos calculados:

```{r eval=FALSE}
# Combinaciones dobles
predicciones$predi9<-(predicciones$logi+predicciones$avnnet)/2
predicciones$predi10<-(predicciones$logi+predicciones$rf)/2
predicciones$predi11<-(predicciones$logi+predicciones$gbm)/2
predicciones$predi12<-(predicciones$logi+predicciones$xgbm)/2
predicciones$predi13<-(predicciones$logi+predicciones$svmLinear)/2
predicciones$predi14<-(predicciones$logi+predicciones$svmPoly)/2
predicciones$predi15<-(predicciones$logi+predicciones$svmRadial)/2
predicciones$predi16<-(predicciones$avnnet+predicciones$rf)/2
predicciones$predi17<-(predicciones$avnnet+predicciones$gbm)/2
predicciones$predi18<-(predicciones$avnnet+predicciones$xgbm)/2
predicciones$predi19<-(predicciones$avnnet+predicciones$svmLinear)/2
predicciones$predi20<-(predicciones$avnnet+predicciones$svmPoly)/2
predicciones$predi21<-(predicciones$avnnet+predicciones$svmRadial)/2
predicciones$predi22<-(predicciones$rf+predicciones$gbm)/2
predicciones$predi23<-(predicciones$rf+predicciones$xgbm)/2
predicciones$predi24<-(predicciones$rf+predicciones$svmLinear)/2
predicciones$predi25<-(predicciones$rf+predicciones$svmPoly)/2
predicciones$predi26<-(predicciones$rf+predicciones$svmRadial)/2
predicciones$predi27<-(predicciones$gbm+predicciones$xgbm)/2
predicciones$predi28<-(predicciones$gbm+predicciones$svmLinear)/2
predicciones$predi29<-(predicciones$gbm+predicciones$svmPoly)/2
predicciones$predi30<-(predicciones$gbm+predicciones$svmRadial)/2
```

### Combinaciones triples de modelos

```{r eval=FALSE}
# Combinaciones triples
predicciones$predi31<-(predicciones$logi+predicciones$avnnet+predicciones$rf)/3
predicciones$predi32<-(predicciones$logi+predicciones$avnnet+predicciones$gbm)/3
predicciones$predi33<-(predicciones$logi+predicciones$avnnet+predicciones$xgbm)/3
predicciones$predi34<-(predicciones$logi+predicciones$avnnet+predicciones$svmLinear)/3
predicciones$predi35<-(predicciones$logi+predicciones$avnnet+predicciones$svmPoly)/3
predicciones$predi36<-(predicciones$logi+predicciones$avnnet+predicciones$svmRadial)/3
predicciones$predi37<-(predicciones$logi+predicciones$rf+predicciones$gbm)/3
predicciones$predi38<-(predicciones$logi+predicciones$rf+predicciones$xgbm)/3
predicciones$predi39<-(predicciones$logi+predicciones$rf+predicciones$svmLinear)/3
predicciones$predi40<-(predicciones$logi+predicciones$rf+predicciones$svmPoly)/3
predicciones$predi41<-(predicciones$logi+predicciones$rf+predicciones$svmRadial)/3
predicciones$predi42<-(predicciones$logi+predicciones$gbm+predicciones$xgbm)/3
predicciones$predi43<-(predicciones$logi+predicciones$gbm+predicciones$xgbm)/3
predicciones$predi44<-(predicciones$logi+predicciones$gbm+predicciones$svmLinear)/3
predicciones$predi45<-(predicciones$logi+predicciones$gbm+predicciones$svmPoly)/3
predicciones$predi46<-(predicciones$logi+predicciones$gbm+predicciones$svmRadial)/3
predicciones$predi47<-(predicciones$logi+predicciones$xgbm+predicciones$svmLinear)/3
predicciones$predi48<-(predicciones$logi+predicciones$xgbm+predicciones$svmPoly)/3
predicciones$predi49<-(predicciones$logi+predicciones$xgbm+predicciones$svmRadial)/3
predicciones$predi50<-(predicciones$rf+predicciones$gbm+predicciones$svmLinear)/3
predicciones$predi51<-(predicciones$rf+predicciones$gbm+predicciones$svmPoly)/3
predicciones$predi52<-(predicciones$rf+predicciones$gbm+predicciones$svmRadial)/3
predicciones$predi53<-(predicciones$rf+predicciones$xgbm+predicciones$svmLinear)/3
predicciones$predi54<-(predicciones$rf+predicciones$xgbm+predicciones$svmPoly)/3
predicciones$predi55<-(predicciones$rf+predicciones$xgbm+predicciones$svmRadial)/3
predicciones$predi56<-(predicciones$rf+predicciones$avnnet+predicciones$gbm)/3
predicciones$predi57<-(predicciones$rf+predicciones$avnnet+predicciones$xgbm)/3
predicciones$predi58<-(predicciones$rf+predicciones$avnnet+predicciones$svmLinear)/3
predicciones$predi59<-(predicciones$rf+predicciones$avnnet+predicciones$svmPoly)/3
predicciones$predi60<-(predicciones$rf+predicciones$avnnet+predicciones$svmRadial)/3
predicciones$predi61<-(predicciones$avnnet+predicciones$gbm+predicciones$svmLinear)/3
predicciones$predi62<-(predicciones$avnnet+predicciones$gbm+predicciones$svmPoly)/3
predicciones$predi63<-(predicciones$avnnet+predicciones$gbm+predicciones$svmRadial)/3
```

### Combinaciones cuádruples de modelos

```{r eval=FALSE}
# Combianciones cuádruples
predicciones$predi64<-(predicciones$logi+predicciones$rf+predicciones$gbm+predicciones$avnnet)/4
predicciones$predi65<-(predicciones$logi+predicciones$rf+predicciones$xgbm+predicciones$avnnet)/4
predicciones$predi66<-(predicciones$logi+predicciones$rf+predicciones$xgbm+predicciones$avnnet)/4
```

### Combinaciones quíntuples de modelos

```{r eval=FALSE}
# Combinaciones quíntuples
predicciones$predi67<-(predicciones$logi+predicciones$rf+predicciones$xgbm+predicciones$avnnet+predicciones$svmLinear)/5
predicciones$predi68<-(predicciones$logi+predicciones$rf+predicciones$xgbm+predicciones$avnnet+predicciones$svmPoly)/5
predicciones$predi69<-(predicciones$logi+predicciones$rf+predicciones$xgbm+predicciones$avnnet+predicciones$svmRadial)/5
```

Una vez calculadas todas las combinaciones, pasamos a guardar **las variables que queremos representar** en una variable:

```{r eval=FALSE}
listado<-c("logi", "avnnet", "rf","gbm",  "xgbm", "svmLinear",  "svmPoly", 
           "svmRadial","predi9", "predi10", "predi11", "predi12", "predi13", 
           "predi14", "predi15", "predi16", "predi17", "predi18", "predi19", 
           "predi20", "predi21", "predi22", "predi23", "predi24", "predi25", 
           "predi26", "predi27", "predi28", "predi29", "predi30", "predi31", 
           "predi32", "predi33", "predi34", "predi35", "predi36", "predi37", 
           "predi38", "predi39", "predi40", "predi41", "predi42", "predi43", 
           "predi44", "predi45", "predi46", "predi47", "predi48", "predi49", 
           "predi50", "predi51", "predi52", "predi53", "predi54", "predi55", 
           "predi56", "predi57", "predi58", "predi59", "predi60", "predi61", 
           "predi62", "predi63", "predi64", "predi65", "predi66", "predi67", 
           "predi68", "predi69")
```

### Comparativa parcial entre los modelos elaborados por el ensamblado

En primer lugar, **guardamos las funciones** para calcular la **tasa de fallos** y el **AUC** sobre las predicciones.

```{r eval=FALSE}
tasafallos <- function(x,y) {
  confu <- confusionMatrix(x,y)
  tasa <- confu[[3]][1]
  return(tasa)
}

auc <- function(x,y) {
  curvaroc <- roc(response=x,predictor=y)
  auc <- curvaroc$auc
  return(auc)
}
```

En segundo lugar, **ejecutamos los bucles** para representar ambas medidas sobre las **predicciones de todos los modelos elaborados**.

```{r eval=FALSE}
repeticiones<-nlevels(factor(predicciones$Rep))
predicciones$Rep<-as.factor(predicciones$Rep)
predicciones$Rep<-as.numeric(predicciones$Rep)

medias0<-data.frame(c())
for (prediccion in listado)
{
  predicciones$proba<-predicciones[,prediccion]
  predicciones[,prediccion]<-ifelse(predicciones[,prediccion]>0.5,"Yes","No")
  for (repe in 1:repeticiones)
  {
    paso <- predicciones[(predicciones$Rep==repe),]
    pre<-factor(paso[,prediccion])
    archi<-paso[,c("proba","obs")]
    archi<-archi[order(archi$proba),]
    obs<-paso[,c("obs")]
    tasa=1-tasafallos(pre,obs)
    t<-as.data.frame(tasa)
    t$modelo<-prediccion
    auc<-suppressMessages(auc(archi$obs,archi$proba))
    t$auc<-auc
    medias0<-rbind(medias0,t)
  }
}
```

Y ya, por último, **generamos los gráficos de la tasa de fallos y el AUC** para los modelos del primer set de variables:

```{r eval=FALSE}
# Boxplot de la tasa de error para cada modelo
 a <- ggplot(data = medias0, aes(x = reorder(modelo, tasa), y = tasa)) +
  geom_boxplot() +
  labs(x = NULL, y = "Tasa de error", title = "Distribución del error según los distintos modelos seleccionados") +
  theme_minimal() +
  theme(text = element_text(face = "bold", size = 15), plot.title = element_text(hjust = 0.5), 
        axis.title.x = element_text(vjust=-0.5)) +
  scale_x_discrete(guide = guide_axis(angle = 50))

# Boxplot de la tasa AUC para cada modelo
 b <- ggplot(data = medias0, aes(x = reorder(modelo, -c(auc)), y = auc)) +
  geom_boxplot() +
  labs(x = NULL, y = "AUC", title = "Distribución de la tasa AUC según los distintos modelos seleccionados") +
  theme_minimal() +
  theme(text = element_text(face = "bold", size = 15), plot.title = element_text(hjust = 0.5), 
        axis.title.x = element_text(vjust=-0.5)) +
  scale_x_discrete(guide = guide_axis(angle = 50))
 
Rmisc::multiplot(a, b)
```

```{r layout="l-body-outset", fig.width=50, fig.asp = .99, echo=FALSE}
knitr::include_graphics("/Users/leztin/Desktop/Captura de pantalla 2023-05-16 a las 19.53.15.png")  
```

Como se puede observar en el gráfico, los modelos creados a partir del **ensamblado son muchísimo mejores**, tanto en términos de **AUC** como de **error** que los modelos individuales.
Concretamente, la combinación **Red neuronal, Gradient Boosting y SVM Lineal** es la que mejores resultados ha ofrecido, con un **AUC de más del 0.995** y con una **tasa de fallos menor a 0.025**.

A continuación visualizaremos las **correlaciones entre los mejores modelos** y los graficaremos:

```{r eval=FALSE}
# Volvemos a generar nuestra matriz de datos
predicciones_nuevo <- 
  cbind(graf_MMPC_pred,Red_MMPC_tun_pred,
        RF_MMPC_pred,GB_MMPC_pred,XGB_MMPC_pred,SVMLin_MMPC_pred,
        SVMPol_MMPC_pred,SVMRad_MMPC_pred)

# Eliminamos duplicados
predicciones_nuevo<- predicciones_nuevo[, !duplicated(colnames(predicciones_nuevo))]

# Añadimos los mejores ensamblados
predicciones_nuevo$predi61<-(predicciones_nuevo$avnnet+predicciones_nuevo$gbm+predicciones_nuevo$svmLinear)/3
predicciones_nuevo$predi58<-(predicciones_nuevo$rf+predicciones_nuevo$avnnet+predicciones_nuevo$svmLinear)/3
predicciones_nuevo$predi47<-(predicciones_nuevo$logi+predicciones_nuevo$xgbm+predicciones_nuevo$svmLinear)/3
predicciones_nuevo$predi44<-(predicciones_nuevo$logi+predicciones_nuevo$gbm+predicciones_nuevo$svmLinear)/3
```

Mostramos la **matriz de correlaciones**:

```{r eval=FALSE}
unigraf1<-predicciones_nuevo[predicciones_nuevo$Rep=="Rep01",]
# Correlaciones entre predicciones de cada algoritmo individual
solos<-c("logi", "avnnet","rf","gbm", "xgbm","svmLinear","svmPoly","svmRadial")
mat<-unigraf1[,solos]
matrizcorr<-cor(mat)
corrplot(matrizcorr, type = "upper", order = "hclust", 
         tl.col = "black", tl.srt = 45,cl.lim=c(0.7,1),is.corr=FALSE)
```

```{r layout="l-body-outset", fig.width=50, fig.asp = .99, echo=FALSE}
knitr::include_graphics("/Users/leztin/Desktop/Captura de pantalla 2023-05-16 a las 19.49.02.png")  
```

Como se puede observar, la **correlación es bastante alta** entre todos los modelos, lo cual facilita el ensamblado.
Como mínimo, la correlación entre modelos es del **0.72**.

```{r eval=FALSE}
a <- qplot(predi61,predi58,data=unigraf1,colour=obs)+
  geom_hline(yintercept=0.5, color="black", size=1)+
  geom_vline(xintercept=0.5, color="black", size=1)+
  theme_minimal()

b <- qplot(predi61,avnnet,data=unigraf1,colour=obs)+
  geom_hline(yintercept=0.5, color="black", size=1)+
  geom_vline(xintercept=0.5, color="black", size=1)+
  theme_minimal()

Rmisc::multiplot(a, b)
```

```{r layout="l-body-outset", fig.width=50, fig.asp = .99, echo=FALSE}
knitr::include_graphics("/Users/leztin/Desktop/Captura de pantalla 2023-05-16 a las 19.51.30.png")  
```

Si comparamos los dos mejores modelos de ensamblado, **la clasificación es casi perfecta**, tal y como se muestra en el primer gráfico.
Pero si comparamos el mejor modelo de ensamblado con el mejor modelo sin ensamblar (Red neuronal), **los resultados son peores a causa del inferior accuracy de la red neuronal**.
En posteriores apartadas elaboraremos **contrastes** para valorar si merece la pena seleccionar un modelo ensamblado frente al resto, a pesar de su complejidad.

A continuación probaremos el ensamblado con el **segundo set de variables**:

## Aplicación al segundo set de variables (Step repetido con el Criterio de Información BIC)

Para calcular las **predicciones** que nos servirán para el ensamblado emplearemos las funciones provistas en el archivo **«cruzadas ensamblado binaria fuente.R»**.
Antes de ejecutarlas, añadiremos a cada una de ellas los **mejores hiperparámetros** que fuimos configurando en anteriores apartados para cada uno de los modelos.

```{r eval=FALSE}
# Regresión logística
graf_MMPC_ensam_2 <- 
  cruzadalogistica(data = air_prep_matrix, vardep = "Satisfaction", 
             listconti = c("Online_Board_Sat_X1", "Travel_Personal.Travel", "WiFi_Sat_X1",
                                       "Customer_Loyal.Customer", "WiFi_Sat_X2", "Baggage_Sat_X3",
                                       "Baggage_Sat_X2", "Class_Eco.Plus", "Checkin_Sat_X3",
                                       "Online_Board_Sat_X3", "Dep_Arr_Sat_X3", "Inflight_Sat_X3",
                                       "Seat_Sat_X3"),
             listclass = c(""), grupos = 5, sinicio = 12346, repe = 10)

graf_MMPC_ensam_2$Modelo = "Reg. logist. \n Segundo set"
graf_MMPC_ensam_2$N_variables = "13"

graf_MMPC_bis_2 <- as.data.frame(graf_MMPC_ensam_2[1])
graf_MMPC_pred_2 <- as.data.frame(graf_MMPC_ensam_2[2])
graf_MMPC_pred_2$logi <- graf_MMPC_pred_2$Yes

# Red neuronal
Red_MMPC_tun_ensam_2 <-
  cruzadaavnnetbin(data = air_prep, vardep = "Satisfaction",
                listconti = c("Online_Board_Sat_X1", "Travel_Personal.Travel", "WiFi_Sat_X1",
                                       "Customer_Loyal.Customer", "WiFi_Sat_X2", "Baggage_Sat_X3",
                                       "Baggage_Sat_X2", "Class_Eco.Plus", "Checkin_Sat_X3",
                                       "Online_Board_Sat_X3", "Dep_Arr_Sat_X3", "Inflight_Sat_X3",
                                       "Seat_Sat_X3"),
                listclass = c(""), grupos = 5, sinicio = 12346, repe = 10, repeticiones = 5,
                itera = 1000, size = c(10), decay = c(0.1))

Red_MMPC_tun_ensam_2$Modelo = "Red neuronal tuneada \n Segundo set"
Red_MMPC_tun_ensam_2$N_variables = "13"

Red_MMPC_tun_bis_2 <- as.data.frame(Red_MMPC_tun_ensam_2[1])
Red_MMPC_tun_pred_2 <- as.data.frame(Red_MMPC_tun_ensam_2[2])
Red_MMPC_tun_pred_2$avnnet <- Red_MMPC_tun_pred_2$Yes

# Bagging
Bag_MMPC_3_ensam_2 <- 
  cruzadarfbin(data=air_prep, vardep="Satisfaction",
               listconti=c("Online_Board_Sat_X1", "Travel_Personal.Travel", "WiFi_Sat_X1",
                                       "Customer_Loyal.Customer", "WiFi_Sat_X2", "Baggage_Sat_X3",
                                       "Baggage_Sat_X2", "Class_Eco.Plus", "Checkin_Sat_X3",
                                       "Online_Board_Sat_X3", "Dep_Arr_Sat_X3", "Inflight_Sat_X3",
                                       "Seat_Sat_X3"),
                           listclass=c(""),
                           grupos=5,sinicio=1234,repe=25,nodesize=10,
                           mtry=13,ntree=5000,replace=TRUE,sampsize=300)

Bag_MMPC_3_ensam_2$Modelo = "Bagging \n Segundo set"
Bag_MMPC_3_ensam_2$N_variables = "13"

Bag_MMPC_3_bis_2 <- as.data.frame(Bag_MMPC_3_ensam_2[1])
Bag_MMPC_3_pred_2 <- as.data.frame(Bag_MMPC_3_ensam_2[2])
Bag_MMPC_3_pred_2$bagging <- Bag_MMPC_3_pred_2$Yes

# Random Forest
RF_MMPC_ensam_2 <- cruzadarfbin(data=air_prep, vardep="Satisfaction",
                           listconti=c("Online_Board_Sat_X1", "Travel_Personal.Travel", "WiFi_Sat_X1",
                                       "Customer_Loyal.Customer", "WiFi_Sat_X2", "Baggage_Sat_X3",
                                       "Baggage_Sat_X2", "Class_Eco.Plus", "Checkin_Sat_X3",
                                       "Online_Board_Sat_X3", "Dep_Arr_Sat_X3", "Inflight_Sat_X3",
                                       "Seat_Sat_X3"),
                           listclass=c(""),
                           grupos=5,sinicio=1234,repe=25,nodesize=10,
                           mtry=9,ntree=5000,replace=TRUE,sampsize=1000)

RF_MMPC_ensam_2$Modelo = "Random Forest \n Segundo set"
RF_MMPC_ensam_2$N_variables = "13"

RF_MMPC_bis_2 <- as.data.frame(RF_MMPC_ensam_2[1])
RF_MMPC_pred_2 <- as.data.frame(RF_MMPC_ensam_2[2])
RF_MMPC_pred_2$rf <- RF_MMPC_pred_2$Yes

# Gradient Boosting
GB_MMPC_ensam_2 <- cruzadagbmbin(data=air_prep, vardep="Satisfaction",
                           listconti=c("Online_Board_Sat_X1", "Travel_Personal.Travel", "WiFi_Sat_X1",
                                       "Customer_Loyal.Customer", "WiFi_Sat_X2", "Baggage_Sat_X3",
                                       "Baggage_Sat_X2", "Class_Eco.Plus", "Checkin_Sat_X3",
                                       "Online_Board_Sat_X3", "Dep_Arr_Sat_X3", "Inflight_Sat_X3",
                                       "Seat_Sat_X3"),
                           listclass=c(""),
                      grupos=5,sinicio=1234,repe=5,n.minobsinnode=7,
                      shrinkage=0.03,n.trees=2000,interaction.depth=2)

GB_MMPC_ensam_2$Modelo = "Gradient Boosting \n Segundo set"
GB_MMPC_ensam_2$N_variables = "13"

GB_MMPC_bis_2 <- as.data.frame(GB_MMPC_ensam_2[1])
GB_MMPC_pred_2 <- as.data.frame(GB_MMPC_ensam_2[2])
GB_MMPC_pred_2$gbm <- GB_MMPC_pred_2$Yes

# XGBoost
XGB_MMPC_ensam_2 <- cruzadaxgbmbin(data=air_prep, vardep="Satisfaction",
                           listconti=c("Online_Board_Sat_X1", "Travel_Personal.Travel", "WiFi_Sat_X1",
                                       "Customer_Loyal.Customer", "WiFi_Sat_X2", "Baggage_Sat_X3",
                                       "Baggage_Sat_X2", "Class_Eco.Plus", "Checkin_Sat_X3",
                                       "Online_Board_Sat_X3", "Dep_Arr_Sat_X3", "Inflight_Sat_X3",
                                       "Seat_Sat_X3"),
                           listclass=c(""),
                        grupos=5,sinicio=1234,repe=25,
                        min_child_weight=10,eta=0.01,nrounds=2000,max_depth=10,
                        gamma=0,colsample_bytree=1,subsample=0.9,alpha=0,lambda=0)

XGB_MMPC_ensam_2$Modelo = "XGBoost \n Segundo set"
XGB_MMPC_ensam_2$N_variables = "13"

XGB_MMPC_bis_2 <- as.data.frame(XGB_MMPC_ensam_2[1])
XGB_MMPC_pred_2 <- as.data.frame(XGB_MMPC_ensam_2[2])
XGB_MMPC_pred_2$xgbm <- XGB_MMPC_pred_2$Yes

# SVM Lineal
SVMLin_MMPC_ensam_2 <- cruzadaSVMbin(data=air_prep, vardep="Satisfaction",
                           listconti=c("Online_Board_Sat_X1", "Travel_Personal.Travel", "WiFi_Sat_X1",
                                       "Customer_Loyal.Customer", "WiFi_Sat_X2", "Baggage_Sat_X3",
                                       "Baggage_Sat_X2", "Class_Eco.Plus", "Checkin_Sat_X3",
                                       "Online_Board_Sat_X3", "Dep_Arr_Sat_X3", "Inflight_Sat_X3",
                                       "Seat_Sat_X3"),
                           listclass=c(""),
                       grupos=5,sinicio=1234,repe=25,C=1.5)

SVMLin_MMPC_ensam_2$Modelo = "SVM Lineal \n Segundo set"
SVMLin_MMPC_ensam_2$N_variables = "13"

SVMLin_MMPC_bis_2 <- as.data.frame(SVMLin_MMPC_ensam_2[1])
SVMLin_MMPC_pred_2 <- as.data.frame(SVMLin_MMPC_ensam_2[2])
SVMLin_MMPC_pred_2$svmLinear <- SVMLin_MMPC_pred_2$Yes

# SVM Polinomial
SVMPol_MMPC_ensam_2 <- cruzadaSVMbinPoly(data=air_prep, vardep="Satisfaction",
                           listconti=c("Online_Board_Sat_X1", "Travel_Personal.Travel", "WiFi_Sat_X1",
                                       "Customer_Loyal.Customer", "WiFi_Sat_X2", "Baggage_Sat_X3",
                                       "Baggage_Sat_X2", "Class_Eco.Plus", "Checkin_Sat_X3",
                                       "Online_Board_Sat_X3", "Dep_Arr_Sat_X3", "Inflight_Sat_X3",
                                       "Seat_Sat_X3"),
                           listclass=c(""),
                       grupos=5,sinicio=1234,repe=25,C=0.7,degree=3,scale=0.03)

SVMPol_MMPC_ensam_2$Modelo = "SVM Polinomial \n Segundo set"
SVMPol_MMPC_ensam_2$N_variables = "13"

SVMPol_MMPC_bis_2 <- as.data.frame(SVMPol_MMPC_ensam_2[1])
SVMPol_MMPC_pred_2 <- as.data.frame(SVMPol_MMPC_ensam_2[2])
SVMPol_MMPC_pred_2$svmPoly <- SVMPol_MMPC_pred_2$Yes

# SVM Radial
SVMRad_MMPC_ensam_2 <- cruzadaSVMbinRBF(data=air_prep, vardep="Satisfaction",
                           listconti=c("Online_Board_Sat_X1", "Travel_Personal.Travel", "WiFi_Sat_X1",
                                       "Customer_Loyal.Customer", "WiFi_Sat_X2", "Baggage_Sat_X3",
                                       "Baggage_Sat_X2", "Class_Eco.Plus", "Checkin_Sat_X3",
                                       "Online_Board_Sat_X3", "Dep_Arr_Sat_X3", "Inflight_Sat_X3",
                                       "Seat_Sat_X3"),
                           listclass=c(""),
                       grupos=5,sinicio=1234,repe=25,C=11,sigma=0.02)

SVMRad_MMPC_ensam_2$Modelo = "SVM Radial \n Segundo set"
SVMRad_MMPC_ensam_2$N_variables = "13"

SVMRad_MMPC_bis_2 <- as.data.frame(SVMRad_MMPC_ensam_2[1])
SVMRad_MMPC_pred_2 <- as.data.frame(SVMRad_MMPC_ensam_2[2])
SVMRad_MMPC_pred_2$svmRadial <- SVMRad_MMPC_pred_2$Yes
```

Una vez calculadas las funciones, **unimos las predicciones en un único dataset**.

```{r eval=FALSE}
# Generamos el dataframe con las predicciones de todos los modelos elaborados
predicciones_2 <- 
  cbind(graf_MMPC_pred_2,Red_MMPC_tun_pred_2,
        RF_MMPC_pred_2,GB_MMPC_pred_2,XGB_MMPC_pred_2,SVMLin_MMPC_pred_2,
        SVMPol_MMPC_pred_2,SVMRad_MMPC_pred_2)

# Eliminamos posibles columnas duplicadas
predicciones_2 <- 
  predicciones_2[, !duplicated(colnames(predicciones_2))]
```

### Combinaciones dobles de modelos

Por último, ejecutamos las combinaciones de todos los modelos calculados:

```{r eval=FALSE}
# Combinaciones dobles
predicciones_2$predi9<-(predicciones_2$logi+predicciones_2$avnnet)/2
predicciones_2$predi10<-(predicciones_2$logi+predicciones_2$rf)/2
predicciones_2$predi11<-(predicciones_2$logi+predicciones_2$gbm)/2
predicciones_2$predi12<-(predicciones_2$logi+predicciones_2$xgbm)/2
predicciones_2$predi13<-(predicciones_2$logi+predicciones_2$svmLinear)/2
predicciones_2$predi14<-(predicciones_2$logi+predicciones_2$svmPoly)/2
predicciones_2$predi15<-(predicciones_2$logi+predicciones_2$svmRadial)/2
predicciones_2$predi16<-(predicciones_2$avnnet+predicciones_2$rf)/2
predicciones_2$predi17<-(predicciones_2$avnnet+predicciones_2$gbm)/2
predicciones_2$predi18<-(predicciones_2$avnnet+predicciones_2$xgbm)/2
predicciones_2$predi19<-(predicciones_2$avnnet+predicciones_2$svmLinear)/2
predicciones_2$predi20<-(predicciones_2$avnnet+predicciones_2$svmPoly)/2
predicciones_2$predi21<-(predicciones_2$avnnet+predicciones_2$svmRadial)/2
predicciones_2$predi22<-(predicciones_2$rf+predicciones_2$gbm)/2
predicciones_2$predi23<-(predicciones_2$rf+predicciones_2$xgbm)/2
predicciones_2$predi24<-(predicciones_2$rf+predicciones_2$svmLinear)/2
predicciones_2$predi25<-(predicciones_2$rf+predicciones_2$svmPoly)/2
predicciones_2$predi26<-(predicciones_2$rf+predicciones_2$svmRadial)/2
predicciones_2$predi27<-(predicciones_2$gbm+predicciones_2$xgbm)/2
predicciones_2$predi28<-(predicciones_2$gbm+predicciones_2$svmLinear)/2
predicciones_2$predi29<-(predicciones_2$gbm+predicciones_2$svmPoly)/2
predicciones_2$predi30<-(predicciones_2$gbm+predicciones_2$svmRadial)/2
```

### Combinaciones triples de modelos

```{r eval=FALSE}
# Combinaciones triples
predicciones_2$predi31<-(predicciones_2$logi+predicciones_2$avnnet+predicciones_2$rf)/3
predicciones_2$predi32<-(predicciones_2$logi+predicciones_2$avnnet+predicciones_2$gbm)/3
predicciones_2$predi33<-(predicciones_2$logi+predicciones_2$avnnet+predicciones_2$xgbm)/3
predicciones_2$predi34<-(predicciones_2$logi+predicciones_2$avnnet+predicciones_2$svmLinear)/3
predicciones_2$predi35<-(predicciones_2$logi+predicciones_2$avnnet+predicciones_2$svmPoly)/3
predicciones_2$predi36<-(predicciones_2$logi+predicciones_2$avnnet+predicciones_2$svmRadial)/3
predicciones_2$predi37<-(predicciones_2$logi+predicciones_2$rf+predicciones_2$gbm)/3
predicciones_2$predi38<-(predicciones_2$logi+predicciones_2$rf+predicciones_2$xgbm)/3
predicciones_2$predi39<-(predicciones_2$logi+predicciones_2$rf+predicciones_2$svmLinear)/3
predicciones_2$predi40<-(predicciones_2$logi+predicciones_2$rf+predicciones_2$svmPoly)/3
predicciones_2$predi41<-(predicciones_2$logi+predicciones_2$rf+predicciones_2$svmRadial)/3
predicciones_2$predi42<-(predicciones_2$logi+predicciones_2$gbm+predicciones_2$xgbm)/3
predicciones_2$predi43<-(predicciones_2$logi+predicciones_2$gbm+predicciones_2$xgbm)/3
predicciones_2$predi44<-(predicciones_2$logi+predicciones_2$gbm+predicciones_2$svmLinear)/3
predicciones_2$predi45<-(predicciones_2$logi+predicciones_2$gbm+predicciones_2$svmPoly)/3
predicciones_2$predi46<-(predicciones_2$logi+predicciones_2$gbm+predicciones_2$svmRadial)/3
predicciones_2$predi47<-(predicciones_2$logi+predicciones_2$xgbm+predicciones_2$svmLinear)/3
predicciones_2$predi48<-(predicciones_2$logi+predicciones_2$xgbm+predicciones_2$svmPoly)/3
predicciones_2$predi49<-(predicciones_2$logi+predicciones_2$xgbm+predicciones_2$svmRadial)/3
predicciones_2$predi50<-(predicciones_2$rf+predicciones_2$gbm+predicciones_2$svmLinear)/3
predicciones_2$predi51<-(predicciones_2$rf+predicciones_2$gbm+predicciones_2$svmPoly)/3
predicciones_2$predi52<-(predicciones_2$rf+predicciones_2$gbm+predicciones_2$svmRadial)/3
predicciones_2$predi53<-(predicciones_2$rf+predicciones_2$xgbm+predicciones_2$svmLinear)/3
predicciones_2$predi54<-(predicciones_2$rf+predicciones_2$xgbm+predicciones_2$svmPoly)/3
predicciones_2$predi55<-(predicciones_2$rf+predicciones_2$xgbm+predicciones_2$svmRadial)/3
predicciones_2$predi56<-(predicciones_2$rf+predicciones_2$avnnet+predicciones_2$gbm)/3
predicciones_2$predi57<-(predicciones_2$rf+predicciones_2$avnnet+predicciones_2$xgbm)/3
predicciones_2$predi58<-(predicciones_2$rf+predicciones_2$avnnet+predicciones_2$svmLinear)/3
predicciones_2$predi59<-(predicciones_2$rf+predicciones_2$avnnet+predicciones_2$svmPoly)/3
predicciones_2$predi60<-(predicciones_2$rf+predicciones_2$avnnet+predicciones_2$svmRadial)/3
predicciones_2$predi61<-(predicciones_2$avnnet+predicciones_2$gbm+predicciones_2$svmLinear)/3
predicciones_2$predi62<-(predicciones_2$avnnet+predicciones_2$gbm+predicciones_2$svmPoly)/3
predicciones_2$predi63<-(predicciones_2$avnnet+predicciones_2$gbm+predicciones_2$svmRadial)/3
```

### Combinaciones cuádruples de modelos

```{r eval=FALSE}
# Combianciones cuádruples
predicciones_2$predi64<-(predicciones_2$logi+predicciones_2$rf+predicciones_2$gbm+predicciones_2$avnnet)/4
predicciones_2$predi65<-(predicciones_2$logi+predicciones_2$rf+predicciones_2$xgbm+predicciones_2$avnnet)/4
predicciones_2$predi66<-(predicciones_2$logi+predicciones_2$rf+predicciones_2$xgbm+predicciones_2$avnnet)/4
```

### Combinaciones quíntuples de modelos

```{r eval=FALSE}
# Combianciones quíntuples
predicciones_2$predi67<-(predicciones_2$logi+predicciones_2$rf+predicciones_2$xgbm+predicciones_2$avnnet+predicciones_2$svmLinear)/5
predicciones_2$predi68<-(predicciones_2$logi+predicciones_2$rf+predicciones_2$xgbm+predicciones_2$avnnet+predicciones_2$svmPoly)/5
predicciones_2$predi69<-(predicciones_2$logi+predicciones_2$rf+predicciones_2$xgbm+predicciones_2$avnnet+predicciones_2$svmRadial)/5
```

### Comparativa parcial entre los modelos elaborados por el ensamblado

A continuación, **ejecutamos los bucles** para representar ambas medidas sobre las **predicciones de todos los modelos elaborados**.

```{r eval=FALSE}
repeticiones<-nlevels(factor(predicciones_2$Rep))
predicciones_2$Rep<-as.factor(predicciones_2$Rep)
predicciones_2$Rep<-as.numeric(predicciones_2$Rep)

medias0bis<-data.frame(c())
for (prediccion in listado)
{
  predicciones_2$proba<-predicciones_2[,prediccion]
  predicciones_2[,prediccion]<-ifelse(predicciones_2[,prediccion]>0.5,"Yes","No")
  for (repe in 1:repeticiones)
  {
    paso <- predicciones_2[(predicciones_2$Rep==repe),]
    pre<-factor(paso[,prediccion])
    archi<-paso[,c("proba","obs")]
    archi<-archi[order(archi$proba),]
    obs<-paso[,c("obs")]
    tasa=1-tasafallos(pre,obs)
    t<-as.data.frame(tasa)
    t$modelo<-prediccion
    auc<-suppressMessages(auc(archi$obs,archi$proba))
    t$auc<-auc
    medias0bis<-rbind(medias0bis,t)
  }
}
```

Y ya, por último, **generamos los gráficos de la tasa de fallos y el AUC** para los modelos del segundo set de variables:

```{r eval=FALSE}
# Boxplot de la tasa de error para cada modelo
 a <- ggplot(data = medias0bis, aes(x = reorder(modelo, tasa), y = tasa)) +
  geom_boxplot() +
  labs(x = NULL, y = "Tasa de error", title = "Distribución del error según los distintos modelos seleccionados") +
  theme_minimal() +
  theme(text = element_text(face = "bold", size = 15), plot.title = element_text(hjust = 0.5), 
        axis.title.x = element_text(vjust=-0.5)) +
  scale_x_discrete(guide = guide_axis(angle = 50))

# Boxplot de la tasa AUC para cada modelo
 b <- ggplot(data = medias0bis, aes(x = reorder(modelo, -c(auc)), y = auc)) +
  geom_boxplot() +
  labs(x = NULL, y = "AUC", title = "Distribución de la tasa AUC según los distintos modelos seleccionados") +
  theme_minimal() +
  theme(text = element_text(face = "bold", size = 15), plot.title = element_text(hjust = 0.5), 
        axis.title.x = element_text(vjust=-0.5)) +
  scale_x_discrete(guide = guide_axis(angle = 50))
 
Rmisc::multiplot(a, b)
```

```{r layout="l-body-outset", fig.width=50, fig.asp = .99, echo=FALSE}
knitr::include_graphics("/Users/leztin/Desktop/Captura de pantalla 2023-05-16 a las 19.55.41.png")  
```

Como se puede observar en el gráfico, los modelos creados a partir del **ensamblado son muchísimo mejores**, tanto en términos de **AUC** como de **error** que los modelos individuales.
Se puede observar una **varianza más elevada para cierto modelos**, aunque si se observa la escala no es demasiada.
Concretamente, la combinación **Regresión logística, Random Forest, Gradient Boosting y Red Neuronal** es la que mejores resultados ha ofrecido, con un **AUC de más del 0.995** y con una **tasa de fallos menor a 0.02**.

A continuación visualizaremos las **correlaciones entre los mejores modelos** y los graficaremos:

```{r eval=FALSE}
# Volvemos a generar nuestra matriz de datos
predicciones_2_nuevo <- 
  cbind(graf_MMPC_pred,Red_MMPC_tun_pred,
        RF_MMPC_pred,GB_MMPC_pred,XGB_MMPC_pred,SVMLin_MMPC_pred,
        SVMPol_MMPC_pred,SVMRad_MMPC_pred)

# Eliminamos duplicados
predicciones_2_nuevo<- predicciones_2_nuevo[, !duplicated(colnames(predicciones_2_nuevo))]

# Añadimos los mejores ensamblados
predicciones_2_nuevo$predi64<-(predicciones_2_nuevo$logi+predicciones_2_nuevo$rf+predicciones_2_nuevo$gbm+predicciones_2_nuevo$avnnet)/4
predicciones_2_nuevo$predi65<-(predicciones_2_nuevo$logi+predicciones_2_nuevo$rf+predicciones_2_nuevo$xgbm+predicciones_2_nuevo$avnnet)/4
predicciones_2_nuevo$predi18<-(predicciones_2_nuevo$avnnet+predicciones_2_nuevo$xgbm)/2
predicciones_2_nuevo$predi17<-(predicciones_2_nuevo$avnnet+predicciones_2_nuevo$gbm)/2
```

Mostramos la **matriz de correlaciones**:

```{r eval=FALSE}
unigraf<-predicciones_2_nuevo[predicciones_2_nuevo$Rep=="Rep01",]
# Correlaciones entre predicciones de cada algoritmo individual
solos<-c("logi", "avnnet","rf","gbm", "xgbm","svmLinear","svmPoly","svmRadial")
mat<-unigraf[,solos]
matrizcorr<-cor(mat)
corrplot(matrizcorr, type = "upper", order = "hclust", 
         tl.col = "black", tl.srt = 45,cl.lim=c(0.7,1),is.corr=FALSE)
```

```{r layout="l-body-outset", fig.width=50, fig.asp = .99, echo=FALSE}
knitr::include_graphics("/Users/leztin/Desktop/Captura de pantalla 2023-05-16 a las 19.49.02.png")  
```

Como se puede observar, la **correlación es bastante alta** entre todos los modelos, lo cual facilita el ensamblado.
Como mínimo, la correlación entre modelos es del **0.72**.

```{r eval=FALSE}
a <- qplot(predi64,predi65,data=unigraf,colour=obs)+
  geom_hline(yintercept=0.5, color="black", size=1)+
  geom_vline(xintercept=0.5, color="black", size=1)+
  theme_minimal()

b <- qplot(predi64,avnnet,data=unigraf,colour=obs)+
  geom_hline(yintercept=0.5, color="black", size=1)+
  geom_vline(xintercept=0.5, color="black", size=1)+
  theme_minimal()

Rmisc::multiplot(a, b)
```

```{r layout="l-body-outset", fig.width=50, fig.asp = .99, echo=FALSE}
knitr::include_graphics("/Users/leztin/Desktop/Captura de pantalla 2023-05-16 a las 19.59.12.png")  
```

Si comparamos los dos mejores modelos de ensamblado, **la clasificación es casi perfecta**, tal y como se muestra en el primer gráfico.
Pero si comparamos el mejor modelo de ensamblado con el mejor modelo sin ensamblar (Red neuronal), **los resultados son peores a causa del inferior accuracy de la red neuronal**.
En posteriores apartadas elaboraremos **contrastes** para valorar si merece la pena seleccionar un modelo ensamblado frente al resto, a pesar de su complejidad.

A continuación, y ya en último lugar, probaremos con el proceso automático **AutoML** para comprobar si mejora de alguna manera **los niveles de AUC y de error de los modelos ensamblados**.

# Fase 7.10: AutoML

Los procesos de **AutoML (Automated Machine Learning)** son un conjunto de técnicas y herramientas diseñadas para **automatizar y simplificar el proceso de construcción de modelos de aprendizaje automático**.
El objetivo del AutoML es permitir a usuarios con poca experiencia en ciencia de datos **desarrollar y desplegar modelos de alta calidad** sin requerir un conocimiento profundo en algoritmos y técnicas de machine learning.

## Aplicación al primer set de variables (Algoritmo MMPC)

Recordemos que este primer set presenta **once variables predictoras**.

```{r results='hide'}
# Configuramos los parámetros de inicio
h2o.init(nthreads=7)

# Transformamos a factor la variable dependiente
air_prep$Satisfaction <-
  as.factor(air_prep$Satisfaction)

# Almacenamos las variables del primer set
train_deep <- 
  as.h2o(air_prep[,c("Satisfaction", "Customer_Loyal.Customer", "Travel_Personal.Travel",
                     "Class_Eco.Plus", "WiFi_Sat_X1", "Online_Board_Sat_X1",
                     "Online_Board_Sat_X3", "Entertainment_Sat_X3",
                     "On_board_Sat_X3", "Leg_Sat_X2", "Leg_Sat_X3","Checkin_Sat_X3")])

# Ejecutamos la función `h2o.deeplearning`
red1 <- h2o.deeplearning(x = 2:12,y=1,training_frame = train_deep,seed=12345,
                         hidden = c(10),epochs =100,activation = "Tanh",
                         rate=0.01,nfolds=10,adaptive_rate=FALSE)
red1
```

```{r layout="l-body-outset", fig.width=50, fig.asp = .99, echo=FALSE}
knitr::include_graphics("/Users/leztin/Desktop/Captura de pantalla 2023-05-18 a las 0.35.18.png")  
```

En este primer acercamiento emplearemos la función `h2o.deeplearning` del paquete `{h2o}`.
Esta función se utiliza habitualmente para entrenar y construir modelos de redes neuronales profundas (también conocidas como *deep learning*) utilizando la arquitectura de H2O.

Como se puede observar, la **función** ofrece una serie de **resultados muy positivos**, aunque no tan buenos como los modelos que habíamos construido con anterioridad.
La función nos ofrece un **AUC general del 95 %** y un nivel de **accuracy del 90 %**.
A continuación probaremos otra función para cotejar sus resultados.

```{r results='hide'}
h2o.init(nthreads=7)
train_automl <- 
  h2o.automl(x = 2:12,y=1,training_frame = train_deep,max_models = 20,
             seed = 12345,keep_cross_validation_predictions=TRUE)

lb <- train_automl@leaderboard
head(lb, n = nrow(lb))
```

```{r layout="l-body-outset", fig.width=50, fig.asp = .99, echo=FALSE}
knitr::include_graphics("/Users/leztin/Desktop/Captura de pantalla 2023-05-18 a las 0.37.12.png")  
```

En esta segunda ocasión emplearemos la función `h2o.automl`.Esta función es parte de la biblioteca `H2O.ai` y se utiliza para realizar el **AutoML (Automated Machine Learning) en el entorno H2O**.

En nuestro caso, la ejecución de la función nos ha devuelto una serie de modelos **bastante bien optimizados**.
El primero de ellos es el `GBM_1_AutoML_1_20230512_232114`.
Comprobemos a continuación en qué consiste:

```{r}
modelo_mejor_automl_1 <- h2o.getModel("GBM_1_AutoML_1_20230512_232114")
```

Como se puede observar, se trata de un **modelo simple Gradient Boosting**.
**Las estadísticas son muy positivas**, es capaz de **competir** con los modelos que hemos calculado en la práctica.
Presenta un **accuracy** general del **92 %**, un **AUC** del **97 %**, una **precisión** del **93 %** y, por último, un **recall** del **92 %**.

Podemos entrenar el modelo con la función `h2o.gbm` tuneando los parámetros según lo indicado por la variable `modelo_mejor_automl_1@parameters`.

```{r results='hide'}
gbm_set1 <- 
  h2o.gbm(x = 2:12,y=1,training_frame = train_deep,seed=12347,
          ntrees=78,max_depth=15,min_rows =100,sample_rate = 0.8,col_sample_rate=0.8,
          col_sample_rate_per_tree = 0.8,distribution = "bernoulli",nfolds = 5,
          keep_cross_validation_predictions = TRUE)
gbm_set1
```

```{r layout="l-body-outset", fig.width=50, fig.asp = .99, echo=FALSE}
knitr::include_graphics("/Users/leztin/Desktop/Captura de pantalla 2023-05-18 a las 0.41.42.png")  
```

**Los resultados de este modelo son excelentes.** Presenta un **AUC del 98.05 %**, superior a las métricas del chunk anterior.

A continuación probaremos con el **segundo set de variables**:

## Aplicación al segundo set de variables (Step repetido con el Criterio de Información BIC)

Recordemos que este segundo set presenta **trece variables predictoras**.

```{r results='hide'}
# Configuramos los parámetros de inicio
h2o.init(nthreads=7)

# Transformamos a factor la variable dependiente
air_prep$Satisfaction <-
  as.factor(air_prep$Satisfaction)

# Almacenamos las variables del primer set
train_deep_2 <- 
  as.h2o(air_prep[,c("Satisfaction","Online_Board_Sat_X1", "Travel_Personal.Travel",
                     "WiFi_Sat_X1","Customer_Loyal.Customer", "WiFi_Sat_X2", "Baggage_Sat_X3",
                     "Baggage_Sat_X2", "Class_Eco.Plus", "Checkin_Sat_X3",
                     "Online_Board_Sat_X3", "Dep_Arr_Sat_X3", "Inflight_Sat_X3","Seat_Sat_X3")])

# Ejecutamos la función `h2o.deeplearning`
red2 <- h2o.deeplearning(x = 2:14,y=1,training_frame = train_deep_2,seed=12345,
                         hidden = c(10),epochs =100,activation = "Tanh",
                         rate=0.01,nfolds=10,adaptive_rate=FALSE)
red2
```

```{r layout="l-body-outset", fig.width=50, fig.asp = .99, echo=FALSE}
knitr::include_graphics("/Users/leztin/Desktop/Captura de pantalla 2023-05-18 a las 0.43.10.png")  
```

Como se puede observar, la **función** ofrece también para este segundo set una serie de **resultados muy positivos**, aunque no tan buenos como los modelos que habíamos construido con anterioridad.
La función nos ofrece un **AUC general del 97 %** y un nivel de **accuracy del 93 %**.
A continuación probaremos la función `h2o.automl` para cotejar sus resultados.

```{r eval=FALSE}
train_automl <- 
  h2o.automl(x = 2:14,y=1,training_frame = train_deep_2,max_models = 20,
             seed = 12345,keep_cross_validation_predictions=TRUE)

lb <- train_automl@leaderboard
head(lb, n = nrow(lb))
```

```{r layout="l-body-outset", fig.width=50, fig.asp = .99, echo=FALSE}
knitr::include_graphics("/Users/leztin/Desktop/Captura de pantalla 2023-05-18 a las 0.37.12.png")  
```

En este segundo caso, la ejecución de la función nos ha devuelto una serie de modelos **muy bien optimizados**.
El primero de ellos es el `GBM_4_AutoML_4_20230514_144246`.
Comprobemos a continuación en qué consiste:

```{r eval=FALSE}
modelo_mejor_automl_2 <- h2o.getModel("GBM_4_AutoML_4_20230514_144246")
```

Como se puede observar, en este caso el modelo vuelve a ser un **Gradient Boosting**.
**Las estadísticas son muy positivas**, es capaz de **competir** con el resto de modelos que hemos calculado en la práctica.
Presenta un **accuracy** general del **94.6 %**, un **AUC** del **98.6 %**, una **precisión** del **92.4 %** y, por último, un **recall** del **98.7 %**.

Al igual que en el anterior apartado, podemos entrenar el modelo con la función `h2o.gbm` tuneando los parámetros según lo indicado por la variable `modelo_mejor_automl_2@parameters`.

```{r eval=FALSE}
gbm_set2 <- 
  h2o.gbm(x = 2:14,y=1,training_frame = train_deep,seed=12352,
          ntrees=72,max_depth=10,min_rows =100,sample_rate = 0.8,col_sample_rate=0.8,
          col_sample_rate_per_tree = 0.8,distribution = "bernoulli",nfolds = 5,
          keep_cross_validation_predictions = TRUE)
gbm_set2
```

```{r layout="l-body-outset", fig.width=50, fig.asp = .99, echo=FALSE}
knitr::include_graphics("/Users/leztin/Desktop/Captura de pantalla 2023-05-17 a las 16.47.48.png")  
```

Al igual que con el anterior set, **los resultados de este modelo vuelven a ser excelentes.** Presenta un **AUC del 98.38 %**, superior a las métricas del chunk anterior.
Si hubiera que elegir entre ambos, **seleccionaría el primer modelo construido con el primer set de variables**.
Cuenta con dos menos que el segundo set y ofrece resultados muy similares.

Para ir finalizando con la práctica, en la siguiente sección se **compararán definitivamente los diferentes modelos aplicados** y se **tomará una decisión acerca de cuál de ellos es el mejor**.

# Fase 8: Selección final del modelo, postanálisis y conclusiones

Para comenzar con la comparativa, primero **uniremos todos los modelos de este trabajo** en un único **dataframe** y graficaremos su **error** y su **AUC**.
Graficaremos los modelos aplicados sobre los **dos sets de variables** que habíamos seleccionado en los primeros epígrafes de este trabajo.

## Comparativa final entre todos los modelos elaborados en la práctica

Vamos a añadir a nuestro dataframe `select_final`, que es el que contiene **las estadísticas de los mejores modelos** que hemos ido seleccionando para nuestros dos sets tentativos durante la práctica, los **modelos de ensamblado** que hemos elaborado y los obtenidos a partir de la función `h2o.automl` del paquete `{h2o}`.

```{r eval=FALSE}
# Almacenamos las estadísticas en términos de AUC y error del mejor modelo de ensamblado para el primer set de variables
Ensamblado_MMPC <- medias0 |> filter(modelo == "predi61")
Ensamblado_MMPC$modelo <- "Ensamblado \n (Red + GBM + SVM Lineal) \n Primer set"
Ensamblado_MMPC$N_variables <- "11"
row.names(Ensamblado_MMPC) <- NULL
Ensamblado_MMPC <- Ensamblado_MMPC |> 
  dplyr::rename(Modelo = modelo)

# Almacenamos las estadísticas en términos de AUC y error del mejor modelo de ensamblado para el segundo set de variables
Ensamblado_BIC <- medias0bis |> filter(modelo == "predi64")
Ensamblado_BIC$modelo <- "Ensamblado \n (Logíst. + RF + GBM + Red) \n Segundo set"
Ensamblado_BIC$N_variables <- "13"
row.names(Ensamblado_BIC) <- NULL
Ensamblado_BIC <- Ensamblado_BIC |> 
  dplyr::rename(Modelo = modelo)
```

```{r echo=FALSE}
Ensamblado_MMPC <- data.frame(
  tasa = c(0.01877708, 0.01974001, 0.01636976, 0.02166586, 0.02118440, 0.01733269, 0.02166586, 0.01733269, 0.01974001, 0.01877708),
  Modelo = c("Ensamblado \n (Red + GBM + SVM Linear) \n Primer set", "Ensamblado \n (Red + GBM + SVM Linear) \n Primer set", "Ensamblado \n (Red + GBM + SVM Linear) \n Primer set", "Ensamblado \n (Red + GBM + SVM Linear) \n Primer set", "Ensamblado \n (Red + GBM + SVM Linear) \n Primer set", "Ensamblado \n (Red + GBM + SVM Linear) \n Primer set", "Ensamblado \n (Red + GBM + SVM Linear) \n Primer set", "Ensamblado \n (Red + GBM + SVM Linear) \n Primer set", "Ensamblado \n (Red + GBM + SVM Linear) \n Primer set", "Ensamblado \n (Red + GBM + SVM Linear) \n Primer set"),
  auc = c(0.9981677, 0.9986482, 0.9986803, 0.9985660, 0.9966062, 0.9988445, 0.9978675, 0.9986567, 0.9978344, 0.9984292),
  N_variables = rep("11", 10)
)
Ensamblado_BIC <- data.frame(
  tasa = c(0.01781416, 0.01540684, 0.01685123, 0.02262879, 0.01877708, 0.01251805, 0.01348098, 0.01011074, 0.01636976, 0.01299952),
  Modelo = c("Ensamblado \n (Logíst. + RF + GBM + Red) \n Segundo set", "Ensamblado \n (Logíst. + RF + GBM + Red) \n Segundo set", "Ensamblado \n (Logíst. + RF + GBM + Red) \n Segundo set", "Ensamblado \n (Logíst. + RF + GBM + Red) \n Segundo set", "Ensamblado \n (Logíst. + RF + GBM + Red) \n Segundo set", "Ensamblado \n (Logíst. + RF + GBM + Red) \n Segundo set", "Ensamblado \n (Logíst. + RF + GBM + Red) \n Segundo set", "Ensamblado \n (Logíst. + RF + GBM + Red) \n Segundo set", "Ensamblado \n (Logíst. + RF + GBM + Red) \n Segundo set", "Ensamblado \n (Logíst. + RF + GBM + Red) \n Segundo set"),
  auc = c(0.9967025, 0.9980657, 0.9981743, 0.9964415, 0.9974497, 0.9994940, 0.9992353, 0.9995648, 0.9990041, 0.9993401),
  N_variables = rep("13", 10)
)
```

```{r}
# Almacenamos las estadísticas en términos de AUC y error del mejor modelo proporcionado por el AutoML para el primer set de variables
AutoML_MMPC <- 
  data.frame(tasa = 0.074014, auc = 0.974023, 
             Modelo = "AutoML (GBM) \n Primer set", N_variables = "11")

# Almacenamos las estadísticas en términos de AUC y error del mejor modelo proporcionado por el AutoML para el segundo set de variables
AutoML_BIC <- 
  data.frame(tasa = 0.063393, auc = 0.983794, 
             Modelo = "AutoML (GBM) \n Segundo set", N_variables = "13")

# Unimos todos los modelos del trabajo en un dataframe
select_final <-
  rbind(graf_MMPC, graf_repetido_BIC_set1, Red_MMPC_tun, 
        Red_step_BIC_tun, Bag_MMPC_3, Bag_BIC_2, RF_MMPC, RF_BIC,
        GB_MMPC, GB_BIC, XGB_MMPC, XGB_BIC, SVMLin_MMPC, SVMLin_BIC,
        SVMPol_MMPC, SVMPol_BIC, SVMRad_MMPC, SVMRad_BIC, Ensamblado_MMPC,
        Ensamblado_BIC, AutoML_MMPC, AutoML_BIC)
```

Y ya, por último, graficamos:

```{r layout="l-body-outset", fig.width=20, fig.asp = .99}
# Boxplot de la tasa de error para cada modelo
 a <- ggplot(data = select_final, aes(x = reorder(Modelo, tasa), y = tasa)) +
  geom_boxplot() +
  labs(x = NULL, y = "Tasa de error", title = "Distribución del error según los distintos modelos seleccionados") +
  theme_minimal() +
  theme(text = element_text(face = "bold", size = 15), plot.title = element_text(hjust = 0.5), 
        axis.title.x = element_text(vjust=-0.5)) +
  geom_label(aes(label = N_variables, y = 0.005), size = 6) +
  scale_x_discrete(guide = guide_axis(angle = 50))

# Boxplot de la tasa AUC para cada modelo
 b <- ggplot(data = select_final, aes(x = reorder(Modelo, -auc), y = auc)) +
  geom_boxplot() +
  labs(x = NULL, y = "AUC", title = "Distribución de la tasa AUC según los distintos modelos seleccionados") +
  theme_minimal() +
  theme(text = element_text(face = "bold", size = 15), plot.title = element_text(hjust = 0.5), 
        axis.title.x = element_text(vjust=-0.5)) +
  geom_label(aes(label = N_variables, y = 0.955), size = 6) +
  scale_x_discrete(guide = guide_axis(angle = 50))
 
Rmisc::multiplot(a, b)
```

Esta sería la gráfica final con todos los modelos creados durante la práctica.
Como se puede observar, **la selección de variables ha sido muy buena**: todos los modelos superan el **0.95 de AUC para los dos sets**.
Además, todos ellos presentan también una **tasa de error inferior a 0.1**.

Como era de esperar, **los modelos de ensamblado han quedado en primer lugar**, por encima de la **red**.
A pesar de ello, antes de decantarnos por un modelo en específico, vamos a elaborar en la siguiente sección una serie de **contrastes de hipótesis** para valorar si realmente merece la pena la **complejidad de los modelos de ensamblado frente a la red neuronal**, que sería el tercer mejor modelo en el ranking.

## Contrastes de hipótesis

Los contrastes se realizarán **comparando los modelos de ensamblado con los mejores modelos simples (sin ensamblar) para cada set de variables**.
Las comparaciones se harían de la siguiente manera:

1.  **Ensamblado - (Red + GBM + SVM Lineal) - Primer set** vs. **XGBoost - Primer set**
2.  **Ensamblado - (Logíst. + RF + GBM + Red) - Segundo set** vs. **Red neuronal tuneada - Segundo set**

Realizaremos **dos contrastes de hipótesis**: un **contraste paramétrico (T de Student)** y otro **no paramétrico (Wilcoxon)** para cada set.
En función de los resultados, **valoraremos por cuál de los cuatro modelos nos decantamos finalmente**.

### Contraste paramétrico: Prueba T de Student

En primer lugar, realizamos el contraste para estos dos modelos del primer set: **Ensamblado - (Red + GBM + SVM Lineal) - Primer set** vs. **XGBoost - Primer set**.

```{r}
# Generamos un dataset con los resultados de los modelos que queremos contrastar
contraste1 <- 
  rbind(XGB_MMPC,Ensamblado_MMPC)

# Generamos la lista con los nombres de los modelos y los enfrentamos
listamodelos <-
  c("XGBoost \n Primer set","Ensamblado \n (Red + GBM + SVM Linear) \n Primer set")
datacontra1 <- 
  contraste1[which(contraste1$Modelo%in%listamodelos),]
```

Una vez tenemos todo preparado, ejecutamos el contraste:

```{r}
# Prueba T de Student
res1 <- t.test(datacontra1$auc ~datacontra1$Modelo)
res1
```

Según la **prueba T de Student**, el **p-valor para el contraste es del 0.0000000000385**, por lo que se rechazaría la hipótesis nula ($H_0$).
**El promedio del error entre ambos modelos es significativamente diferente.**

En segundo lugar, realizamos el contraste para estos dos modelos del segundo set: **Ensamblado - (Logíst. + RF + GBM + Red) - Segundo set** vs. **Red neuronal tuneada - Segundo set**.

```{r}
# Generamos un dataset con los resultados de los modelos que queremos contrastar
contraste2 <- 
  rbind(Red_step_BIC_tun,Ensamblado_BIC)

# Generamos la lista con los nombres de los modelos y los enfrentamos
listamodelos <-
  c("Red neuronal tuneada \n Segundo set","Ensamblado \n (Logíst. + RF + GBM + Red) \n Segundo set")
contraste2 <- 
  contraste2[which(contraste2$Modelo%in%listamodelos),]
```

Una vez tenemos todo preparado, ejecutamos el contraste:

```{r}
# Prueba T de Student
res2 <- t.test(contraste2$auc ~contraste2$Modelo)
res2
```

De nuevo, y al igual que en el anterior contraste la **prueba T de Student**, el **p-valor para el contraste es del 0.000000000001197**, por lo que se rechazaría la hipótesis nula ($H_0$).
**El promedio del error entre ambos modelos es significativamente diferente.**

### Contraste no paramétrico: Test de Wilcoxon

Por simple curiosidad, también aplicaremos el test de Wilcoxon.
En primer lugar, realizamos el contraste para estos dos modelos del primer set: **Ensamblado - (Red + GBM + SVM Lineal) - Primer set** vs. **XGBoost - Primer set**.

```{r}
# Test de Wilcoxon
res_wilcox <- wilcox.test(contraste1$auc ~ contraste1$Modelo)
res_wilcox
```

Según el **test de Wilcoxon**, el **p-valor para el contraste es del 0.000666**, por lo que se rechazaría la hipótesis nula ($H_0$).
**El promedio del error entre ambos modelos es significativamente diferente.**

Por último, realizamos el contraste para estos dos modelos del segundo set: **Ensamblado - (Logíst. + RF + GBM + Red) - Segundo set** vs. **Red neuronal tuneada - Segundo set**.

```{r}
# Test de Wilcoxon
res_wilcox <- wilcox.test(contraste2$auc ~ contraste2$Modelo)
res_wilcox
```

Y, de nuevo, según el **test de Wilcoxon**, el **p-valor para el contraste es del 0.00000001089**, por lo que se rechazaría la hipótesis nula ($H_0$).
**El promedio del error entre ambos modelos es significativamente diferente.**

## Decisión final

A pesar del resultado de los test, **finalmente me voy a decantar por los modelos simples en lugar de los modelos ensamblados**.
Estos últimos son mucho **más complejos**, y la ganancia tanto en términos de error como en términos de AUC es del orden de las milésimas.
**Considero que no merece la pena.**

```{r layout="l-body-outset", fig.width=15, fig.asp = .99}
# Aislamos nuestros dos modelos candidatos
final <- select_final |> filter(Modelo == "Red neuronal tuneada \n Segundo set" |
                                  Modelo == "XGBoost \n Primer set")

# Boxplot de la tasa de error para cada modelo
 a <- ggplot(data = final, aes(x = reorder(Modelo, tasa), y = tasa)) +
  geom_boxplot() +
  labs(x = NULL, y = "Tasa de error", title = "Distribución del error según los modelos finales") +
  theme_minimal() +
  theme(text = element_text(face = "bold", size = 15), plot.title = element_text(hjust = 0.5), 
        axis.title.x = element_text(vjust=-0.5)) +
  geom_label(aes(label = N_variables, y = 0.005), size = 6) +
  scale_x_discrete(guide = guide_axis(angle = 50))

# Boxplot de la tasa AUC para cada modelo
 b <- ggplot(data = final, aes(x = reorder(Modelo, -auc), y = auc)) +
  geom_boxplot() +
  labs(x = NULL, y = "AUC", title = "Distribución de la tasa AUC según los modelos finales") +
  theme_minimal() +
  theme(text = element_text(face = "bold", size = 15), plot.title = element_text(hjust = 0.5), 
        axis.title.x = element_text(vjust=-0.5)) +
  geom_label(aes(label = N_variables, y = 0.955), size = 6) +
  scale_x_discrete(guide = guide_axis(angle = 50))
 
Rmisc::multiplot(a, b)
```

En el gráfico se muestra la **comparativa en error y en AUC de mis dos opciones finales**.
Los resultados de ambos modelos son los siguientes:

1.  **Red neuronal tuneada:** Presenta un **error medio del 0.07**, un **AUC de 0.98**, y cuenta con **13 variables** de las **32** totales.

2.  **XGBoost tuneado:** Presenta un **error medio de 0.08**, un **AUC de 0.97**, y cuenta con tan solo **11 variables** de las **32** totales.

Entre estos dos modelos, finalmente me decantaré por el modelo **XGBoost** con la siguiente configuración: `min_child_weight = 10`, `eta = 0.03`, `nrounds = 1000`, `max_depth = 10`, `gamma = 0`, `colsample_bytree = 1`, y `subsample = 0.9`.
Lo he elegido frente a la red neuronal principalmente porque su configuración cuenta con **2 variables menos que en el caso del otro modelo**, y porque las ganancias en términos de error y de AUC **son una nimiedad**.
Ambos modelos **son complejos**, requieren de bastante hiperparámetros que tunear, pero el hecho de que el XGBoost presente **menos variables es lo que ha provocado que me decante por él**.
Además, el modelo seleccionado presenta una **reducida varianza**.

En el siguiente y último apartado del trabajo emplearemos el modelo para **predecir**, estudiaremos su **matriz de confusión y sus estadísticas básicas**, y lo **compararemos con otros notebooks** sobre este mismo dataset subidos a la página web de **Kaggle**.

## Predicciones, observaciones y especificaciones del modelo final

```{r echo=FALSE}
# Fijamos semilla
set.seed(12346)

# Inicializamos la paralelización
clusters <- detectCores() - 1
make_cluster <- makeCluster(clusters)
registerDoParallel(make_cluster)

# Le indicamos validación cruzada repetida
control <- trainControl(method = "repeatedcv",number=4,repeats=5,savePredictions = "all",
                        classProbs=TRUE) 

# Creamos el grid tuneado
xgbmgrid <- expand.grid(min_child_weight=c(10),
                      eta=c(0.06),
                      nrounds=c(500),
                      max_depth=10,gamma=0,
                      colsample_bytree=1,subsample=0.9)

# Lanzamos la función del modelo
xgbm_final <- train(factor(Satisfaction)~Online_Board_Sat_X1+Travel_Personal.Travel+
                         WiFi_Sat_X1+Customer_Loyal.Customer+WiFi_Sat_X2+Baggage_Sat_X3+
                         +Baggage_Sat_X2+Class_Eco.Plus+Checkin_Sat_X3+Online_Board_Sat_X3+
                         Dep_Arr_Sat_X3+Inflight_Sat_X3+Seat_Sat_X3,
              data=air_prep,method="xgbTree",trControl=control,tuneGrid=xgbmgrid,verbose=FALSE)

# Finalizamos la paralelización
stopCluster(make_cluster)
registerDoSEQ()
```

Antes de nada, **guardamos las predicciones de nuestro modelo** final en `pred_final` para poder representar la **matriz de confusión**:

```{r}
pred_final <-
  xgbm_final$pred
```

Una vez almacenadas en la variable, echemos un vistazo a la **matriz de confusión y a las métricas básicas** de nuestro modelo seleccionado:

```{r}
confmatrix <- 
  confusionMatrix(data = factor(pred_final$pred), reference = factor(pred_final$obs),
                  positive = "Yes")
confmatrix
```

```{r}
curva <-
  roc(pred_final$obs,pred_final$Yes,levels=c("Yes","No"))
curva
```

-   **Accuracy:** el modelo ha alcanzado un accuracy máximo del **93.18 %**.
-   **Sensibilidad (porcentaje de verdaderos positivos):** el modelo ha alcanzado una sensibilidad máxima del **95.23 %**.
-   **Especificidad (porcentaje de verdaderos negativos):** el modelo ha alcanzado una especificidad máxima del **90.51 %**.
-   **Valor curva ROC:** respecto al valor de la curva ROC, el modelo ha alcanzado un **98.43 %**.

Además, si observamos la matriz de confusión, **de 5885 clientes satisfechos, el modelo ha clasificado correctamente 5604**.
Por otro lado, **de 4500 clientes insatisfechos, el modelo ha clasificado correctamente 4073**.
Hemos considerado un **punto de crossover** sensibilidad vs. especificidad del **0.5**.
Si quisiéramos incrementar el porcentaje de verdaderos positivos, podríamos alterar ese punto de equilibrio **aumentando la especificidad en detrimento de la sensibilidad**.

Vamos a comprobar esta cuestión **alterando el punto de corte**:

```{r}
# Definimos el nuevo punto de corte
corte <- 0.6

# Aplicamos el punto de corte a `pred_final`
pred_final$predcorte <- ifelse(pred_final$Yes>corte,"Yes","No")
pred_final$predcorte <- as.factor(pred_final$predcorte)

# Volvemos a generar la matriz de confusión
confmatrix2 <- 
  confusionMatrix(data = factor(pred_final$predcorte), reference = factor(pred_final$obs),
                  positive = "Yes")
confmatrix2
```

Como se puede observar en la nueva matriz, **con el punto de corte sobre 0.6** (en lugar de 0.5) logramos **equilibrar sensibilidad y especificidad en el 92 %**.
Dependiendo del mayor o menor interés que se tenga en clasificar los datos de la clase positiva o negativa, podremos modificar este límite a nuestro gusto.
Con `corte = 0.6` ha quedado **bastante equilibrado**.

A continuación, algunos gráficos muy visuales sobre cómo se distribuyen las predicciones:

```{r}
pred_final |> filter(obs == "Yes") |> 
  ggplot(aes(x = seq_along(Yes), y = Yes)) +
  geom_point(color = "blue", shape = 16) +
  labs(x = "Distribución categoría `Yes`", y = "Probabilidad") +
  theme_minimal()
```

En este *scatter plot* azul están representadas **todas las observaciones catalogadas como** `Yes`.
A cada observación le corresponde **una probabilidad representada en el eje y**.
Como se puede observar, **la gran mayoría de observaciones se congregan en la parte superior del gráfico**, en donde la **probabilidad es cercana a 1**.
Ello indica que el modelo **ha aprendido los patrones de los datos** y ha sabido clasificar correctamente la gran mayoría de `Yes` de nuestra variable objetivo `Satisfaction`.

```{r}
pred_final |> filter(obs == "No") |> 
  ggplot(aes(x = seq_along(Yes), y = Yes)) +
  geom_point(color = "red", shape = 16) +
  labs(x = "Distribución categoría `No`", y = "Probabilidad") +
  theme_minimal()
```

Este segundo gráfico muestra lo mismo que el anterior, pero esta vez para las categorías catalogadas como `No`.
Como se puede observar, la gran mayoría de observaciones **se congregan alrededor del valor 0**, precisamente porque el modelo ha sabido asignarles la probabilidad que les corresponde.
Como es evidente, ambos gráficos son complementarios.

# Fase Extra: Tabla de los parámetros de la regresión logística, importancia de variables, tabla resumen con todos los algoritmos y comparativa con notebooks de Kaggle

## Interpretación tabla de los parámetros de la regresión logística

Para ir concluyendo, algunas **cuestiones finales** que se han quedado en el tintero.
En primer lugar, **mostraremos e interpretaremos la tabla de los parámetros de la regresión logística para el modelo seleccionado**.

```{r}
# Aplicamos `method = none` para obtener la tabla de los valores de la logística
control <- 
  trainControl(method = "none", classProbs = TRUE, savePredictions = "all")

# Definimos el modelo, enfrentando la objetivo a nuestro set de variables preliminar
logi_final <- 
  train(Satisfaction ~ Customer_Loyal.Customer+Travel_Personal.Travel+
          Class_Eco.Plus+WiFi_Sat_X1+Online_Board_Sat_X1+Online_Board_Sat_X3+
          Entertainment_Sat_X3+On_board_Sat_X3+Leg_Sat_X2+Leg_Sat_X3+Checkin_Sat_X3, 
        data = air_prep, method = "glm", trControl = control)

summary(logi_final)
```

Como se puede observar en las métricas, el modelo que se ha decidido crear se trata de un **modelo de regresión logística simple**.
A modo de ejemplo, la **interpretación** de $\beta_4$ es la siguiente: si la **satisfacción con el WiFi** a bordo del avión **aumenta en una unidad** se estima que, en media, la probabilidad de que el cliente quede satisfecho con la experiencia **incrementará en 3.0473 unidades**.
Esta relación no es más que la **elasticidad** entre la satisfacción con el WiFi a bordo de un avión y su satisfacción general con la experiencia y se trata, además, de una **relación constante**.

Por otro lado, en la salida del modelo podemos observar como los **p-valor** coligados a los distintos parámetros $\beta$ y al estadístico para este contraste son **bastante bajos**.
Si trabajamos con un nivel de significación habitual del 5 % (0.05), todos los p-valor son menores que ese nivel de significación, por lo que podríamos **rechazar la hipótesis nula**, esto es, **la no significación individual** de **todas las variables** que componen el modelo al 5 % de significación.
Por ende, a la luz de los resultados, **todas las variables son significativas individualmente**, o lo que es lo mismo: **el efecto de todas las variables predictoras** dependen de la variable `Satisfaction` al 5 % de nivel de significación. Además, por cada parámetro de la logística le corresponden unas 200 observaciones de la clase minoritaria (ya comprobamos en anteriores apartados que se encontraba bastante balanceada).

## Importancia de las variables y gráfico visualpred

```{r echo=FALSE}
knitr::include_graphics("/Users/leztin/Desktop/Captura de pantalla 2023-05-16 a las 15.14.21.png")  
```

```{r echo=FALSE}
knitr::include_graphics("/Users/leztin/Desktop/Visualpred final.png")  
```

En estos dos últimos gráfico podemos visualizar el **grado de aportación al accuracy total de las distintas variables que componen el modelo final**, y un **gráfico** `visualpred` del **XGBoost** seleccionado.
Como se puede observar, el **WiFi a bordo del avión** parece seguir manteniéndose cómo la variable **más relevante** a la hora de considerar el **accuracy general** del modelo.

Además, en el gráfico `visualpred` podemos ver cómo **la división por parte del algoritmo entre clases es bastante satisfactoria**.
El algoritmo ha conseguido **aprender el patrón** de los datos, y **la masa probabilística se reparte con bastante acierto entre el total de los datos**.

## Tabla resumen con los resultados de todos los modelos y comparación con otros notebooks de Kaggle

```{r echo=FALSE, eval=FALSE}
ab <- 
  select_final |> group_by(factor(Modelo)) |> filter(N_variables == "11") |>  summarise(AUC = mean(auc))
cd <- 
  select_final |> group_by(factor(Modelo)) |> filter(N_variables == "11") |>  summarise("Tasa de fallos" = mean(tasa)) |> dplyr::select(-"factor(Modelo)")
tabla_final <- cbind(ab, cd)
tabla_final$`factor(Modelo)` <- str_extract(tabla_final$`factor(Modelo)`, "^[^\\n]+")
tabla_final <- tabla_final %>%
  arrange(desc(AUC)) %>%
  dplyr::rename(Modelo = `factor(Modelo)`)
tabla_final
```

```{r echo=FALSE}
knitr::include_graphics("/Users/leztin/Desktop/Captura de pantalla 2023-05-16 a las 15.52.44.png")  
```

Esta sería la **tabla final** con los resultados de **todos los algoritmos aplicados en este trabajo al set finalmente seleccionado**.
Vamos a compararla con el notebook más votado dentro de la plataforma Kaggle para hacernos una idea de si los resultados son o no competitivos.

A continuación se muestra los resultados del notebook mejor valorado en Kaggle (**Classification: Predicting Customer Satisfaction - TJ KLEIN**).
**Como se puede observar, los resultados de sus mejores algoritmos son un poco inferiores a los de este trabajo**.
Además, en el mejor modelo de este trabajo se emplean **11 variables de las 32 originales**, bastantes menos que en el notebook de Kaggle con el que estamos comparando ([<https://bit.ly/42L6JSD>]):

```{r echo=FALSE}
knitr::include_graphics("/Users/leztin/Desktop/Captura de pantalla 2023-05-16 a las 15.57.42.png")  
```

Hasta aquí hemos llegado.
En el segundo PDF adjunto se resuelve esta misma práctica empleando el **software SAS Miner**.

<CENTER>**¡Muchas gracias por la atención!**</CENTER>
